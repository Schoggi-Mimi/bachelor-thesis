{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c04dc703-4279-41ec-b933-b303265e809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from dotmap import DotMap\n",
    "import wandb\n",
    "from wandb.wandb_run import Run\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "from einops import rearrange\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy import stats\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from data import SCINDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "656a4603-7bf8-4500-bdf5-6d90434639e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_regressor_on_dataset(model: nn.Module,\n",
    "                                      dataset: Dataset, \n",
    "                                      batch_size: int, \n",
    "                                      num_workers: int,\n",
    "                                      device: torch.device, \n",
    "                                      save_dir: str):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    features, scores = get_features_scores(model, dataloader, device, save_dir)\n",
    "\n",
    "    # perform grid search to find best alpha values\n",
    "    best_alpha = alpha_grid_search(dataset=dataset, features=features, scores=scores, num_splits=10)\n",
    "    #best_alpha = 0.151991108295293\n",
    "    print(f'Best alpha found: {best_alpha}')\n",
    "\n",
    "    # Generate indices for training on the whole dataset\n",
    "    train_indices = np.arange(len(dataset))\n",
    "    train_indices = np.repeat(train_indices * 5, 5) + np.tile(np.arange(5), len(train_indices))  # for each index generate 5 indices (one for each crop)\n",
    "\n",
    "    # Select train features and scores using the generated indices\n",
    "    train_features = features[train_indices]\n",
    "    train_scores = scores[train_indices]\n",
    "\n",
    "    # Fit a Ridge regressor to the training data\n",
    "    regressor = Ridge(alpha=best_alpha).fit(train_features, train_scores)\n",
    "\n",
    "    # Save the trained regressor to a file\n",
    "    with open(f\"scin_regressor_{best_alpha}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(regressor, f)\n",
    "\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca19f88b-9d9b-4238-ad4f-22543c5b80c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_scores(model: nn.Module,\n",
    "                        dataloader: DataLoader,\n",
    "                        device: torch.device,\n",
    "                        save_dir: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    feats_file = os.path.join(save_dir, \"features.npy\")\n",
    "    scores_file = os.path.join(save_dir, \"scores.npy\")\n",
    "    \"\"\"\n",
    "    if os.path.exists(feats_file) and os.path.exists(scores_file):\n",
    "        feats = np.load(feats_file)\n",
    "        scores = np.load(scores_file)\n",
    "        print('Loaded features and scores from saved file in SCIN.')\n",
    "        return feats, scores\"\"\"\n",
    "    feats = np.zeros((0, model.encoder.feat_dim * 2))   # Double the features because of the original and downsampled image\n",
    "    scores = np.zeros(0)\n",
    "    #progress_bar = tqdm(total=len(dataloader), desc=\"Extracting features\")\n",
    "    total_iterations = len(dataloader) * dataloader.batch_size\n",
    "    with tqdm(total=total_iterations, desc=\"Extracting features\", leave=False) as progress_bar:\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            img_orig = batch[\"img\"].to(device)\n",
    "            img_ds = batch[\"img_ds\"].to(device)\n",
    "            mos = batch[\"mos\"]\n",
    "    \n",
    "            img_orig = rearrange(img_orig, \"b n c h w -> (b n) c h w\")\n",
    "            img_ds = rearrange(img_ds, \"b n c h w -> (b n) c h w\")\n",
    "            mos = mos.repeat_interleave(5)  # repeat MOS for each crop\n",
    "    \n",
    "            with torch.cuda.amp.autocast(), torch.no_grad():\n",
    "                _, f = model(img_orig, img_ds, return_embedding=True)\n",
    "    \n",
    "            feats = np.concatenate((feats, f.cpu().numpy()), 0)\n",
    "            scores = np.concatenate((scores, mos.numpy()), 0)\n",
    "            progress_bar.update(1)\n",
    "    np.save(feats_file, feats)\n",
    "    np.save(scores_file, scores)\n",
    "    return feats, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a10f840-3157-401e-88cf-16bb2cc729a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001, 1000.0, 100]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_range = [1e-3, 1e3, 100]\n",
    "grid_search_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4dadfac-3ef6-43d2-a6e9-fbf06f2eec78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 10.0, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_range = [1e-1, 1e1, 1]\n",
    "grid_search_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "697a62a3-964f-4774-b4cd-c2cbeff5fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_grid_search(dataset: Dataset,\n",
    "                      features: np.ndarray,\n",
    "                      scores: np.ndarray,\n",
    "                      num_splits: int) -> float:\n",
    "    #grid_search_range = [1e-3, 1e3, 100]\n",
    "    grid_search_range = [1e-2, 1e2, 10]\n",
    "    #grid_search_range = [1e-1, 1e1, 1]\n",
    "    alphas = np.geomspace(*grid_search_range, endpoint=True)\n",
    "    srocc_all = [[] for _ in range(len(alphas))]\n",
    "    with tqdm(total=num_splits * len(alphas), desc='Grid Search', unit='split') as pbar:\n",
    "        for i in range(num_splits):\n",
    "            train_indices = dataset.get_split_indices(split=i, phase=\"train\")\n",
    "            val_indices = dataset.get_split_indices(split=i, phase=\"val\")\n",
    "    \n",
    "            # for each index generate 5 indices (one for each crop)\n",
    "            train_indices = np.repeat(train_indices * 5, 5) + np.tile(np.arange(5), len(train_indices))\n",
    "            val_indices = np.repeat(val_indices * 5, 5) + np.tile(np.arange(5), len(val_indices))\n",
    "    \n",
    "            train_features = features[train_indices]\n",
    "            train_scores = scores[train_indices]\n",
    "    \n",
    "            val_features = features[val_indices]\n",
    "            val_scores = scores[val_indices]\n",
    "            val_scores = val_scores[::5]  # Scores are repeated for each crop, so we only keep the first one\n",
    "    \n",
    "            for idx, alpha in enumerate(alphas):\n",
    "                regressor = Ridge(alpha=alpha).fit(train_features, train_scores)\n",
    "                preds = regressor.predict(val_features)\n",
    "                preds = np.mean(np.reshape(preds, (-1, 5)), 1)  # Average the predictions of the 5 crops of the same image\n",
    "                srocc_all[idx].append(stats.spearmanr(preds, val_scores)[0])\n",
    "                pbar.update(1)\n",
    "\n",
    "    srocc_all_median = [np.median(srocc) for srocc in srocc_all]\n",
    "    srocc_all_median = np.array(srocc_all_median)\n",
    "    best_alpha_idx = np.argmax(srocc_all_median)\n",
    "    best_alpha = alphas[best_alpha_idx]\n",
    "\n",
    "    return best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7c238f4-ae5d-474c-a423-dc9504b2a1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/miccunifi_ARNIQA_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "arniqa = torch.hub.load(repo_or_dir=\"miccunifi/ARNIQA\", source=\"github\", model=\"ARNIQA\")\n",
    "arniqa.eval().to(DEVICE)\n",
    "next(arniqa.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdd884b2-4ada-47a5-8f1d-c0bce050bd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"SCIN_v2\"\n",
    "NUM_SPLITS = 10\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 1\n",
    "GRID_SEARCH = True\n",
    "# ALPHA = 0.151991108295293 # For simplicity, a fixed alpha value is used\n",
    "CROP_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e39fc65-ed45-4dbc-bf11-95dc918ae61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "scin_dataset = SCINDataset(root=DATA_PATH, phase=\"all\", crop_size=CROP_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7882ea7-001f-4af7-ad59-334bb4185087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  10%|â–ˆ         | 10/100 [03:59<36:31, 24.35s/split]        "
     ]
    }
   ],
   "source": [
    "regressor = train_linear_regressor_on_dataset(model=arniqa, dataset=scin_dataset, batch_size=BATCH_SIZE, \n",
    "                                              num_workers=NUM_WORKERS, device=DEVICE, save_dir=DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f43114-14bc-4eb1-bca6-8d95c883342b",
   "metadata": {},
   "source": [
    "# Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "744cf602-b1df-46e2-9847-a40ab8ad5f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"scin_regressor_0.21544346900318834.pkl\", \"rb\") as f:\n",
    "    regressor = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "625d8d64-4180-40d7-af8c-211300b27ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image_path):\n",
    "    width, height = image_path.size\n",
    "    print(f\"Image size: {width}x{height} pixels\")\n",
    "    display(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ee89b0-f9d9-495c-a7d5-a5df4c06d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../test_images/fig5c.jpg\"\n",
    "#img_path = \"../test_images/fig4e.png\"\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "img_ds = transforms.Resize((img.size[1] // 2, img.size[0] // 2))(img)\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "img = preprocess(img).unsqueeze(0).to(DEVICE)\n",
    "img_ds = preprocess(img_ds).unsqueeze(0).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c46abea-ea55-41cf-8d70-1deb03c8ffd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted MOS Score: [2.66327731]\n"
     ]
    }
   ],
   "source": [
    "test = 0\n",
    "\n",
    "if test == 0:\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        _, features = arniqa(img, img_ds, return_embedding=True, scale_score=True)\n",
    "        features = features.cpu().numpy()\n",
    "    predicted_score = regressor.predict(features)\n",
    "    print(\"Predicted MOS Score:\", predicted_score)\n",
    "elif test == 1:\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        predicted_score = arniqa(img, img_ds, return_embedding=False, scale_score=True)\n",
    "    print(f\"Image quality score: {predicted_score.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8467a1b-f754-452a-b9b9-64287e76cc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.47138855, -1.53796235, -0.64137025, ...,  0.46897656,\n",
       "        2.30539767,  2.18712411])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3625782b-7190-4236-a7eb-67696da809e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.025981603865405"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74265a64-2ab6-4d21-8d37-6dfa72bc9380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21544346900318834"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bee1d8-210a-4d25-9245-2917aef596c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01991ad-92d7-4dca-afbc-81d8f7f7505a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72d2b2b-0297-4d92-acf7-6ad64d98885a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10076c02-6fa9-4bcc-a699-47a46e50ce2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(original_name=TorchLinearRegression)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arniqa.regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8179130a-14e6-4a24-bc95-35953142b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomRegressor(nn.Module):\n",
    "    def __init__(self, regressor):\n",
    "        super(CustomRegressor, self).__init__()\n",
    "        self.regressor = regressor\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_cpu = x.cpu()\n",
    "        return torch.tensor(self.regressor.predict(x_cpu.numpy()))\n",
    "\n",
    "# Convert the scikit-learn regressor to a PyTorch module\n",
    "custom_regressor = CustomRegressor(regressor)\n",
    "arniqa.regressor = custom_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ae29688-9f87-4b94-aae9-01b8e4f5978e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomRegressor()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arniqa.regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e90568b-fc55-4a3f-ae72-c192335665f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
