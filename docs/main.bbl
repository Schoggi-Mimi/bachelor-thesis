% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{apa/apasortcite//global/global}
    \entry{Monkeypox}{online}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=5e330206d122845de19963480ab85a48}{%
           family={Ahsan},
           familyi={A\bibinitperiod},
           given={Md\bibnamedelima Manjurul},
           giveni={M\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=806c019703dc5c4505a620506f40d465}{%
           family={Uddin},
           familyi={U\bibinitperiod},
           given={Muhammad\bibnamedelima Ramiz},
           giveni={M\bibinitperiod\bibinitdelim R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f2604d696a98e14c3b9b05edfdaeb79b}{%
           family={Luna},
           familyi={L\bibinitperiod},
           given={Shahana\bibnamedelima Akter},
           giveni={S\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b4496085a60ed3ba0135575814a31b0b}
      \strng{fullhash}{8a516943b5a0f5ee3eeb5f0b2f086d99}
      \strng{bibnamehash}{8a516943b5a0f5ee3eeb5f0b2f086d99}
      \strng{authorbibnamehash}{8a516943b5a0f5ee3eeb5f0b2f086d99}
      \strng{authornamehash}{b4496085a60ed3ba0135575814a31b0b}
      \strng{authorfullhash}{8a516943b5a0f5ee3eeb5f0b2f086d99}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper explains the initial Monkeypox Open image data collection procedure. It was created by assembling images collected from websites, newspapers, and online portals and currently contains around 1905 images after data augmentation.}
      \field{day}{3}
      \field{eprintclass}{cs, eess}
      \field{eprinttype}{arxiv}
      \field{langid}{english}
      \field{month}{6}
      \field{title}{Monkeypox {{Image Data}} Collection}
      \field{urlday}{28}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2206.01774
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/J3MR87R2/Ahsan et al. - 2022 - Monkeypox Image Data collection.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2206.01774
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2206.01774
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing}
    \endentry
    \entry{CSIQ}{article}{}
      \name{author}{1}{}{%
        {{un=1,uniquepart=given,hash=c5addfdd7f1dd742dac1643e46f25ee6}{%
           family={Chandler},
           familyi={C\bibinitperiod},
           given={Damon\bibnamedelima M.},
           giveni={D\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=1}}%
      }
      \strng{namehash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{fullhash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{bibnamehash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{authorbibnamehash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{authornamehash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{authorfullhash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{day}{1}
      \field{issn}{1017-9909}
      \field{journaltitle}{Journal of Electronic Imaging}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{J. Electron. Imaging}
      \field{shorttitle}{Most Apparent Distortion}
      \field{title}{Most Apparent Distortion: Full-Reference Image Quality Assessment and the Role of Strategy}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{19}
      \field{year}{2010}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{011006}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1117/1.3267105
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/ND7PFFNY/Chandler - 2010 - Most apparent distortion full-reference image qua.pdf
      \endverb
      \verb{urlraw}
      \verb https://s2.smu.edu/~eclarson/pubs/2010JEI_MAD.pdf
      \endverb
      \verb{url}
      \verb https://s2.smu.edu/~eclarson/pubs/2010JEI_MAD.pdf
      \endverb
    \endentry
    \entry{A57}{article}{}
      \name{author}{2}{}{%
        {{un=1,uniquepart=given,hash=52a422f501ab24ced4fed94ce0226e40}{%
           family={Chandler},
           familyi={C\bibinitperiod},
           given={D.M.},
           giveni={D\bibinitperiod},
           givenun=1}}%
        {{un=0,uniquepart=base,hash=e4622e95fefb83373d9614ae9c8ce220}{%
           family={Hemami},
           familyi={H\bibinitperiod},
           given={S.S.},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{fullhash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{bibnamehash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{authorbibnamehash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{authornamehash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{authorfullhash}{1ea3294ab1b80857b24a400ac4e1c519}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper presents an efficient metric for quantifying the visual fidelity of natural images based on near-threshold and suprathreshold properties of human vision. The proposed metric, the visual signal-to-noise ratio (VSNR), operates via a two-stage approach. In the first stage, contrast thresholds for detection of distortions in the presence of natural images are computed via wavelet-based models of visual masking and visual summation in order to determine whether the distortions in the distorted image are visible. If the distortions are below the threshold of detection, the distorted image is deemed to be of perfect visual fidelity (VSNR = ) and no further analysis is required. If the distortions are suprathreshold, a second stage is applied which operates based on the low-level visual property of perceived contrast, and the mid-level visual property of global precedence. These two properties are modeled as Euclidean distances in distortion-contrast space of a multiscale wavelet decomposition, and VSNR is computed based on a simple linear sum of these distances. The proposed VSNR metric is generally competitive with current metrics of visual fidelity; it is efficient both in terms of its low computational complexity and in terms of its low memory requirements; and it operates based on physical luminances and visual angle (rather than on digital pixel values and pixel-based dimensions) to accommodate different viewing conditions.}
      \field{issn}{1057-7149}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{9}
      \field{number}{9}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{shorttitle}{{{VSNR}}}
      \field{title}{{{VSNR}}: {{A Wavelet-Based Visual Signal-to-Noise Ratio}} for {{Natural Images}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{16}
      \field{year}{2007}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2284\bibrangedash 2298}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1109/TIP.2007.901820
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/EW9CANZ4/Chandler und Hemami - 2007 - VSNR A Wavelet-Based Visual Signal-to-Noise Ratio.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/4286985/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/4286985/
      \endverb
    \endentry
    \entry{DDI}{article}{}
      \name{author}{19}{}{%
        {{un=0,uniquepart=base,hash=0df7931cf6d169c0892a3a00ce803ffa}{%
           family={Daneshjou},
           familyi={D\bibinitperiod},
           given={Roxana},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=727a8a479e533213d5df986b6f2d695e}{%
           family={Vodrahalli},
           familyi={V\bibinitperiod},
           given={Kailas},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7dcf7c517335b316301b5a23b218557b}{%
           family={Novoa},
           familyi={N\bibinitperiod},
           given={Roberto\bibnamedelima A.},
           giveni={R\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f52780318e8d7a8f1246945fc17275d5}{%
           family={Jenkins},
           familyi={J\bibinitperiod},
           given={Melissa},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c37e00c1ca8aafe56159ff4ab1f6e040}{%
           family={Liang},
           familyi={L\bibinitperiod},
           given={Weixin},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=60abb913d03e3830abf9001aa7fc6e66}{%
           family={Rotemberg},
           familyi={R\bibinitperiod},
           given={Veronica},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d5274c1d02c20ebd471b200127fcee09}{%
           family={Ko},
           familyi={K\bibinitperiod},
           given={Justin},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2418082b9eed3d391d9b768fd518590b}{%
           family={Swetter},
           familyi={S\bibinitperiod},
           given={Susan\bibnamedelima M.},
           giveni={S\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=70d210517db32b4eaab0e90ad1400947}{%
           family={Bailey},
           familyi={B\bibinitperiod},
           given={Elizabeth\bibnamedelima E.},
           giveni={E\bibinitperiod\bibinitdelim E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=52203a415c44a164349b49556b4cb936}{%
           family={Gevaert},
           familyi={G\bibinitperiod},
           given={Olivier},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8891e16d35998eaa26fec3e89246c530}{%
           family={Mukherjee},
           familyi={M\bibinitperiod},
           given={Pritam},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c396d55e91bde40804ef7b29e3f2d9a4}{%
           family={Phung},
           familyi={P\bibinitperiod},
           given={Michelle},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cc6c5220558493c7698dbc66b3af1f9a}{%
           family={Yekrang},
           familyi={Y\bibinitperiod},
           given={Kiana},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a4e5d95ac01bebef06e82562655bff0b}{%
           family={Fong},
           familyi={F\bibinitperiod},
           given={Bradley},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=41236bc53de1c13fa044268006cbd26e}{%
           family={Sahasrabudhe},
           familyi={S\bibinitperiod},
           given={Rachna},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a2fdfbc1a0bd5114e0589d350fd4e21f}{%
           family={Allerup},
           familyi={A\bibinitperiod},
           given={Johan\bibnamedelimb A.\bibnamedelimi C.},
           giveni={J\bibinitperiod\bibinitdelim A\bibinitperiod\bibinitdelim C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=166f1cda23be30a0e86aec354d1ba119}{%
           family={Okata-Karigane},
           familyi={O\bibinithyphendelim K\bibinitperiod},
           given={Utako},
           giveni={U\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1b868d50048a635fa27ffa744323fa41}{%
           family={Zou},
           familyi={Z\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dc642188ac4ca15bdcac2f5db259e705}{%
           family={Chiou},
           familyi={C\bibinitperiod},
           given={Albert\bibnamedelima S.},
           giveni={A\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{c2819d3adaa0ac3e74c4f0e85171265e}
      \strng{fullhash}{fa9506acc8c11aab5b50c7db22308db9}
      \strng{bibnamehash}{fa9506acc8c11aab5b50c7db22308db9}
      \strng{authorbibnamehash}{fa9506acc8c11aab5b50c7db22308db9}
      \strng{authornamehash}{c2819d3adaa0ac3e74c4f0e85171265e}
      \strng{authorfullhash}{fa9506acc8c11aab5b50c7db22308db9}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{An estimated 3 billion people lack access to dermatological care globally. Artificial intelligence (AI) may aid in triaging skin diseases and identifying malignancies. However, most AI models have not been assessed on images of diverse skin tones or uncommon diseases. Thus, we created the Diverse Dermatology Images (DDI) dataset—the first publicly available, expertly curated, and pathologically confirmed image dataset with diverse skin tones. We show that state-of-the-art dermatology AI models exhibit substantial limitations on the DDI dataset, particularly on dark skin tones and uncommon diseases. We find that dermatologists, who often label AI datasets, also perform worse on images of dark skin tones and uncommon diseases. Fine-tuning AI models on the DDI images closes the performance gap between light and dark skin tones. These findings identify important weaknesses and biases in dermatology AI that should be addressed for reliable application to diverse patients and diseases. , A diverse, curated clinical dermatology image set can help address AI in dermatology limitations.}
      \field{day}{12}
      \field{issn}{2375-2548}
      \field{journaltitle}{Science Advances}
      \field{langid}{english}
      \field{month}{8}
      \field{number}{32}
      \field{shortjournal}{Sci. Adv.}
      \field{title}{Disparities in Dermatology {{AI}} Performance on a Diverse, Curated Clinical Image Set}
      \field{urlday}{28}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{8}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{eabq6147}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1126/sciadv.abq6147
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/ECM8UI47/Daneshjou et al. - 2022 - Disparities in dermatology AI performance on a div.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.science.org/doi/10.1126/sciadv.abq6147
      \endverb
      \verb{url}
      \verb https://www.science.org/doi/10.1126/sciadv.abq6147
      \endverb
    \endentry
    \entry{LIVE_Wild}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=3e0108af1e78568ae823af503315860a}{%
           family={Ghadiyaram},
           familyi={G\bibinitperiod},
           given={Deepti},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d9c2ab9a8cbcab08292923a454c88ce7}{%
           family={Bovik},
           familyi={B\bibinitperiod},
           given={Alan\bibnamedelima C.},
           giveni={A\bibinitperiod\bibinitdelim C\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{fullhash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{bibnamehash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{authorbibnamehash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{authornamehash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{authorfullhash}{3cdb959f35d9532ad6b5f9539dc38537}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Most publicly available image quality databases have been created under highly controlled conditions by introducing graded simulated distortions onto high-quality photographs. However, images captured using typical real-world mobile camera devices are usually afflicted by complex mixtures of multiple distortions, which are not necessarily well-modeled by the synthetic distortions found in existing databases. The originators of existing legacy databases usually conducted human psychometric studies to obtain statistically meaningful sets of human opinion scores on images in a stringently controlled visual environment, resulting in small data collections relative to other kinds of image analysis databases. Toward overcoming these limitations, we designed and created a new database that we call the LIVE In the Wild Image Quality Challenge Database, which contains widely diverse authentic image distortions on a large number of images captured using a representative variety of modern mobile devices. We also designed and implemented a new online crowdsourcing system, which we have used to conduct a very large-scale, multi-month image quality assessment (IQA) subjective study. Our database consists of over 350 000 opinion scores on 1162 images evaluated by over 8100 unique human observers. Despite the lack of control over the experimental environments of the numerous study participants, we demonstrate excellent internal consistency of the subjective data set. We also evaluate several top-performing blind IQA algorithms on it and present insights on how the mixtures of distortions challenge both end users as well as automatic perceptual quality prediction models. The new database is available for public use at http://live.ece.utexas.edu/research/ChallengeDB/index.html.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{title}{Massive {{Online Crowdsourced Study}} of {{Subjective}} and {{Objective Picture Quality}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{25}
      \field{year}{2016}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{372\bibrangedash 387}
      \range{pages}{16}
      \verb{doi}
      \verb 10.1109/TIP.2015.2500021
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/NQWGF6QQ/Ghadiyaram und Bovik - 2016 - Massive Online Crowdsourced Study of Subjective an.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/7327186/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/7327186/
      \endverb
    \endentry
    \entry{F17K}{online}{}
      \name{author}{8}{}{%
        {{un=0,uniquepart=base,hash=fd54e1cfc05f311f39082f00f60d2b84}{%
           family={Groh},
           familyi={G\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2d4275cdd5c811184540d396a2145804}{%
           family={Harris},
           familyi={H\bibinitperiod},
           given={Caleb},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7d52a0f63a3bd096458d2eff247fa29d}{%
           family={Soenksen},
           familyi={S\bibinitperiod},
           given={Luis},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=28dfabe7b57656678c41ad55936042d8}{%
           family={Lau},
           familyi={L\bibinitperiod},
           given={Felix},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5331a36550165214d7a48f5d4a3163bc}{%
           family={Han},
           familyi={H\bibinitperiod},
           given={Rachel},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=648e51d2d11d843b2d3cbd072073b357}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Aerin},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7ea6c3c20fa36baa9472ad5aa2199f99}{%
           family={Koochek},
           familyi={K\bibinitperiod},
           given={Arash},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e847d65f28237726943cbd201016ae0a}{%
           family={Badri},
           familyi={B\bibinitperiod},
           given={Omar},
           giveni={O\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{01d902a15a712621710f5ad4e6bdd8a8}
      \strng{fullhash}{1e31ebdb01806e8aa75f38d3df862b31}
      \strng{bibnamehash}{1e31ebdb01806e8aa75f38d3df862b31}
      \strng{authorbibnamehash}{1e31ebdb01806e8aa75f38d3df862b31}
      \strng{authornamehash}{01d902a15a712621710f5ad4e6bdd8a8}
      \strng{authorfullhash}{1e31ebdb01806e8aa75f38d3df862b31}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{How does the accuracy of deep neural network models trained to classify clinical images of skin conditions vary across skin color? While recent studies demonstrate computer vision models can serve as a useful decision support tool in healthcare and provide dermatologist-level classification on a number of specific tasks, darker skin is underrepresented in the data. Most publicly available data sets do not include Fitzpatrick skin type labels. We annotate 16,577 clinical images sourced from two dermatology atlases with Fitzpatrick skin type labels and open-source these annotations. Based on these labels, we find that there are significantly more images of light skin types than dark skin types in this dataset. We train a deep neural network model to classify 114 skin conditions and find that the model is most accurate on skin types similar to those it was trained on. In addition, we evaluate how an algorithmic approach to identifying skin tones, individual typology angle, compares with Fitzpatrick skin type labels annotated by a team of human labelers.}
      \field{day}{20}
      \field{eprintclass}{cs}
      \field{eprinttype}{arxiv}
      \field{langid}{english}
      \field{month}{4}
      \field{title}{Evaluating {{Deep Neural Networks Trained}} on {{Clinical Images}} in {{Dermatology}} with the {{Fitzpatrick}} 17k {{Dataset}}}
      \field{urlday}{28}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2104.09957
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/7CFK8V66/Groh et al. - 2021 - Evaluating Deep Neural Networks Trained on Clinica.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2104.09957
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2104.09957
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{MDID2013}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=a64df0db3d659a7cb92ab2266cdd6339}{%
           family={Gu},
           familyi={G\bibinitperiod},
           given={Ke},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=de70ef50dd45ba84349c3a3d3d5a9141}{%
           family={Zhai},
           familyi={Z\bibinitperiod},
           given={Guangtao},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=31f1758fe4ad1edbef9504ac0116d1ad}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Xiaokang},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0d9c450eb8905fc9a195a67a39e601af}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Wenjun},
           giveni={W\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{4e5d9e5d83d0e26c4d17cce126315705}
      \strng{fullhash}{4f4df664f870c36e53e9c30c581f479c}
      \strng{bibnamehash}{4f4df664f870c36e53e9c30c581f479c}
      \strng{authorbibnamehash}{4f4df664f870c36e53e9c30c581f479c}
      \strng{authornamehash}{4e5d9e5d83d0e26c4d17cce126315705}
      \strng{authorfullhash}{4f4df664f870c36e53e9c30c581f479c}
      \field{extraname}{1}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In a typical image communication system, the visual signal presented to the end users may undergo the steps of acquisition, compression and transmission which cause the artifacts of blurring, quantization and noise. However, the researches of image quality assessment (IQA) with multiple distortion types are very limited. In this paper, we first introduce a new multiply distorted image database (MDID2013), which is composed of 324 images that are simultaneously corrupted by blurring, JPEG compression and noise injection. We then propose a new six-step blind metric (SISBLIM) for quality assessment of both singly and multiply distorted images. Inspired by the early human visual model and recently revealed free energy based brain theory, our method works to systematically combine the single quality prediction of each emerging distortion type and joint effects of different distortion sources. Comparative studies of the proposed SISBLIM with popular full-reference IQA approaches and start-of-the-art no-reference IQA metrics are conducted on five singly distorted image databases (LIVE, TID2008, CSIQ, IVC, Toyama) and two newly released multiply distorted image databases (LIVEMD, MDID2013). Experimental results confirm the effectiveness of our blind technique. MATLAB codes of the proposed SISBLIM algorithm and MDID2013 database will be available online at http://gvsp.sjtu.edu.cn/.}
      \field{issn}{0018-9316, 1557-9611}
      \field{journaltitle}{IEEE Transactions on Broadcasting}
      \field{langid}{english}
      \field{month}{9}
      \field{number}{3}
      \field{shortjournal}{IEEE Trans. on Broadcast.}
      \field{title}{Hybrid {{No-Reference Quality Metric}} for {{Singly}} and {{Multiply Distorted Images}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{60}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{555\bibrangedash 567}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TBC.2014.2344471
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/B4SN597A/Gu et al. - 2014 - Hybrid No-Reference Quality Metric for Singly and .pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/6879255/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/6879255/
      \endverb
    \endentry
    \entry{HSNID}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=a64df0db3d659a7cb92ab2266cdd6339}{%
           family={Gu},
           familyi={G\bibinitperiod},
           given={Ke},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b6fc78834b479731029a5edb14fd5de0}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Xin},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=14f0dd7dfcfc375a1d3a6b42a2c58757}{%
           family={Qiao},
           familyi={Q\bibinitperiod},
           given={Junfei},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a63ef12742ef71a5a06fcf66d6d72ad7}{%
           family={Jiang},
           familyi={J\bibinitperiod},
           given={Qiuping},
           giveni={Q\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ef82e2e99c11391b0d3372d3bf096101}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Weisi},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=24f20de24938c18a3655f419579d0900}{%
           family={Thalmann},
           familyi={T\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{4e5d9e5d83d0e26c4d17cce126315705}
      \strng{fullhash}{3c429fdd3ef0a5700e5721efbe97dd62}
      \strng{bibnamehash}{3c429fdd3ef0a5700e5721efbe97dd62}
      \strng{authorbibnamehash}{3c429fdd3ef0a5700e5721efbe97dd62}
      \strng{authornamehash}{4e5d9e5d83d0e26c4d17cce126315705}
      \strng{authorfullhash}{3c429fdd3ef0a5700e5721efbe97dd62}
      \field{extraname}{2}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this work, we resolve a big challenge that most current image quality metrics (IQMs) are unavailable across different image contents, especially simultaneously coping with natural scene (NS) images or screen content (SC) images. By comparison with existing works, this paper deploys on-line and off-line data for proposing a unified no-reference (NR) IQM, not only applied to different distortion types and intensities but also to various image contents including classical NS images and prevailing SC images. Our proposed NR IQM is developed with two data-driven learning processes following feature extraction, which is based on scene statistic models, free-energy brain principle, and human visual system (HVS) characteristics. In the first process, the scene statistic models and an image retrieve technique are combined, based on on-line and off-line training instances, to derive a novel loose classifier for retrieving clean images and helping to infer the image content. In the second process, the features extracted by incorporating the inferred image content, free-energy and low-level perceptual characteristics of the HVS are learned by utilizing off-line training samples to analyze the distortion types and intensities and thereby to predict the image quality. The two processes mentioned above depend on a gigantic quantity of training data, much exceeding the number of images applied to performance validation, and thus make our model’s performance more reliable. Through extensive experiments, it has been validated that the proposed blind IQM is capable of simultaneously inferring the quality of NS and SC images, and it has attained superior performance as compared with popular and state-of-the-art IQMs on the subjective NS and SC image quality databases. The source code of our model will be released with the publication of the paper at https://kegu.netlify.com.}
      \field{day}{1}
      \field{issn}{2332-7790, 2372-2096}
      \field{journaltitle}{IEEE Transactions on Big Data}
      \field{langid}{english}
      \field{month}{12}
      \field{number}{4}
      \field{shortjournal}{IEEE Trans. Big Data}
      \field{title}{Learning a {{Unified Blind Image Quality Metric}} via {{On-Line}} and {{Off-Line Big Training Instances}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{6}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{780\bibrangedash 791}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/TBDATA.2019.2895605
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/8K778KAQ/Gu et al. - 2020 - Learning a Unified Blind Image Quality Metric via .pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8627983/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8627983/
      \endverb
    \endentry
    \entry{DesignThinking}{book}{}
      \name{editor}{5}{}{%
        {{un=0,uniquepart=base,hash=3256cddf77f82c7ebb20075626add887}{%
           family={Hoffmann},
           familyi={H\bibinitperiod},
           given={Christian\bibnamedelima Pieter},
           giveni={C\bibinitperiod\bibinitdelim P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0b49b3c14a19de344828832bdac60c0c}{%
           family={Lennerts},
           familyi={L\bibinitperiod},
           given={Silke},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2bdad7fccb2d18293bf3a170825f79e9}{%
           family={Schmitz},
           familyi={S\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8babc848fff930512f3b1874b79ea55e}{%
           family={Stölzle},
           familyi={S\bibinitperiod},
           given={Wolfgang},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3df7861ab18004fde039801677b379cf}{%
           family={Uebernickel},
           familyi={U\bibinitperiod},
           given={Falk},
           giveni={F\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Wiesbaden}%
      }
      \list{publisher}{1}{%
        {Springer Fachmedien Wiesbaden}%
      }
      \strng{namehash}{f61c76cafc5705d4bbc20230cdeb2886}
      \strng{fullhash}{58012356417ad9a435c599f385d6bcb1}
      \strng{bibnamehash}{58012356417ad9a435c599f385d6bcb1}
      \strng{editorbibnamehash}{58012356417ad9a435c599f385d6bcb1}
      \strng{editornamehash}{f61c76cafc5705d4bbc20230cdeb2886}
      \strng{editorfullhash}{58012356417ad9a435c599f385d6bcb1}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{editor}
      \field{labeltitlesource}{shorttitle}
      \field{langid}{english}
      \field{shorttitle}{Business {{Innovation}}}
      \field{title}{Business {{Innovation}}: {{Das St}}. {{Galler Modell}}}
      \field{urlday}{29}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2016}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.1007/978-3-658-07167-7
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/EAEZ5T5N/Hoffmann et al. - 2016 - Business Innovation Das St. Galler Modell.pdf
      \endverb
      \verb{urlraw}
      \verb https://link.springer.com/10.1007/978-3-658-07167-7
      \endverb
      \verb{url}
      \verb https://link.springer.com/10.1007/978-3-658-07167-7
      \endverb
    \endentry
    \entry{ImageQX}{online}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=8befab1f4adfe07956f09ed4f2229e2e}{%
           family={Jalaboi},
           familyi={J\bibinitperiod},
           given={Raluca},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7862b9aae6d622aee37d7b62ba9450e7}{%
           family={Winther},
           familyi={W\bibinitperiod},
           given={Ole},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3c84f09b7c007ffaea13e97c783dc97e}{%
           family={Galimzianova},
           familyi={G\bibinitperiod},
           given={Alfiia},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{20b41d73e4f5671db0dfb9cfd9363442}
      \strng{fullhash}{da3df0de5748984ae7a39a4a27c94ed7}
      \strng{bibnamehash}{da3df0de5748984ae7a39a4a27c94ed7}
      \strng{authorbibnamehash}{da3df0de5748984ae7a39a4a27c94ed7}
      \strng{authornamehash}{20b41d73e4f5671db0dfb9cfd9363442}
      \strng{authorfullhash}{da3df0de5748984ae7a39a4a27c94ed7}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Image quality is a crucial factor in the effectiveness and efficiency of teledermatological consultations. However, up to 50\% of images sent by patients have quality issues, thus increasing the time to diagnosis and treatment. An automated, easily deployable, explainable method for assessing image quality is necessary to improve the current teledermatological consultation flow. We introduce ImageQX, a convolutional neural network for image quality assessment with a learning mechanism for identifying the most common poor image quality explanations: bad framing, bad lighting, blur, low resolution, and distance issues. ImageQX was trained on 26,635 photographs and validated on 9,874 photographs, each annotated with image quality labels and poor image quality explanations by up to 12 board-certified dermatologists. The photographic images were taken between 2017 and 2019 using a mobile skin disease tracking application accessible worldwide. Our method achieves expert-level performance for both image quality assessment and poor image quality explanation. For image quality assessment, ImageQX obtains a macro F1-score of 0.73 ± 0.01, which places it within standard deviation of the pairwise inter-rater F1-score of 0.77 ± 0.07. For poor image quality explanations, our method obtains F1-scores of between 0.37 ± 0.01 and 0.70 ± 0.01, similar to the inter-rater pairwise F1-score of between 0.24 ± 0.15 and 0.83 ± 0.06. Moreover, with a size of only 15 MB, ImageQX is easily deployable on mobile devices. With an image quality detection performance similar to that of dermatologists, incorporating ImageQX into the teledermatology flow can enable a better, faster flow for remote consultations.}
      \field{day}{23}
      \field{eprintclass}{cs}
      \field{eprinttype}{arxiv}
      \field{langid}{english}
      \field{month}{1}
      \field{title}{Explainable {{Image Quality Assessments}} in {{Teledermatological Photography}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2209.04699
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/5JFM3Q9H/Jalaboi et al. - 2023 - Explainable Image Quality Assessments in Telederma.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2209.04699
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2209.04699
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
    \endentry
    \entry{LIVEMD}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=cd27d3d228b115c84bc1d88310a81f02}{%
           family={Jayaraman},
           familyi={J\bibinitperiod},
           given={Dinesh},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5140f90dfa1ff2db127d5ad357e881ea}{%
           family={Mittal},
           familyi={M\bibinitperiod},
           given={Anish},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0637cd6093dcea240cdcb122b300761b}{%
           family={Moorthy},
           familyi={M\bibinitperiod},
           given={Anush\bibnamedelima K.},
           giveni={A\bibinitperiod\bibinitdelim K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d9c2ab9a8cbcab08292923a454c88ce7}{%
           family={Bovik},
           familyi={B\bibinitperiod},
           given={Alan\bibnamedelima C.},
           giveni={A\bibinitperiod\bibinitdelim C\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Pacific Grove, CA, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{b9473887aa8ef09533091798c76022ef}
      \strng{fullhash}{8fb566e1d8b66be5dca6b5531931decd}
      \strng{bibnamehash}{8fb566e1d8b66be5dca6b5531931decd}
      \strng{authorbibnamehash}{8fb566e1d8b66be5dca6b5531931decd}
      \strng{authornamehash}{b9473887aa8ef09533091798c76022ef}
      \strng{authorfullhash}{8fb566e1d8b66be5dca6b5531931decd}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Subjective studies have been conducted in the past to obtain human judgments of visual quality on distorted images in order, among other things, to benchmark objective image qual. ity assessment (lQA) algorithms. Existing subjective studies primarily have records of human ratings on images that were corrupted by only one of many possible distortions. However, the majority of images that are available for consumption are corrupted by multiple distortions. Towards broadening the corpora of records of human responses to visual distortions, we recently conducted a study on two types of multiply distorted images to obtain human judgments of the visual quality of such images. Further, we compared the performance of several existing objective image quality measures on the new database and analyze the effects of multiple distortions on commonly used quality-determinant features and on human ratings.}
      \field{eventtitle}{2012 46th {{Asilomar Conference}} on {{Signals}}, {{Systems}} and {{Computers}}}
      \field{journaltitle}{2012 {{Conference Record}} of the {{Forty Sixth Asilomar Conference}} on {{Signals}}, {{Systems}} and {{Computers}} ({{ASILOMAR}})}
      \field{langid}{english}
      \field{month}{11}
      \field{title}{Objective Quality Assessment of Multiply Distorted Images}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2012}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1693\bibrangedash 1697}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/ACSSC.2012.6489321
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/XIL22H3U/Jayaraman et al. - 2012 - Objective quality assessment of multiply distorted.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6489321/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6489321/
      \endverb
    \endentry
    \entry{Derm7pt}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=da947d3afb637b7e27cbc33776cce543}{%
           family={Kawahara},
           familyi={K\bibinitperiod},
           given={Jeremy},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=33dca317433f473bebf123d208ea18c0}{%
           family={Daneshvar},
           familyi={D\bibinitperiod},
           given={Sara},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=240f6e7e4d9967c0fa69aea0c1c382d9}{%
           family={Argenziano},
           familyi={A\bibinitperiod},
           given={Giuseppe},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=061eb4eb95e9947e4010093d17626dd1}{%
           family={Hamarneh},
           familyi={H\bibinitperiod},
           given={Ghassan},
           giveni={G\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{659c1fdbf8a702920ba2f2085730c412}
      \strng{fullhash}{c1226c3bec07be6aed0a3fb6c8556555}
      \strng{bibnamehash}{c1226c3bec07be6aed0a3fb6c8556555}
      \strng{authorbibnamehash}{c1226c3bec07be6aed0a3fb6c8556555}
      \strng{authornamehash}{659c1fdbf8a702920ba2f2085730c412}
      \strng{authorfullhash}{c1226c3bec07be6aed0a3fb6c8556555}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a multitask deep convolutional neural network, trained on multimodal data (clinical and dermoscopic images, and patient metadata), to classify the 7-point melanoma checklist criteria and perform skin lesion diagnosis. Our neural network is trained using several multitask loss functions, where each loss considers different combinations of the input modalities, which allows our model to be robust to missing data at inference time. Our final model classifies the 7-point checklist and skin condition diagnosis, produces multimodal feature vectors suitable for image retrieval, and localizes clinically discriminant regions. We benchmark our approach using 1011 lesion cases, and report comprehensive results over all 7-point criteria and diagnosis. We also make our dataset (images and metadata) publicly available online at http://derm.cs.sfu.ca.}
      \field{issn}{2168-2194, 2168-2208}
      \field{journaltitle}{IEEE Journal of Biomedical and Health Informatics}
      \field{langid}{english}
      \field{month}{3}
      \field{number}{2}
      \field{shortjournal}{IEEE J. Biomed. Health Inform.}
      \field{title}{Seven-{{Point Checklist}} and {{Skin Lesion Classification Using Multitask Multimodal Neural Nets}}}
      \field{urlday}{28}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{23}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{538\bibrangedash 546}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1109/JBHI.2018.2824327
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/X3NDWJDI/Kawahara et al. - 2019 - Seven-Point Checklist and Skin Lesion Classificati.pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8333693/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8333693/
      \endverb
    \endentry
    \entry{WED}{article}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=79f9b1044b245e49f7e431dfc1b96bbd}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Kede},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9aec47e12e3d6fbc7bdca7a5da683262}{%
           family={Duanmu},
           familyi={D\bibinitperiod},
           given={Zhengfang},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c39472ae48abeae16b94f055c782c3fe}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Qingbo},
           giveni={Q\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f244e8ae5eff7776cf2b4b5b84ad8c4a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhou},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a145467fa9fec4f93e60603bdd640271}{%
           family={Yong},
           familyi={Y\bibinitperiod},
           given={Hongwei},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a549968ccfc4003d90c1ffd4a9ff5a05}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Hongliang},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f4a4cbf770add19c206827116c68732e}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Lei},
           giveni={L\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{629b9403529af15b56742c449f643c2d}
      \strng{fullhash}{19823db61e86416d5dafd1eee1bf3ab2}
      \strng{bibnamehash}{19823db61e86416d5dafd1eee1bf3ab2}
      \strng{authorbibnamehash}{19823db61e86416d5dafd1eee1bf3ab2}
      \strng{authornamehash}{629b9403529af15b56742c449f643c2d}
      \strng{authorfullhash}{19823db61e86416d5dafd1eee1bf3ab2}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The great content diversity of real-world digital images poses a grand challenge to image quality assessment (IQA) models, which are traditionally designed and validated on a handful of commonly used IQA databases with very limited content variation. To test the generalization capability and to facilitate the wide usage of IQA techniques in real-world applications, we establish a large-scale database named the Waterloo Exploration Database, which in its current state contains 4744 pristine natural images and 94 880 distorted images created from them. Instead of collecting the mean opinion score for each image via subjective testing, which is extremely difficult if not impossible, we present three alternative test criteria to evaluate the performance of IQA models, namely, the pristine/distorted image discriminability test, the listwise ranking consistency test, and the pairwise preference consistency test (P-test). We compare 20 well-known IQA models using the proposed criteria, which not only provide a stronger test in a more challenging testing environment for existing models, but also demonstrate the additional benefits of using the proposed database. For example, in the P-test, even for the best performing no-reference IQA model, more than 6 million failure cases against the model are “discovered” automatically out of over 1 billion test pairs. Furthermore, we discuss how the new database may be exploited using innovative approaches in the future, to reveal the weaknesses of existing IQA models, to provide insights on how to improve the models, and to shed light on how the next-generation IQA models may be developed. The database and codes are made publicly available at: https://ece.uwaterloo.ca/\textasciitilde k29ma/exploration/.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{2}
      \field{number}{2}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{shorttitle}{Waterloo {{Exploration Database}}}
      \field{title}{Waterloo {{Exploration Database}}: {{New Challenges}} for {{Image Quality Assessment Models}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{26}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1004\bibrangedash 1016}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TIP.2016.2631888
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/CZGVWNWD/Ma et al. - 2017 - Waterloo Exploration Database New Challenges for .pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/7752930/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/7752930/
      \endverb
    \endentry
    \entry{CCT}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=2f8448dbface32ad773f9ade4399a3f6}{%
           family={Min},
           familyi={M\bibinitperiod},
           given={Xiongkuo},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=79f9b1044b245e49f7e431dfc1b96bbd}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Kede},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a64df0db3d659a7cb92ab2266cdd6339}{%
           family={Gu},
           familyi={G\bibinitperiod},
           given={Ke},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=de70ef50dd45ba84349c3a3d3d5a9141}{%
           family={Zhai},
           familyi={Z\bibinitperiod},
           given={Guangtao},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f244e8ae5eff7776cf2b4b5b84ad8c4a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhou},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ef82e2e99c11391b0d3372d3bf096101}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Weisi},
           giveni={W\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b5956eea704a1bf19d70dfa9e1835ec0}
      \strng{fullhash}{62389347e63997afa9f42a66fd9abb81}
      \strng{bibnamehash}{62389347e63997afa9f42a66fd9abb81}
      \strng{authorbibnamehash}{62389347e63997afa9f42a66fd9abb81}
      \strng{authornamehash}{b5956eea704a1bf19d70dfa9e1835ec0}
      \strng{authorfullhash}{62389347e63997afa9f42a66fd9abb81}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Digital images in the real world are created by a variety of means and have diverse properties. A photographical natural scene image (NSI) may exhibit substantially different characteristics from a computer graphic image (CGI) or a screen content image (SCI). This casts major challenges to objective image quality assessment, for which existing approaches lack effective mechanisms to capture such content type variations, and thus are difficult to generalize from one type to another. To tackle this problem, we first construct a cross-content-type (CCT) database, which contains 1,320 distorted NSIs, CGIs, and SCIs, compressed using the high efficiency video coding (HEVC) intra coding method and the screen content compression (SCC) extension of HEVC. We then carry out a subjective experiment on the database in a well-controlled laboratory environment. Moreover, we propose a unified content-type adaptive (UCA) blind image quality assessment model that is applicable across content types. A key step in UCA is to incorporate the variations of human perceptual characteristics in viewing different content types through a multi-scale weighting framework. This leads to superior performance on the constructed CCT database. UCA is training-free, implying strong generalizability. To verify this, we test UCA on other databases containing JPEG, MPEG-2, H.264, and HEVC compressed images/videos, and observe that it consistently achieves competitive performance.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{11}
      \field{number}{11}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{title}{Unified {{Blind Quality Assessment}} of {{Compressed Natural}}, {{Graphic}}, and {{Screen Content Images}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{26}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{5462\bibrangedash 5474}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TIP.2017.2735192
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/FCJP6NPM/Min et al. - 2017 - Unified Blind Quality Assessment of Compressed Nat.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/8000398/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/8000398/
      \endverb
    \endentry
    \entry{SCIQ}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=9c42300b0b3bbf9827ee4a6c487490c7}{%
           family={Ni},
           familyi={N\bibinitperiod},
           given={Zhangkai},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8601659a37cae9b8932645c653921e5b}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Lin},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6b78353626b7ef8b21555f733da16b90}{%
           family={Zeng},
           familyi={Z\bibinitperiod},
           given={Huanqiang},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=11c05b885f1bc92570da26e49722e81d}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Jing},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=303437312f7cdcac2a16a360f776ae19}{%
           family={Cai},
           familyi={C\bibinitperiod},
           given={Canhui},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cd16103d76b32c3a006e7b7ad54f13c5}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Kai-Kuang},
           giveni={K\bibinithyphendelim K\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{6c4a826b8d6c30eb9890ddf80eedeb09}
      \strng{fullhash}{25988e9cf43c1bdbd64c9a3e1fd02cfc}
      \strng{bibnamehash}{25988e9cf43c1bdbd64c9a3e1fd02cfc}
      \strng{authorbibnamehash}{25988e9cf43c1bdbd64c9a3e1fd02cfc}
      \strng{authornamehash}{6c4a826b8d6c30eb9890ddf80eedeb09}
      \strng{authorfullhash}{25988e9cf43c1bdbd64c9a3e1fd02cfc}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In this paper, an accurate full-reference image quality assessment (IQA) model developed for assessing screen content images (SCIs), called the edge similarity (ESIM), is proposed. It is inspired by the fact that the human visual system (HVS) is highly sensitive to edges that are often encountered in SCIs; therefore, essential edge features are extracted and exploited for conducting IQA for the SCIs. The key novelty of the proposed ESIM lies in the extraction and use of three salient edge features—i.e., edge contrast, edge width, and edge direction. The first two attributes are simultaneously generated from the input SCI based on a parametric edge model, while the last one is derived directly from the input SCI. The extraction of these three features will be performed for the reference SCI and the distorted SCI, individually. The degree of similarity measured for each above-mentioned edge attribute is then computed independently, followed by combining them together using our proposed edge-width pooling strategy to generate the final ESIM score. To conduct the performance evaluation of our proposed ESIM model, a new and the largest SCI database (denoted as SCID) is established in our work and made to the public for download. Our database contains 1800 distorted SCIs that are generated from 40 reference SCIs. For each SCI, nine distortion types are investigated, and five degradation levels are produced for each distortion type. Extensive simulation results have clearly shown that the proposed ESIM model is more consistent with the perception of the HVS on the evaluation of distorted SCIs than the multiple state-of-the-art IQA methods.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{10}
      \field{number}{10}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{shorttitle}{{{ESIM}}}
      \field{title}{{{ESIM}}: {{Edge Similarity}} for {{Screen Content Image Quality Assessment}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{26}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{4818\bibrangedash 4831}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1109/TIP.2017.2718185
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/KUNRFCHU/Ni et al. - 2017 - ESIM Edge Similarity for Screen Content Image Qua.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/7954714/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/7954714/
      \endverb
    \endentry
    \entry{PAD-UFES-20}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=d9fef9544610b0b771a7c79d6e4087ec}{%
           family={Pacheco},
           familyi={P\bibinitperiod},
           given={Andre\bibnamedelima G.C.},
           giveni={A\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a71b4c6ee0af0a5030c2d47206795bf3}{%
           family={Krohling},
           familyi={K\bibinitperiod},
           given={Renato\bibnamedelima A.},
           giveni={R\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{086a5903b7cd94f3f3b4c8b062f70c43}
      \strng{fullhash}{086a5903b7cd94f3f3b4c8b062f70c43}
      \strng{bibnamehash}{086a5903b7cd94f3f3b4c8b062f70c43}
      \strng{authorbibnamehash}{086a5903b7cd94f3f3b4c8b062f70c43}
      \strng{authornamehash}{086a5903b7cd94f3f3b4c8b062f70c43}
      \strng{authorfullhash}{086a5903b7cd94f3f3b4c8b062f70c43}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Skin cancer is one of the most common types of cancer worldwide. Over the past few years, different approaches have been proposed to deal with automated skin cancer detection. Nonetheless, most of them are based only on dermoscopic images and do not take into account the patient clinical information, an important clue towards clinical diagnosis. In this work, we present an approach to fill this gap. First, we introduce a new dataset composed of clinical images, collected using smartphones, and clinical data related to the patient. Next, we propose a straightforward method that includes an aggregation mechanism in well-known deep learning models to combine features from images and clinical data. Last, we carry out experiments to compare the models’ performance with and without using this mechanism. The results present an improvement of approximately 7\% in balanced accuracy when the aggregation method is applied. Overall, the impact of clinical data on models’ performance is significant and shows the importance of including these features on automated skin cancer detection.}
      \field{issn}{00104825}
      \field{journaltitle}{Computers in Biology and Medicine}
      \field{langid}{english}
      \field{month}{1}
      \field{shortjournal}{Computers in Biology and Medicine}
      \field{title}{The Impact of Patient Clinical Information on Automated Skin Cancer Detection}
      \field{urlday}{28}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{116}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{103545}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1016/j.compbiomed.2019.103545
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/8GRBMVLI/Pacheco und Krohling - 2020 - The impact of patient clinical information on auto.pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0010482519304019
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0010482519304019
      \endverb
    \endentry
    \entry{TID2008}{article}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=6b0ff13763f4a453b1d67bcef505c432}{%
           family={Ponomarenko},
           familyi={P\bibinitperiod},
           given={Nikolay},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fb49a7d26e4975bcb180af4a1fb7c99c}{%
           family={Lukin},
           familyi={L\bibinitperiod},
           given={Vladimir},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=666e9bd7b942482665d8772f7b7971bb}{%
           family={Zelensky},
           familyi={Z\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=72943da991b92fae8d3fcb28a3080793}{%
           family={Egiazarian},
           familyi={E\bibinitperiod},
           given={Karen},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4e0efd455d29950438dd83f5832f2921}{%
           family={Astola},
           familyi={A\bibinitperiod},
           given={Jaakko},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f63fd57cf4abe0aec29baf824c417de2}{%
           family={Carli},
           familyi={C\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=98456d3cec333fcf3f72e5a9a98bebba}{%
           family={Battisti},
           familyi={B\bibinitperiod},
           given={Federica},
           giveni={F\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{eaa11fffd3aeed1bc200d020c1b222b5}
      \strng{fullhash}{83f7028eeea63dc208b91cb2fa48a4c0}
      \strng{bibnamehash}{83f7028eeea63dc208b91cb2fa48a4c0}
      \strng{authorbibnamehash}{83f7028eeea63dc208b91cb2fa48a4c0}
      \strng{authornamehash}{eaa11fffd3aeed1bc200d020c1b222b5}
      \strng{authorfullhash}{83f7028eeea63dc208b91cb2fa48a4c0}
      \field{extraname}{1}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, a new image database, TID2008, for evaluation of full-reference visual quality assessment metrics is described. It contains 1700 test images (25 reference images, 17 types of distortions for each reference image, 4 different levels of each type of distortion). Mean Opinion Scores (MOS) for this database have been obtained as a result of more than 800 experiments. During these tests, observers from three countries (Finland, Italy, and Ukraine) have carried out about 256000 individual human quality judgments. The obtained MOS can be used for effective testing of different visual quality metrics as well as for the design of new metrics. Using the designed image database, we have tested several known quality metrics. The designed test image database is freely available for downloading and utilization in scientific investigations.}
      \field{langid}{english}
      \field{month}{1}
      \field{title}{{{TID2008}} – {{A Database}} for {{Evaluation}} of {{Full- Reference Visual Quality Assessment Metrics}}}
      \field{year}{2009}
      \field{dateera}{ce}
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/M93CPMPI/Ponomarenko et al. - TID2008 – A Database for Evaluation of Full- Refer.pdf
      \endverb
    \endentry
    \entry{TID2013}{article}{}
      \name{author}{11}{}{%
        {{un=0,uniquepart=base,hash=6b0ff13763f4a453b1d67bcef505c432}{%
           family={Ponomarenko},
           familyi={P\bibinitperiod},
           given={Nikolay},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=907fb6d00ff75c72b6d853ef1774f7f3}{%
           family={Jin},
           familyi={J\bibinitperiod},
           given={Lina},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1fe31832eb20800c7cd39d1cad85d7c9}{%
           family={Ieremeiev},
           familyi={I\bibinitperiod},
           given={Oleg},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fb49a7d26e4975bcb180af4a1fb7c99c}{%
           family={Lukin},
           familyi={L\bibinitperiod},
           given={Vladimir},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=72943da991b92fae8d3fcb28a3080793}{%
           family={Egiazarian},
           familyi={E\bibinitperiod},
           given={Karen},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4e0efd455d29950438dd83f5832f2921}{%
           family={Astola},
           familyi={A\bibinitperiod},
           given={Jaakko},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4a4f6b7f29f29613b2d443fbb6c58666}{%
           family={Vozel},
           familyi={V\bibinitperiod},
           given={Benoit},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=66695ef8124fdf52d033aff69af5bcae}{%
           family={Chehdi},
           familyi={C\bibinitperiod},
           given={Kacem},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f63fd57cf4abe0aec29baf824c417de2}{%
           family={Carli},
           familyi={C\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=98456d3cec333fcf3f72e5a9a98bebba}{%
           family={Battisti},
           familyi={B\bibinitperiod},
           given={Federica},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c0aab84e5274fd7546e004e63d60f04e}{%
           family={Jay\bibnamedelima Kuo},
           familyi={J\bibinitperiod\bibinitdelim K\bibinitperiod},
           given={C.-C.},
           giveni={C\bibinithyphendelim C\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{eaa11fffd3aeed1bc200d020c1b222b5}
      \strng{fullhash}{4e34179dbf744081b7a35d5b2fa6931a}
      \strng{bibnamehash}{4e34179dbf744081b7a35d5b2fa6931a}
      \strng{authorbibnamehash}{4e34179dbf744081b7a35d5b2fa6931a}
      \strng{authornamehash}{eaa11fffd3aeed1bc200d020c1b222b5}
      \strng{authorfullhash}{4e34179dbf744081b7a35d5b2fa6931a}
      \field{extraname}{2}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper describes a recently created image database, TID2013, intended for evaluation of full-reference visual quality assessment metrics. With respect to TID2008, the new database contains a larger number (3000) of test images obtained from 25 reference images, 24 types of distortions for each reference image, and 5 levels for each type of distortion. Motivations for introducing 7 new types of distortions and one additional level of distortions are given; examples of distorted images are presented. Mean opinion scores (MOS) for the new database have been collected by performing 985 subjective experiments with volunteers (observers) from five countries (Finland, France, Italy, Ukraine, and USA). The availability of MOS allows the use of the designed database as a fundamental tool for assessing the effectiveness of visual quality. Furthermore, existing visual quality metrics have been tested with the proposed database and the collected results have been analyzed using rank order correlation coefficients between MOS and considered metrics. These correlation indices have been obtained both considering the full set of distorted images and specific image subsets, for highlighting advantages and drawbacks of existing, state of the art, quality metrics. Approaches to thorough performance analysis for a given metric are presented to detect practical situations or distortion types for which this metric is not adequate enough to human perception. The created image database and the collected MOS values are freely available for downloading and utilization for scientific purposes.}
      \field{issn}{09235965}
      \field{journaltitle}{Signal Processing: Image Communication}
      \field{langid}{english}
      \field{month}{1}
      \field{shortjournal}{Signal Processing: Image Communication}
      \field{shorttitle}{Image Database {{TID2013}}}
      \field{title}{Image Database {{TID2013}}: {{Peculiarities}}, Results and Perspectives}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{30}
      \field{year}{2015}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{57\bibrangedash 77}
      \range{pages}{21}
      \verb{doi}
      \verb 10.1016/j.image.2014.10.009
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/NSWLLPSB/Ponomarenko et al. - 2015 - Image database TID2013 Peculiarities, results and.pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0923596514001490
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0923596514001490
      \endverb
    \endentry
    \entry{LIVE}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=84051ed6c4d99d3ccc763a9bfdfd28a8}{%
           family={Sheikh},
           familyi={S\bibinitperiod},
           given={H.R.},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2334097f18452e6d91139d8b12e6223c}{%
           family={Sabir},
           familyi={S\bibinitperiod},
           given={M.F.},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6192fbf30c45211fdfc67652236bec72}{%
           family={Bovik},
           familyi={B\bibinitperiod},
           given={A.C.},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{60b8bf6e07bbc3f0a1175b5fdca492f2}
      \strng{fullhash}{183b9ff62727cc10f604641f986c09bb}
      \strng{bibnamehash}{183b9ff62727cc10f604641f986c09bb}
      \strng{authorbibnamehash}{183b9ff62727cc10f604641f986c09bb}
      \strng{authornamehash}{60b8bf6e07bbc3f0a1175b5fdca492f2}
      \strng{authorfullhash}{183b9ff62727cc10f604641f986c09bb}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Measurement of visual quality is of fundamental importance for numerous image and video processing applications, where the goal of quality assessment (QA) algorithms is to automatically assess the quality of images or videos in agreement with human quality judgments. Over the years, many researchers have taken different approaches to the problem and have contributed significant research in this area and claim to have made progress in their respective domains. It is important to evaluate the performance of these algorithms in a comparative setting and analyze the strengths and weaknesses of these methods. In this paper, we present results of an extensive subjective quality assessment study in which a total of 779 distorted images were evaluated by about two dozen human subjects. The “ground truth” image quality data obtained from about 25 000 individual human quality judgments is used to evaluate the performance of several prominent full-reference image quality assessment algorithms. To the best of our knowledge, apart from video quality studies conducted by the Video Quality Experts Group, the study presented in this paper is the largest subjective image quality study in the literature in terms of number of images, distortion types, and number of human judgments per image. Moreover, we have made the data from the study freely available to the research community [1]. This would allow other researchers to easily report comparative results in the future.}
      \field{issn}{1057-7149}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{11}
      \field{number}{11}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{title}{A {{Statistical Evaluation}} of {{Recent Full Reference Image Quality Assessment Algorithms}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{15}
      \field{year}{2006}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{3440\bibrangedash 3451}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/TIP.2006.881959
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/8F2JWIAS/Sheikh et al. - 2006 - A Statistical Evaluation of Recent Full Reference .pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/1709988/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/1709988/
      \endverb
    \endentry
    \entry{MDID2016}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=4a71f03f723a983aabae2662ac156d9f}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Wen},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7c8ea78b26e5365d21c23659d9b4f074}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Fei},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=736e79ce2ca1a08fe56752b8e0af07e3}{%
           family={Liao},
           familyi={L\bibinitperiod},
           given={Qingmin},
           giveni={Q\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{f53481d5258202a126a9be4c28902e7f}
      \strng{fullhash}{e720cb32b22801f81c74f57f1eab3b26}
      \strng{bibnamehash}{e720cb32b22801f81c74f57f1eab3b26}
      \strng{authorbibnamehash}{e720cb32b22801f81c74f57f1eab3b26}
      \strng{authornamehash}{f53481d5258202a126a9be4c28902e7f}
      \strng{authorfullhash}{e720cb32b22801f81c74f57f1eab3b26}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In this paper, we present a new database, the multiply distorted image database (MDID), to evaluate image quality assessment (IQA) metrics on multiply distorted images. The database contains 20 reference images and 1600 distorted images. The latter images are obtained by contamination of the former with multiple distortions of random types and levels, so multiple types of distortions appear in each distorted image. Pair comparison sorting (PCS) is used as a new subjective rating method to evaluate image quality. This method allows subjects to make equal decisions on images whose difference in quality cannot be easily evaluated visually. A total of 192 subjects participated in the subjective rating, in which mean opinion scores and standard deviations were obtained. In IQA research, subjective scores and algorithm predictions are generally related by a nonlinear regression. We further propose a method to initialize the parameters of the nonlinear regression. The experiments of IQA metrics conducted on MDID validate that this database is advisable and challenging.}
      \field{issn}{00313203}
      \field{journaltitle}{Pattern Recognition}
      \field{langid}{english}
      \field{month}{1}
      \field{shortjournal}{Pattern Recognition}
      \field{shorttitle}{{{MDID}}}
      \field{title}{{{MDID}}: {{A}} Multiply Distorted Image Database for Image Quality Assessment}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{61}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{153\bibrangedash 168}
      \range{pages}{16}
      \verb{doi}
      \verb 10.1016/j.patcog.2016.07.033
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/JY7KJWKT/Sun et al. - 2017 - MDID A multiply distorted image database for imag.pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0031320316301911
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0031320316301911
      \endverb
    \endentry
    \entry{CID2013}{article}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=615c6826672471ff60b2d75da0020ced}{%
           family={Virtanen},
           familyi={V\bibinitperiod},
           given={Toni},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2c8e334e3ec64237c89b96f6f6dcee30}{%
           family={Nuutinen},
           familyi={N\bibinitperiod},
           given={Mikko},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c68ab1345a264730e85774b5e5fd34a9}{%
           family={Vaahteranoksa},
           familyi={V\bibinitperiod},
           given={Mikko},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=29ea3694c2bb063a2a643f72e5714d79}{%
           family={Oittinen},
           familyi={O\bibinitperiod},
           given={Pirkko},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=80a1211c5bf6d287819b70deed6eb327}{%
           family={Hakkinen},
           familyi={H\bibinitperiod},
           given={Jukka},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{e24786bd08b9de7985bad8323d0b8513}
      \strng{fullhash}{cc14904a43c60badb56949cfec98d6b1}
      \strng{bibnamehash}{cc14904a43c60badb56949cfec98d6b1}
      \strng{authorbibnamehash}{cc14904a43c60badb56949cfec98d6b1}
      \strng{authornamehash}{e24786bd08b9de7985bad8323d0b8513}
      \strng{authorfullhash}{cc14904a43c60badb56949cfec98d6b1}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper presents a new database, CID2013, to address the issue of using no-reference (NR) image quality assessment algorithms on images with multiple distortions. Current NR algorithms struggle to handle images with many concurrent distortion types, such as real photographic images captured by different digital cameras. The database consists of six image sets; on average, 30 subjects have evaluated 12–14 devices depicting eight different scenes for a total of 79 different cameras, 480 images, and 188 subjects (67\% female). The subjective evaluation method was a hybrid absolute category rating-pair comparison developed for the study and presented in this paper. This method utilizes a slideshow of all images within a scene to allow the test images to work as references to each other. In addition to mean opinion score value, the images are also rated using sharpness, graininess, lightness, and color saturation scales. The CID2013 database contains images used in the experiments with the full subjective data plus extensive background information from the subjects. The database is made freely available for the research community.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{shorttitle}{{{CID2013}}}
      \field{title}{{{CID2013}}: {{A Database}} for {{Evaluating No-Reference Image Quality Assessment Algorithms}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{24}
      \field{year}{2015}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{390\bibrangedash 402}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TIP.2014.2378061
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/KHXSACRZ/Virtanen et al. - 2015 - CID2013 A Database for Evaluating No-Reference Im.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6975172/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6975172/
      \endverb
    \endentry
    \entry{TrueImage}{online}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=727a8a479e533213d5df986b6f2d695e}{%
           family={Vodrahalli},
           familyi={V\bibinitperiod},
           given={Kailas},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0df7931cf6d169c0892a3a00ce803ffa}{%
           family={Daneshjou},
           familyi={D\bibinitperiod},
           given={Roxana},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7dcf7c517335b316301b5a23b218557b}{%
           family={Novoa},
           familyi={N\bibinitperiod},
           given={Roberto\bibnamedelima A.},
           giveni={R\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f8bf81fdd5ba316aafc4d84f3492fdc6}{%
           family={Chiou},
           familyi={C\bibinitperiod},
           given={Albert},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fafb26071e10025682d74122178dcdc3}{%
           family={Ko},
           familyi={K\bibinitperiod},
           given={Justin\bibnamedelima M.},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1b868d50048a635fa27ffa744323fa41}{%
           family={Zou},
           familyi={Z\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{5d4a1468e52078d03ee41bac58856ba8}
      \strng{fullhash}{1ff7a5aba214426ed147e083823e40b6}
      \strng{bibnamehash}{1ff7a5aba214426ed147e083823e40b6}
      \strng{authorbibnamehash}{1ff7a5aba214426ed147e083823e40b6}
      \strng{authornamehash}{5d4a1468e52078d03ee41bac58856ba8}
      \strng{authorfullhash}{1ff7a5aba214426ed147e083823e40b6}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Telehealth is an increasingly critical component of the health care ecosystem, especially due to the COVID-19 pandemic. Rapid adoption of telehealth has exposed limitations in the existing infrastructure. In this paper, we study and highlight photo quality as a major challenge in the telehealth workflow. We focus on teledermatology, where photo quality is particularly important; the framework proposed here can be generalized to other health domains. For telemedicine, dermatologists request that patients submit images of their lesions for assessment. However, these images are often of insufficient quality to make a clinical diagnosis since patients do not have experience taking clinical photos. A clinician has to manually triage poor quality images and request new images to be submitted, leading to wasted time for both the clinician and the patient. We propose an automated image assessment machine learning pipeline, TrueImage, to detect poor quality dermatology photos and to guide patients in taking better photos. Our experiments indicate that TrueImage can reject 50\% of the sub-par quality images, while retaining 80\% of good quality images patients send in, despite heterogeneity and limitations in the training data. These promising results suggest that our solution is feasible and can improve the quality of teledermatology care.}
      \field{day}{1}
      \field{eprintclass}{cs, eess}
      \field{eprinttype}{arxiv}
      \field{month}{10}
      \field{shorttitle}{{{TrueImage}}}
      \field{title}{{{TrueImage}}: {{A Machine Learning Algorithm}} to {{Improve}} the {{Quality}} of {{Telehealth Photos}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2010.02086
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/ZHAJZ8H3/Vodrahalli et al. - 2020 - TrueImage A Machine Learning Algorithm to Improve.pdf;/Users/choekyelnyungmartsang/Zotero/storage/J95RUXP7/2010.html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2010.02086
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2010.02086
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Computers and Society,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Signal Processing}
    \endentry
    \entry{SCIN}{online}{}
      \name{author}{20}{}{%
        {{un=0,uniquepart=base,hash=157eeb7ce96413ee755bd0cfc3fd3171}{%
           family={Ward},
           familyi={W\bibinitperiod},
           given={Abbi},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=968d50258df8e602bdff89292ed04f7e}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Jimmy},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=74ed6c812a6076b83c7d60b4ed25c56b}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Julie},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3594b4311617d31637c712574c23a86a}{%
           family={Lakshminarasimhan},
           familyi={L\bibinitperiod},
           given={Sriram},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6b651bbe7b5a39a7d2c8f18e8c23ffa3}{%
           family={Carrick},
           familyi={C\bibinitperiod},
           given={Ashley},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b8b84659f2ef971f9084812de41a996d}{%
           family={Campana},
           familyi={C\bibinitperiod},
           given={Bilson},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=63a749c918287d0d110056a35fefab13}{%
           family={Hartford},
           familyi={H\bibinitperiod},
           given={Jay},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9378442568d686a831bd5825320c1ef1}{%
           family={S},
           familyi={S\bibinitperiod},
           given={Pradeep\bibnamedelima Kumar},
           giveni={P\bibinitperiod\bibinitdelim K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3e3132e6f6ad493ee0ea0ddc316159b7}{%
           family={Tiyasirichokchai},
           familyi={T\bibinitperiod},
           given={Tiya},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=191bc273a5f531232c05b746f242e5ef}{%
           family={Virmani},
           familyi={V\bibinitperiod},
           given={Sunny},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0ef6f4906fe6a3689db39f9ba23e0753}{%
           family={Wong},
           familyi={W\bibinitperiod},
           given={Renee},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=46fb71a11e070da3ec8e9ff62a75ddef}{%
           family={Matias},
           familyi={M\bibinitperiod},
           given={Yossi},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=84d9f354fa0b45dae996f27dad2c6607}{%
           family={Corrado},
           familyi={C\bibinitperiod},
           given={Greg\bibnamedelima S.},
           giveni={G\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d38a80bf82831fe5c4d0f850a77ddff9}{%
           family={Webster},
           familyi={W\bibinitperiod},
           given={Dale\bibnamedelima R.},
           giveni={D\bibinitperiod\bibinitdelim R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a6468eba3b866893d49ff041b27ebc90}{%
           family={Siegel},
           familyi={S\bibinitperiod},
           given={Dawn},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d1a8967b0a24afdb7417d43b5c02a5fe}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Steven},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d5274c1d02c20ebd471b200127fcee09}{%
           family={Ko},
           familyi={K\bibinitperiod},
           given={Justin},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=45aacfb5c7248e226c7bc1188c1e4e00}{%
           family={Karthikesalingam},
           familyi={K\bibinitperiod},
           given={Alan},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9ee01be967ae8313a09a6ac2ac566cfa}{%
           family={Semturs},
           familyi={S\bibinitperiod},
           given={Christopher},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=237ccb6307c5f44294cf3c1a86f20f37}{%
           family={Rao},
           familyi={R\bibinitperiod},
           given={Pooja},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{3c84a7ffa1295ec35976dd43530332b3}
      \strng{fullhash}{edfdba1ab1637c9e2621d6b53c909a62}
      \strng{bibnamehash}{edfdba1ab1637c9e2621d6b53c909a62}
      \strng{authorbibnamehash}{edfdba1ab1637c9e2621d6b53c909a62}
      \strng{authornamehash}{3c84a7ffa1295ec35976dd43530332b3}
      \strng{authorfullhash}{edfdba1ab1637c9e2621d6b53c909a62}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Background: Health datasets from clinical sources do not reflect the breadth and diversity of disease in the real world, impacting research, medical education, and artificial intelligence (AI) tool development. Dermatology is a suitable area to develop and test a new and scalable method to create representative health datasets. Methods: We used Google Search advertisements to invite contributions to an open access dataset of images of dermatology conditions, demographic, and symptom information. With informed contributor consent, we describe and release this dataset containing 10,408 images from 5,033 contributions from internet users in the United States over 8 months starting March 2023. The dataset includes dermatologist condition labels as well as estimated Fitzpatrick Skin Type (eFST) and Monk Skin Tone (eMST) labels for the images. Results: We received a median of 22 submissions/day (IQR 14–30). Female (66.72\%) and younger (52\% {$<$} age 40) contributors had a higher representation in the dataset compared to the US population, and 32.6\% of contributors reported a non-White racial or ethnic identity. Over 97.5\% of contributions were genuine images of skin conditions. Dermatologist confidence in assigning a differential diagnosis increased with the number of available variables, and showed a weak correlation with image sharpness (Spearman’s P values {$<$} 0.001 and 0.01 respectively). Most contributions were short-duration (54\% with onset {$<$} 7 days ago ) and 89\% were allergic, infectious, or inflammatory conditions. eFST and eMST distributions reflected the geographical origin of the dataset. The dataset is available at github.com/google-researchdatasets/scin. Conclusion: Search ads are effective at crowdsourcing images of health conditions. The SCIN dataset bridges important gaps in the availability of representative images of common skin conditions.}
      \field{day}{28}
      \field{eprintclass}{cs}
      \field{eprinttype}{arxiv}
      \field{langid}{english}
      \field{month}{2}
      \field{shorttitle}{Crowdsourcing {{Dermatology Images}} with {{Google Search Ads}}}
      \field{title}{Crowdsourcing {{Dermatology Images}} with {{Google Search Ads}}: {{Creating}} a {{Real-World Skin Condition Dataset}}}
      \field{urlday}{28}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2024}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2402.18545
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/UQGXAEAY/Ward et al. - 2024 - Crowdsourcing Dermatology Images with Google Searc.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2402.18545
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2402.18545
      \endverb
      \keyw{Computer Science - Computers and Society}
    \endentry
    \entry{ACNE04}{article}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=1e9a188f2fe0d90e12f60cc057f247e9}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Xiaoping},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e75d9f8e33d3b19f37af6bfbb75ee3d8}{%
           family={Wen},
           familyi={W\bibinitperiod},
           given={Ni},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2fdd02cf869cd5db2eb76ef827bb449d}{%
           family={Liang},
           familyi={L\bibinitperiod},
           given={Jie},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4bb63a56d1c146994bcd32b61ecddbf9}{%
           family={Lai},
           familyi={L\bibinitperiod},
           given={Yu-Kun},
           giveni={Y\bibinithyphendelim K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=24aa2bf674e02bf6de471f2763a3ee86}{%
           family={She},
           familyi={S\bibinitperiod},
           given={Dongyu},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bfbe355b6a8257baeffd5b8814bc5c57}{%
           family={Cheng},
           familyi={C\bibinitperiod},
           given={Ming-Ming},
           giveni={M\bibinithyphendelim M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=658c76617bcffe77e2bd3f068cf03c67}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Jufeng},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Seoul, Korea (South)}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{c452610eaf09b5680fcfd3167d1cd188}
      \strng{fullhash}{308851af87d512d2a5468470587a057c}
      \strng{bibnamehash}{308851af87d512d2a5468470587a057c}
      \strng{authorbibnamehash}{308851af87d512d2a5468470587a057c}
      \strng{authornamehash}{c452610eaf09b5680fcfd3167d1cd188}
      \strng{authorfullhash}{308851af87d512d2a5468470587a057c}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Accurate grading of skin disease severity plays a crucial role in precise treatment for patients. Acne vulgaris, the most common skin disease in adolescence, can be graded by evidence-based lesion counting as well as experiencebased global estimation in the medical field. However, due to the appearance similarity of acne with close severity, it is challenging to count and grade acne accurately. In this paper, we address the problem of acne image analysis via Label Distribution Learning (LDL) considering the ambiguous information among acne severity. Based on the professional grading criterion, we generate two acne label distributions considering the relationship between the similar number of lesions and severity of acne, respectively. We also propose a unified framework for joint acne image grading and counting, which is optimized by the multi-task learning loss. In addition, we further build the ACNE04 dataset with annotations of acne severity and lesion number of each image for evaluation. Experiments demonstrate that our proposed framework performs favorably against stateof-the-art methods. We make the code and dataset publicly available at https://github.com/xpwu95/ldl.}
      \field{eventtitle}{2019 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})}
      \field{isbn}{978-1-72814-803-8}
      \field{journaltitle}{2019 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})}
      \field{langid}{english}
      \field{month}{10}
      \field{title}{Joint {{Acne Image Grading}} and {{Counting}} via {{Label Distribution Learning}}}
      \field{urlday}{28}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{10641\bibrangedash 10650}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/ICCV.2019.01074
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/43KJG5LJ/Wu et al. - 2019 - Joint Acne Image Grading and Counting via Label Di.pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/9010021/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/9010021/
      \endverb
    \endentry
    \entry{SIQAD}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=20c90b2c7ed4d1d31d2f648c075f6c90}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Huan},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d3a448d23a1b82215bcec1d99bd62be9}{%
           family={{Yuming Fang}},
           familyi={Y\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=ef82e2e99c11391b0d3372d3bf096101}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Weisi},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f244e8ae5eff7776cf2b4b5b84ad8c4a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhou},
           giveni={Z\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Singapore, Singapore}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{8969d129e834b307511063481c2617d5}
      \strng{fullhash}{e66dc206f4d5df2b4d3f10a64a29b763}
      \strng{bibnamehash}{e66dc206f4d5df2b4d3f10a64a29b763}
      \strng{authorbibnamehash}{e66dc206f4d5df2b4d3f10a64a29b763}
      \strng{authornamehash}{8969d129e834b307511063481c2617d5}
      \strng{authorfullhash}{e66dc206f4d5df2b4d3f10a64a29b763}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Research on Screen Content Images (SCIs) becomes important as they are increasingly used in multi-device communication applications. In this paper, we present a study of subjective quality assessment for distorted SCIs, and investigate which part (text or picture) contributes more to the overall visual quality. We construct a large-scale Screen Image Quality Assessment Database (SIQAD) consisting of 20 source and 980 distorted SCIs. The 11-category Absolute Category Rating (ACR) is employed to obtain three subjective quality scores corresponding to the entire image, textual and pictorial regions respectively. Based on the subjective data, we investigate the applicability of 12 state-of-the-art Image Quality Assessment (IQA) methods for objectively assessing the quality of SCIs. The results indicate that existing IQA methods are limited in predicting human quality judgement of SCIs. Moreover, we propose a prediction model to account for the correlation between the subjective scores of textual and pictorial regions and the entire image. The current results make an initial move towards objective quality assessment of SCIs.}
      \field{eventtitle}{2014 {{Sixth International Workshop}} on {{Quality}} of {{Multimedia Experience}} ({{QoMEX}})}
      \field{isbn}{978-1-4799-6536-6}
      \field{journaltitle}{2014 {{Sixth International Workshop}} on {{Quality}} of {{Multimedia Experience}} ({{QoMEX}})}
      \field{langid}{english}
      \field{month}{9}
      \field{title}{Subjective Quality Assessment of {{Screen Content Images}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{257\bibrangedash 262}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/QoMEX.2014.6982328
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/46AJMFUP/Yang et al. - 2014 - Subjective quality assessment of Screen Content Im.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6982328/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6982328/
      \endverb
    \endentry
  \enddatalist
  \datalist[entry]{apa/global//global/global}
    \entry{Monkeypox}{online}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=5e330206d122845de19963480ab85a48}{%
           family={Ahsan},
           familyi={A\bibinitperiod},
           given={Md\bibnamedelima Manjurul},
           giveni={M\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=806c019703dc5c4505a620506f40d465}{%
           family={Uddin},
           familyi={U\bibinitperiod},
           given={Muhammad\bibnamedelima Ramiz},
           giveni={M\bibinitperiod\bibinitdelim R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f2604d696a98e14c3b9b05edfdaeb79b}{%
           family={Luna},
           familyi={L\bibinitperiod},
           given={Shahana\bibnamedelima Akter},
           giveni={S\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b4496085a60ed3ba0135575814a31b0b}
      \strng{fullhash}{8a516943b5a0f5ee3eeb5f0b2f086d99}
      \strng{bibnamehash}{8a516943b5a0f5ee3eeb5f0b2f086d99}
      \strng{authorbibnamehash}{8a516943b5a0f5ee3eeb5f0b2f086d99}
      \strng{authornamehash}{b4496085a60ed3ba0135575814a31b0b}
      \strng{authorfullhash}{8a516943b5a0f5ee3eeb5f0b2f086d99}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper explains the initial Monkeypox Open image data collection procedure. It was created by assembling images collected from websites, newspapers, and online portals and currently contains around 1905 images after data augmentation.}
      \field{day}{3}
      \field{eprintclass}{cs, eess}
      \field{eprinttype}{arxiv}
      \field{langid}{english}
      \field{month}{6}
      \field{title}{Monkeypox {{Image Data}} Collection}
      \field{urlday}{28}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2206.01774
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/J3MR87R2/Ahsan et al. - 2022 - Monkeypox Image Data collection.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2206.01774
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2206.01774
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing}
    \endentry
    \entry{CSIQ}{article}{}
      \name{author}{1}{}{%
        {{un=1,uniquepart=given,hash=c5addfdd7f1dd742dac1643e46f25ee6}{%
           family={Chandler},
           familyi={C\bibinitperiod},
           given={Damon\bibnamedelima M.},
           giveni={D\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=1}}%
      }
      \strng{namehash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{fullhash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{bibnamehash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{authorbibnamehash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{authornamehash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{authorfullhash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{day}{1}
      \field{issn}{1017-9909}
      \field{journaltitle}{Journal of Electronic Imaging}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{J. Electron. Imaging}
      \field{shorttitle}{Most Apparent Distortion}
      \field{title}{Most Apparent Distortion: Full-Reference Image Quality Assessment and the Role of Strategy}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{19}
      \field{year}{2010}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{011006}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1117/1.3267105
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/ND7PFFNY/Chandler - 2010 - Most apparent distortion full-reference image qua.pdf
      \endverb
      \verb{urlraw}
      \verb https://s2.smu.edu/~eclarson/pubs/2010JEI_MAD.pdf
      \endverb
      \verb{url}
      \verb https://s2.smu.edu/~eclarson/pubs/2010JEI_MAD.pdf
      \endverb
    \endentry
    \entry{A57}{article}{}
      \name{author}{2}{}{%
        {{un=1,uniquepart=given,hash=52a422f501ab24ced4fed94ce0226e40}{%
           family={Chandler},
           familyi={C\bibinitperiod},
           given={D.M.},
           giveni={D\bibinitperiod},
           givenun=1}}%
        {{un=0,uniquepart=base,hash=e4622e95fefb83373d9614ae9c8ce220}{%
           family={Hemami},
           familyi={H\bibinitperiod},
           given={S.S.},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{fullhash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{bibnamehash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{authorbibnamehash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{authornamehash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{authorfullhash}{1ea3294ab1b80857b24a400ac4e1c519}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper presents an efficient metric for quantifying the visual fidelity of natural images based on near-threshold and suprathreshold properties of human vision. The proposed metric, the visual signal-to-noise ratio (VSNR), operates via a two-stage approach. In the first stage, contrast thresholds for detection of distortions in the presence of natural images are computed via wavelet-based models of visual masking and visual summation in order to determine whether the distortions in the distorted image are visible. If the distortions are below the threshold of detection, the distorted image is deemed to be of perfect visual fidelity (VSNR = ) and no further analysis is required. If the distortions are suprathreshold, a second stage is applied which operates based on the low-level visual property of perceived contrast, and the mid-level visual property of global precedence. These two properties are modeled as Euclidean distances in distortion-contrast space of a multiscale wavelet decomposition, and VSNR is computed based on a simple linear sum of these distances. The proposed VSNR metric is generally competitive with current metrics of visual fidelity; it is efficient both in terms of its low computational complexity and in terms of its low memory requirements; and it operates based on physical luminances and visual angle (rather than on digital pixel values and pixel-based dimensions) to accommodate different viewing conditions.}
      \field{issn}{1057-7149}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{9}
      \field{number}{9}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{shorttitle}{{{VSNR}}}
      \field{title}{{{VSNR}}: {{A Wavelet-Based Visual Signal-to-Noise Ratio}} for {{Natural Images}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{16}
      \field{year}{2007}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2284\bibrangedash 2298}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1109/TIP.2007.901820
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/EW9CANZ4/Chandler und Hemami - 2007 - VSNR A Wavelet-Based Visual Signal-to-Noise Ratio.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/4286985/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/4286985/
      \endverb
    \endentry
    \entry{DDI}{article}{}
      \name{author}{19}{}{%
        {{un=0,uniquepart=base,hash=0df7931cf6d169c0892a3a00ce803ffa}{%
           family={Daneshjou},
           familyi={D\bibinitperiod},
           given={Roxana},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=727a8a479e533213d5df986b6f2d695e}{%
           family={Vodrahalli},
           familyi={V\bibinitperiod},
           given={Kailas},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7dcf7c517335b316301b5a23b218557b}{%
           family={Novoa},
           familyi={N\bibinitperiod},
           given={Roberto\bibnamedelima A.},
           giveni={R\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f52780318e8d7a8f1246945fc17275d5}{%
           family={Jenkins},
           familyi={J\bibinitperiod},
           given={Melissa},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c37e00c1ca8aafe56159ff4ab1f6e040}{%
           family={Liang},
           familyi={L\bibinitperiod},
           given={Weixin},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=60abb913d03e3830abf9001aa7fc6e66}{%
           family={Rotemberg},
           familyi={R\bibinitperiod},
           given={Veronica},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d5274c1d02c20ebd471b200127fcee09}{%
           family={Ko},
           familyi={K\bibinitperiod},
           given={Justin},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2418082b9eed3d391d9b768fd518590b}{%
           family={Swetter},
           familyi={S\bibinitperiod},
           given={Susan\bibnamedelima M.},
           giveni={S\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=70d210517db32b4eaab0e90ad1400947}{%
           family={Bailey},
           familyi={B\bibinitperiod},
           given={Elizabeth\bibnamedelima E.},
           giveni={E\bibinitperiod\bibinitdelim E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=52203a415c44a164349b49556b4cb936}{%
           family={Gevaert},
           familyi={G\bibinitperiod},
           given={Olivier},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8891e16d35998eaa26fec3e89246c530}{%
           family={Mukherjee},
           familyi={M\bibinitperiod},
           given={Pritam},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c396d55e91bde40804ef7b29e3f2d9a4}{%
           family={Phung},
           familyi={P\bibinitperiod},
           given={Michelle},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cc6c5220558493c7698dbc66b3af1f9a}{%
           family={Yekrang},
           familyi={Y\bibinitperiod},
           given={Kiana},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a4e5d95ac01bebef06e82562655bff0b}{%
           family={Fong},
           familyi={F\bibinitperiod},
           given={Bradley},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=41236bc53de1c13fa044268006cbd26e}{%
           family={Sahasrabudhe},
           familyi={S\bibinitperiod},
           given={Rachna},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a2fdfbc1a0bd5114e0589d350fd4e21f}{%
           family={Allerup},
           familyi={A\bibinitperiod},
           given={Johan\bibnamedelimb A.\bibnamedelimi C.},
           giveni={J\bibinitperiod\bibinitdelim A\bibinitperiod\bibinitdelim C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=166f1cda23be30a0e86aec354d1ba119}{%
           family={Okata-Karigane},
           familyi={O\bibinithyphendelim K\bibinitperiod},
           given={Utako},
           giveni={U\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1b868d50048a635fa27ffa744323fa41}{%
           family={Zou},
           familyi={Z\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dc642188ac4ca15bdcac2f5db259e705}{%
           family={Chiou},
           familyi={C\bibinitperiod},
           given={Albert\bibnamedelima S.},
           giveni={A\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{c2819d3adaa0ac3e74c4f0e85171265e}
      \strng{fullhash}{fa9506acc8c11aab5b50c7db22308db9}
      \strng{bibnamehash}{fa9506acc8c11aab5b50c7db22308db9}
      \strng{authorbibnamehash}{fa9506acc8c11aab5b50c7db22308db9}
      \strng{authornamehash}{c2819d3adaa0ac3e74c4f0e85171265e}
      \strng{authorfullhash}{fa9506acc8c11aab5b50c7db22308db9}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{An estimated 3 billion people lack access to dermatological care globally. Artificial intelligence (AI) may aid in triaging skin diseases and identifying malignancies. However, most AI models have not been assessed on images of diverse skin tones or uncommon diseases. Thus, we created the Diverse Dermatology Images (DDI) dataset—the first publicly available, expertly curated, and pathologically confirmed image dataset with diverse skin tones. We show that state-of-the-art dermatology AI models exhibit substantial limitations on the DDI dataset, particularly on dark skin tones and uncommon diseases. We find that dermatologists, who often label AI datasets, also perform worse on images of dark skin tones and uncommon diseases. Fine-tuning AI models on the DDI images closes the performance gap between light and dark skin tones. These findings identify important weaknesses and biases in dermatology AI that should be addressed for reliable application to diverse patients and diseases. , A diverse, curated clinical dermatology image set can help address AI in dermatology limitations.}
      \field{day}{12}
      \field{issn}{2375-2548}
      \field{journaltitle}{Science Advances}
      \field{langid}{english}
      \field{month}{8}
      \field{number}{32}
      \field{shortjournal}{Sci. Adv.}
      \field{title}{Disparities in Dermatology {{AI}} Performance on a Diverse, Curated Clinical Image Set}
      \field{urlday}{28}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{8}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{eabq6147}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1126/sciadv.abq6147
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/ECM8UI47/Daneshjou et al. - 2022 - Disparities in dermatology AI performance on a div.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.science.org/doi/10.1126/sciadv.abq6147
      \endverb
      \verb{url}
      \verb https://www.science.org/doi/10.1126/sciadv.abq6147
      \endverb
    \endentry
    \entry{LIVE_Wild}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=3e0108af1e78568ae823af503315860a}{%
           family={Ghadiyaram},
           familyi={G\bibinitperiod},
           given={Deepti},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d9c2ab9a8cbcab08292923a454c88ce7}{%
           family={Bovik},
           familyi={B\bibinitperiod},
           given={Alan\bibnamedelima C.},
           giveni={A\bibinitperiod\bibinitdelim C\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{fullhash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{bibnamehash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{authorbibnamehash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{authornamehash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{authorfullhash}{3cdb959f35d9532ad6b5f9539dc38537}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Most publicly available image quality databases have been created under highly controlled conditions by introducing graded simulated distortions onto high-quality photographs. However, images captured using typical real-world mobile camera devices are usually afflicted by complex mixtures of multiple distortions, which are not necessarily well-modeled by the synthetic distortions found in existing databases. The originators of existing legacy databases usually conducted human psychometric studies to obtain statistically meaningful sets of human opinion scores on images in a stringently controlled visual environment, resulting in small data collections relative to other kinds of image analysis databases. Toward overcoming these limitations, we designed and created a new database that we call the LIVE In the Wild Image Quality Challenge Database, which contains widely diverse authentic image distortions on a large number of images captured using a representative variety of modern mobile devices. We also designed and implemented a new online crowdsourcing system, which we have used to conduct a very large-scale, multi-month image quality assessment (IQA) subjective study. Our database consists of over 350 000 opinion scores on 1162 images evaluated by over 8100 unique human observers. Despite the lack of control over the experimental environments of the numerous study participants, we demonstrate excellent internal consistency of the subjective data set. We also evaluate several top-performing blind IQA algorithms on it and present insights on how the mixtures of distortions challenge both end users as well as automatic perceptual quality prediction models. The new database is available for public use at http://live.ece.utexas.edu/research/ChallengeDB/index.html.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{title}{Massive {{Online Crowdsourced Study}} of {{Subjective}} and {{Objective Picture Quality}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{25}
      \field{year}{2016}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{372\bibrangedash 387}
      \range{pages}{16}
      \verb{doi}
      \verb 10.1109/TIP.2015.2500021
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/NQWGF6QQ/Ghadiyaram und Bovik - 2016 - Massive Online Crowdsourced Study of Subjective an.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/7327186/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/7327186/
      \endverb
    \endentry
    \entry{F17K}{online}{}
      \name{author}{8}{}{%
        {{un=0,uniquepart=base,hash=fd54e1cfc05f311f39082f00f60d2b84}{%
           family={Groh},
           familyi={G\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2d4275cdd5c811184540d396a2145804}{%
           family={Harris},
           familyi={H\bibinitperiod},
           given={Caleb},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7d52a0f63a3bd096458d2eff247fa29d}{%
           family={Soenksen},
           familyi={S\bibinitperiod},
           given={Luis},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=28dfabe7b57656678c41ad55936042d8}{%
           family={Lau},
           familyi={L\bibinitperiod},
           given={Felix},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5331a36550165214d7a48f5d4a3163bc}{%
           family={Han},
           familyi={H\bibinitperiod},
           given={Rachel},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=648e51d2d11d843b2d3cbd072073b357}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Aerin},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7ea6c3c20fa36baa9472ad5aa2199f99}{%
           family={Koochek},
           familyi={K\bibinitperiod},
           given={Arash},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e847d65f28237726943cbd201016ae0a}{%
           family={Badri},
           familyi={B\bibinitperiod},
           given={Omar},
           giveni={O\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{01d902a15a712621710f5ad4e6bdd8a8}
      \strng{fullhash}{1e31ebdb01806e8aa75f38d3df862b31}
      \strng{bibnamehash}{1e31ebdb01806e8aa75f38d3df862b31}
      \strng{authorbibnamehash}{1e31ebdb01806e8aa75f38d3df862b31}
      \strng{authornamehash}{01d902a15a712621710f5ad4e6bdd8a8}
      \strng{authorfullhash}{1e31ebdb01806e8aa75f38d3df862b31}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{How does the accuracy of deep neural network models trained to classify clinical images of skin conditions vary across skin color? While recent studies demonstrate computer vision models can serve as a useful decision support tool in healthcare and provide dermatologist-level classification on a number of specific tasks, darker skin is underrepresented in the data. Most publicly available data sets do not include Fitzpatrick skin type labels. We annotate 16,577 clinical images sourced from two dermatology atlases with Fitzpatrick skin type labels and open-source these annotations. Based on these labels, we find that there are significantly more images of light skin types than dark skin types in this dataset. We train a deep neural network model to classify 114 skin conditions and find that the model is most accurate on skin types similar to those it was trained on. In addition, we evaluate how an algorithmic approach to identifying skin tones, individual typology angle, compares with Fitzpatrick skin type labels annotated by a team of human labelers.}
      \field{day}{20}
      \field{eprintclass}{cs}
      \field{eprinttype}{arxiv}
      \field{langid}{english}
      \field{month}{4}
      \field{title}{Evaluating {{Deep Neural Networks Trained}} on {{Clinical Images}} in {{Dermatology}} with the {{Fitzpatrick}} 17k {{Dataset}}}
      \field{urlday}{28}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2104.09957
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/7CFK8V66/Groh et al. - 2021 - Evaluating Deep Neural Networks Trained on Clinica.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2104.09957
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2104.09957
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{HSNID}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=a64df0db3d659a7cb92ab2266cdd6339}{%
           family={Gu},
           familyi={G\bibinitperiod},
           given={Ke},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b6fc78834b479731029a5edb14fd5de0}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Xin},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=14f0dd7dfcfc375a1d3a6b42a2c58757}{%
           family={Qiao},
           familyi={Q\bibinitperiod},
           given={Junfei},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a63ef12742ef71a5a06fcf66d6d72ad7}{%
           family={Jiang},
           familyi={J\bibinitperiod},
           given={Qiuping},
           giveni={Q\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ef82e2e99c11391b0d3372d3bf096101}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Weisi},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=24f20de24938c18a3655f419579d0900}{%
           family={Thalmann},
           familyi={T\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{4e5d9e5d83d0e26c4d17cce126315705}
      \strng{fullhash}{3c429fdd3ef0a5700e5721efbe97dd62}
      \strng{bibnamehash}{3c429fdd3ef0a5700e5721efbe97dd62}
      \strng{authorbibnamehash}{3c429fdd3ef0a5700e5721efbe97dd62}
      \strng{authornamehash}{4e5d9e5d83d0e26c4d17cce126315705}
      \strng{authorfullhash}{3c429fdd3ef0a5700e5721efbe97dd62}
      \field{extraname}{1}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this work, we resolve a big challenge that most current image quality metrics (IQMs) are unavailable across different image contents, especially simultaneously coping with natural scene (NS) images or screen content (SC) images. By comparison with existing works, this paper deploys on-line and off-line data for proposing a unified no-reference (NR) IQM, not only applied to different distortion types and intensities but also to various image contents including classical NS images and prevailing SC images. Our proposed NR IQM is developed with two data-driven learning processes following feature extraction, which is based on scene statistic models, free-energy brain principle, and human visual system (HVS) characteristics. In the first process, the scene statistic models and an image retrieve technique are combined, based on on-line and off-line training instances, to derive a novel loose classifier for retrieving clean images and helping to infer the image content. In the second process, the features extracted by incorporating the inferred image content, free-energy and low-level perceptual characteristics of the HVS are learned by utilizing off-line training samples to analyze the distortion types and intensities and thereby to predict the image quality. The two processes mentioned above depend on a gigantic quantity of training data, much exceeding the number of images applied to performance validation, and thus make our model’s performance more reliable. Through extensive experiments, it has been validated that the proposed blind IQM is capable of simultaneously inferring the quality of NS and SC images, and it has attained superior performance as compared with popular and state-of-the-art IQMs on the subjective NS and SC image quality databases. The source code of our model will be released with the publication of the paper at https://kegu.netlify.com.}
      \field{day}{1}
      \field{issn}{2332-7790, 2372-2096}
      \field{journaltitle}{IEEE Transactions on Big Data}
      \field{langid}{english}
      \field{month}{12}
      \field{number}{4}
      \field{shortjournal}{IEEE Trans. Big Data}
      \field{title}{Learning a {{Unified Blind Image Quality Metric}} via {{On-Line}} and {{Off-Line Big Training Instances}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{6}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{780\bibrangedash 791}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/TBDATA.2019.2895605
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/8K778KAQ/Gu et al. - 2020 - Learning a Unified Blind Image Quality Metric via .pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8627983/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8627983/
      \endverb
    \endentry
    \entry{MDID2013}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=a64df0db3d659a7cb92ab2266cdd6339}{%
           family={Gu},
           familyi={G\bibinitperiod},
           given={Ke},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=de70ef50dd45ba84349c3a3d3d5a9141}{%
           family={Zhai},
           familyi={Z\bibinitperiod},
           given={Guangtao},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=31f1758fe4ad1edbef9504ac0116d1ad}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Xiaokang},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0d9c450eb8905fc9a195a67a39e601af}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Wenjun},
           giveni={W\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{4e5d9e5d83d0e26c4d17cce126315705}
      \strng{fullhash}{4f4df664f870c36e53e9c30c581f479c}
      \strng{bibnamehash}{4f4df664f870c36e53e9c30c581f479c}
      \strng{authorbibnamehash}{4f4df664f870c36e53e9c30c581f479c}
      \strng{authornamehash}{4e5d9e5d83d0e26c4d17cce126315705}
      \strng{authorfullhash}{4f4df664f870c36e53e9c30c581f479c}
      \field{extraname}{2}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In a typical image communication system, the visual signal presented to the end users may undergo the steps of acquisition, compression and transmission which cause the artifacts of blurring, quantization and noise. However, the researches of image quality assessment (IQA) with multiple distortion types are very limited. In this paper, we first introduce a new multiply distorted image database (MDID2013), which is composed of 324 images that are simultaneously corrupted by blurring, JPEG compression and noise injection. We then propose a new six-step blind metric (SISBLIM) for quality assessment of both singly and multiply distorted images. Inspired by the early human visual model and recently revealed free energy based brain theory, our method works to systematically combine the single quality prediction of each emerging distortion type and joint effects of different distortion sources. Comparative studies of the proposed SISBLIM with popular full-reference IQA approaches and start-of-the-art no-reference IQA metrics are conducted on five singly distorted image databases (LIVE, TID2008, CSIQ, IVC, Toyama) and two newly released multiply distorted image databases (LIVEMD, MDID2013). Experimental results confirm the effectiveness of our blind technique. MATLAB codes of the proposed SISBLIM algorithm and MDID2013 database will be available online at http://gvsp.sjtu.edu.cn/.}
      \field{issn}{0018-9316, 1557-9611}
      \field{journaltitle}{IEEE Transactions on Broadcasting}
      \field{langid}{english}
      \field{month}{9}
      \field{number}{3}
      \field{shortjournal}{IEEE Trans. on Broadcast.}
      \field{title}{Hybrid {{No-Reference Quality Metric}} for {{Singly}} and {{Multiply Distorted Images}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{60}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{555\bibrangedash 567}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TBC.2014.2344471
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/B4SN597A/Gu et al. - 2014 - Hybrid No-Reference Quality Metric for Singly and .pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/6879255/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/6879255/
      \endverb
    \endentry
    \entry{DesignThinking}{book}{}
      \name{editor}{5}{}{%
        {{un=0,uniquepart=base,hash=3256cddf77f82c7ebb20075626add887}{%
           family={Hoffmann},
           familyi={H\bibinitperiod},
           given={Christian\bibnamedelima Pieter},
           giveni={C\bibinitperiod\bibinitdelim P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0b49b3c14a19de344828832bdac60c0c}{%
           family={Lennerts},
           familyi={L\bibinitperiod},
           given={Silke},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2bdad7fccb2d18293bf3a170825f79e9}{%
           family={Schmitz},
           familyi={S\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8babc848fff930512f3b1874b79ea55e}{%
           family={Stölzle},
           familyi={S\bibinitperiod},
           given={Wolfgang},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3df7861ab18004fde039801677b379cf}{%
           family={Uebernickel},
           familyi={U\bibinitperiod},
           given={Falk},
           giveni={F\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Wiesbaden}%
      }
      \list{publisher}{1}{%
        {Springer Fachmedien Wiesbaden}%
      }
      \strng{namehash}{f61c76cafc5705d4bbc20230cdeb2886}
      \strng{fullhash}{58012356417ad9a435c599f385d6bcb1}
      \strng{bibnamehash}{58012356417ad9a435c599f385d6bcb1}
      \strng{editorbibnamehash}{58012356417ad9a435c599f385d6bcb1}
      \strng{editornamehash}{f61c76cafc5705d4bbc20230cdeb2886}
      \strng{editorfullhash}{58012356417ad9a435c599f385d6bcb1}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{editor}
      \field{labeltitlesource}{shorttitle}
      \field{langid}{english}
      \field{shorttitle}{Business {{Innovation}}}
      \field{title}{Business {{Innovation}}: {{Das St}}. {{Galler Modell}}}
      \field{urlday}{29}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2016}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.1007/978-3-658-07167-7
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/EAEZ5T5N/Hoffmann et al. - 2016 - Business Innovation Das St. Galler Modell.pdf
      \endverb
      \verb{urlraw}
      \verb https://link.springer.com/10.1007/978-3-658-07167-7
      \endverb
      \verb{url}
      \verb https://link.springer.com/10.1007/978-3-658-07167-7
      \endverb
    \endentry
    \entry{ImageQX}{online}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=8befab1f4adfe07956f09ed4f2229e2e}{%
           family={Jalaboi},
           familyi={J\bibinitperiod},
           given={Raluca},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7862b9aae6d622aee37d7b62ba9450e7}{%
           family={Winther},
           familyi={W\bibinitperiod},
           given={Ole},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3c84f09b7c007ffaea13e97c783dc97e}{%
           family={Galimzianova},
           familyi={G\bibinitperiod},
           given={Alfiia},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{20b41d73e4f5671db0dfb9cfd9363442}
      \strng{fullhash}{da3df0de5748984ae7a39a4a27c94ed7}
      \strng{bibnamehash}{da3df0de5748984ae7a39a4a27c94ed7}
      \strng{authorbibnamehash}{da3df0de5748984ae7a39a4a27c94ed7}
      \strng{authornamehash}{20b41d73e4f5671db0dfb9cfd9363442}
      \strng{authorfullhash}{da3df0de5748984ae7a39a4a27c94ed7}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Image quality is a crucial factor in the effectiveness and efficiency of teledermatological consultations. However, up to 50\% of images sent by patients have quality issues, thus increasing the time to diagnosis and treatment. An automated, easily deployable, explainable method for assessing image quality is necessary to improve the current teledermatological consultation flow. We introduce ImageQX, a convolutional neural network for image quality assessment with a learning mechanism for identifying the most common poor image quality explanations: bad framing, bad lighting, blur, low resolution, and distance issues. ImageQX was trained on 26,635 photographs and validated on 9,874 photographs, each annotated with image quality labels and poor image quality explanations by up to 12 board-certified dermatologists. The photographic images were taken between 2017 and 2019 using a mobile skin disease tracking application accessible worldwide. Our method achieves expert-level performance for both image quality assessment and poor image quality explanation. For image quality assessment, ImageQX obtains a macro F1-score of 0.73 ± 0.01, which places it within standard deviation of the pairwise inter-rater F1-score of 0.77 ± 0.07. For poor image quality explanations, our method obtains F1-scores of between 0.37 ± 0.01 and 0.70 ± 0.01, similar to the inter-rater pairwise F1-score of between 0.24 ± 0.15 and 0.83 ± 0.06. Moreover, with a size of only 15 MB, ImageQX is easily deployable on mobile devices. With an image quality detection performance similar to that of dermatologists, incorporating ImageQX into the teledermatology flow can enable a better, faster flow for remote consultations.}
      \field{day}{23}
      \field{eprintclass}{cs}
      \field{eprinttype}{arxiv}
      \field{langid}{english}
      \field{month}{1}
      \field{title}{Explainable {{Image Quality Assessments}} in {{Teledermatological Photography}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2209.04699
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/5JFM3Q9H/Jalaboi et al. - 2023 - Explainable Image Quality Assessments in Telederma.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2209.04699
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2209.04699
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
    \endentry
    \entry{LIVEMD}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=cd27d3d228b115c84bc1d88310a81f02}{%
           family={Jayaraman},
           familyi={J\bibinitperiod},
           given={Dinesh},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5140f90dfa1ff2db127d5ad357e881ea}{%
           family={Mittal},
           familyi={M\bibinitperiod},
           given={Anish},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0637cd6093dcea240cdcb122b300761b}{%
           family={Moorthy},
           familyi={M\bibinitperiod},
           given={Anush\bibnamedelima K.},
           giveni={A\bibinitperiod\bibinitdelim K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d9c2ab9a8cbcab08292923a454c88ce7}{%
           family={Bovik},
           familyi={B\bibinitperiod},
           given={Alan\bibnamedelima C.},
           giveni={A\bibinitperiod\bibinitdelim C\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Pacific Grove, CA, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{b9473887aa8ef09533091798c76022ef}
      \strng{fullhash}{8fb566e1d8b66be5dca6b5531931decd}
      \strng{bibnamehash}{8fb566e1d8b66be5dca6b5531931decd}
      \strng{authorbibnamehash}{8fb566e1d8b66be5dca6b5531931decd}
      \strng{authornamehash}{b9473887aa8ef09533091798c76022ef}
      \strng{authorfullhash}{8fb566e1d8b66be5dca6b5531931decd}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Subjective studies have been conducted in the past to obtain human judgments of visual quality on distorted images in order, among other things, to benchmark objective image qual. ity assessment (lQA) algorithms. Existing subjective studies primarily have records of human ratings on images that were corrupted by only one of many possible distortions. However, the majority of images that are available for consumption are corrupted by multiple distortions. Towards broadening the corpora of records of human responses to visual distortions, we recently conducted a study on two types of multiply distorted images to obtain human judgments of the visual quality of such images. Further, we compared the performance of several existing objective image quality measures on the new database and analyze the effects of multiple distortions on commonly used quality-determinant features and on human ratings.}
      \field{eventtitle}{2012 46th {{Asilomar Conference}} on {{Signals}}, {{Systems}} and {{Computers}}}
      \field{journaltitle}{2012 {{Conference Record}} of the {{Forty Sixth Asilomar Conference}} on {{Signals}}, {{Systems}} and {{Computers}} ({{ASILOMAR}})}
      \field{langid}{english}
      \field{month}{11}
      \field{title}{Objective Quality Assessment of Multiply Distorted Images}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2012}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1693\bibrangedash 1697}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/ACSSC.2012.6489321
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/XIL22H3U/Jayaraman et al. - 2012 - Objective quality assessment of multiply distorted.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6489321/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6489321/
      \endverb
    \endentry
    \entry{Derm7pt}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=da947d3afb637b7e27cbc33776cce543}{%
           family={Kawahara},
           familyi={K\bibinitperiod},
           given={Jeremy},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=33dca317433f473bebf123d208ea18c0}{%
           family={Daneshvar},
           familyi={D\bibinitperiod},
           given={Sara},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=240f6e7e4d9967c0fa69aea0c1c382d9}{%
           family={Argenziano},
           familyi={A\bibinitperiod},
           given={Giuseppe},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=061eb4eb95e9947e4010093d17626dd1}{%
           family={Hamarneh},
           familyi={H\bibinitperiod},
           given={Ghassan},
           giveni={G\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{659c1fdbf8a702920ba2f2085730c412}
      \strng{fullhash}{c1226c3bec07be6aed0a3fb6c8556555}
      \strng{bibnamehash}{c1226c3bec07be6aed0a3fb6c8556555}
      \strng{authorbibnamehash}{c1226c3bec07be6aed0a3fb6c8556555}
      \strng{authornamehash}{659c1fdbf8a702920ba2f2085730c412}
      \strng{authorfullhash}{c1226c3bec07be6aed0a3fb6c8556555}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a multitask deep convolutional neural network, trained on multimodal data (clinical and dermoscopic images, and patient metadata), to classify the 7-point melanoma checklist criteria and perform skin lesion diagnosis. Our neural network is trained using several multitask loss functions, where each loss considers different combinations of the input modalities, which allows our model to be robust to missing data at inference time. Our final model classifies the 7-point checklist and skin condition diagnosis, produces multimodal feature vectors suitable for image retrieval, and localizes clinically discriminant regions. We benchmark our approach using 1011 lesion cases, and report comprehensive results over all 7-point criteria and diagnosis. We also make our dataset (images and metadata) publicly available online at http://derm.cs.sfu.ca.}
      \field{issn}{2168-2194, 2168-2208}
      \field{journaltitle}{IEEE Journal of Biomedical and Health Informatics}
      \field{langid}{english}
      \field{month}{3}
      \field{number}{2}
      \field{shortjournal}{IEEE J. Biomed. Health Inform.}
      \field{title}{Seven-{{Point Checklist}} and {{Skin Lesion Classification Using Multitask Multimodal Neural Nets}}}
      \field{urlday}{28}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{23}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{538\bibrangedash 546}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1109/JBHI.2018.2824327
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/X3NDWJDI/Kawahara et al. - 2019 - Seven-Point Checklist and Skin Lesion Classificati.pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8333693/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8333693/
      \endverb
    \endentry
    \entry{WED}{article}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=79f9b1044b245e49f7e431dfc1b96bbd}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Kede},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9aec47e12e3d6fbc7bdca7a5da683262}{%
           family={Duanmu},
           familyi={D\bibinitperiod},
           given={Zhengfang},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c39472ae48abeae16b94f055c782c3fe}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Qingbo},
           giveni={Q\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f244e8ae5eff7776cf2b4b5b84ad8c4a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhou},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a145467fa9fec4f93e60603bdd640271}{%
           family={Yong},
           familyi={Y\bibinitperiod},
           given={Hongwei},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a549968ccfc4003d90c1ffd4a9ff5a05}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Hongliang},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f4a4cbf770add19c206827116c68732e}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Lei},
           giveni={L\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{629b9403529af15b56742c449f643c2d}
      \strng{fullhash}{19823db61e86416d5dafd1eee1bf3ab2}
      \strng{bibnamehash}{19823db61e86416d5dafd1eee1bf3ab2}
      \strng{authorbibnamehash}{19823db61e86416d5dafd1eee1bf3ab2}
      \strng{authornamehash}{629b9403529af15b56742c449f643c2d}
      \strng{authorfullhash}{19823db61e86416d5dafd1eee1bf3ab2}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The great content diversity of real-world digital images poses a grand challenge to image quality assessment (IQA) models, which are traditionally designed and validated on a handful of commonly used IQA databases with very limited content variation. To test the generalization capability and to facilitate the wide usage of IQA techniques in real-world applications, we establish a large-scale database named the Waterloo Exploration Database, which in its current state contains 4744 pristine natural images and 94 880 distorted images created from them. Instead of collecting the mean opinion score for each image via subjective testing, which is extremely difficult if not impossible, we present three alternative test criteria to evaluate the performance of IQA models, namely, the pristine/distorted image discriminability test, the listwise ranking consistency test, and the pairwise preference consistency test (P-test). We compare 20 well-known IQA models using the proposed criteria, which not only provide a stronger test in a more challenging testing environment for existing models, but also demonstrate the additional benefits of using the proposed database. For example, in the P-test, even for the best performing no-reference IQA model, more than 6 million failure cases against the model are “discovered” automatically out of over 1 billion test pairs. Furthermore, we discuss how the new database may be exploited using innovative approaches in the future, to reveal the weaknesses of existing IQA models, to provide insights on how to improve the models, and to shed light on how the next-generation IQA models may be developed. The database and codes are made publicly available at: https://ece.uwaterloo.ca/\textasciitilde k29ma/exploration/.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{2}
      \field{number}{2}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{shorttitle}{Waterloo {{Exploration Database}}}
      \field{title}{Waterloo {{Exploration Database}}: {{New Challenges}} for {{Image Quality Assessment Models}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{26}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1004\bibrangedash 1016}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TIP.2016.2631888
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/CZGVWNWD/Ma et al. - 2017 - Waterloo Exploration Database New Challenges for .pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/7752930/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/7752930/
      \endverb
    \endentry
    \entry{CCT}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=2f8448dbface32ad773f9ade4399a3f6}{%
           family={Min},
           familyi={M\bibinitperiod},
           given={Xiongkuo},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=79f9b1044b245e49f7e431dfc1b96bbd}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Kede},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a64df0db3d659a7cb92ab2266cdd6339}{%
           family={Gu},
           familyi={G\bibinitperiod},
           given={Ke},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=de70ef50dd45ba84349c3a3d3d5a9141}{%
           family={Zhai},
           familyi={Z\bibinitperiod},
           given={Guangtao},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f244e8ae5eff7776cf2b4b5b84ad8c4a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhou},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ef82e2e99c11391b0d3372d3bf096101}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Weisi},
           giveni={W\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b5956eea704a1bf19d70dfa9e1835ec0}
      \strng{fullhash}{62389347e63997afa9f42a66fd9abb81}
      \strng{bibnamehash}{62389347e63997afa9f42a66fd9abb81}
      \strng{authorbibnamehash}{62389347e63997afa9f42a66fd9abb81}
      \strng{authornamehash}{b5956eea704a1bf19d70dfa9e1835ec0}
      \strng{authorfullhash}{62389347e63997afa9f42a66fd9abb81}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Digital images in the real world are created by a variety of means and have diverse properties. A photographical natural scene image (NSI) may exhibit substantially different characteristics from a computer graphic image (CGI) or a screen content image (SCI). This casts major challenges to objective image quality assessment, for which existing approaches lack effective mechanisms to capture such content type variations, and thus are difficult to generalize from one type to another. To tackle this problem, we first construct a cross-content-type (CCT) database, which contains 1,320 distorted NSIs, CGIs, and SCIs, compressed using the high efficiency video coding (HEVC) intra coding method and the screen content compression (SCC) extension of HEVC. We then carry out a subjective experiment on the database in a well-controlled laboratory environment. Moreover, we propose a unified content-type adaptive (UCA) blind image quality assessment model that is applicable across content types. A key step in UCA is to incorporate the variations of human perceptual characteristics in viewing different content types through a multi-scale weighting framework. This leads to superior performance on the constructed CCT database. UCA is training-free, implying strong generalizability. To verify this, we test UCA on other databases containing JPEG, MPEG-2, H.264, and HEVC compressed images/videos, and observe that it consistently achieves competitive performance.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{11}
      \field{number}{11}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{title}{Unified {{Blind Quality Assessment}} of {{Compressed Natural}}, {{Graphic}}, and {{Screen Content Images}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{26}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{5462\bibrangedash 5474}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TIP.2017.2735192
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/FCJP6NPM/Min et al. - 2017 - Unified Blind Quality Assessment of Compressed Nat.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/8000398/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/8000398/
      \endverb
    \endentry
    \entry{SCIQ}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=9c42300b0b3bbf9827ee4a6c487490c7}{%
           family={Ni},
           familyi={N\bibinitperiod},
           given={Zhangkai},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8601659a37cae9b8932645c653921e5b}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Lin},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6b78353626b7ef8b21555f733da16b90}{%
           family={Zeng},
           familyi={Z\bibinitperiod},
           given={Huanqiang},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=11c05b885f1bc92570da26e49722e81d}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Jing},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=303437312f7cdcac2a16a360f776ae19}{%
           family={Cai},
           familyi={C\bibinitperiod},
           given={Canhui},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cd16103d76b32c3a006e7b7ad54f13c5}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Kai-Kuang},
           giveni={K\bibinithyphendelim K\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{6c4a826b8d6c30eb9890ddf80eedeb09}
      \strng{fullhash}{25988e9cf43c1bdbd64c9a3e1fd02cfc}
      \strng{bibnamehash}{25988e9cf43c1bdbd64c9a3e1fd02cfc}
      \strng{authorbibnamehash}{25988e9cf43c1bdbd64c9a3e1fd02cfc}
      \strng{authornamehash}{6c4a826b8d6c30eb9890ddf80eedeb09}
      \strng{authorfullhash}{25988e9cf43c1bdbd64c9a3e1fd02cfc}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In this paper, an accurate full-reference image quality assessment (IQA) model developed for assessing screen content images (SCIs), called the edge similarity (ESIM), is proposed. It is inspired by the fact that the human visual system (HVS) is highly sensitive to edges that are often encountered in SCIs; therefore, essential edge features are extracted and exploited for conducting IQA for the SCIs. The key novelty of the proposed ESIM lies in the extraction and use of three salient edge features—i.e., edge contrast, edge width, and edge direction. The first two attributes are simultaneously generated from the input SCI based on a parametric edge model, while the last one is derived directly from the input SCI. The extraction of these three features will be performed for the reference SCI and the distorted SCI, individually. The degree of similarity measured for each above-mentioned edge attribute is then computed independently, followed by combining them together using our proposed edge-width pooling strategy to generate the final ESIM score. To conduct the performance evaluation of our proposed ESIM model, a new and the largest SCI database (denoted as SCID) is established in our work and made to the public for download. Our database contains 1800 distorted SCIs that are generated from 40 reference SCIs. For each SCI, nine distortion types are investigated, and five degradation levels are produced for each distortion type. Extensive simulation results have clearly shown that the proposed ESIM model is more consistent with the perception of the HVS on the evaluation of distorted SCIs than the multiple state-of-the-art IQA methods.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{10}
      \field{number}{10}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{shorttitle}{{{ESIM}}}
      \field{title}{{{ESIM}}: {{Edge Similarity}} for {{Screen Content Image Quality Assessment}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{26}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{4818\bibrangedash 4831}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1109/TIP.2017.2718185
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/KUNRFCHU/Ni et al. - 2017 - ESIM Edge Similarity for Screen Content Image Qua.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/7954714/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/7954714/
      \endverb
    \endentry
    \entry{PAD-UFES-20}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=d9fef9544610b0b771a7c79d6e4087ec}{%
           family={Pacheco},
           familyi={P\bibinitperiod},
           given={Andre\bibnamedelima G.C.},
           giveni={A\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a71b4c6ee0af0a5030c2d47206795bf3}{%
           family={Krohling},
           familyi={K\bibinitperiod},
           given={Renato\bibnamedelima A.},
           giveni={R\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{086a5903b7cd94f3f3b4c8b062f70c43}
      \strng{fullhash}{086a5903b7cd94f3f3b4c8b062f70c43}
      \strng{bibnamehash}{086a5903b7cd94f3f3b4c8b062f70c43}
      \strng{authorbibnamehash}{086a5903b7cd94f3f3b4c8b062f70c43}
      \strng{authornamehash}{086a5903b7cd94f3f3b4c8b062f70c43}
      \strng{authorfullhash}{086a5903b7cd94f3f3b4c8b062f70c43}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Skin cancer is one of the most common types of cancer worldwide. Over the past few years, different approaches have been proposed to deal with automated skin cancer detection. Nonetheless, most of them are based only on dermoscopic images and do not take into account the patient clinical information, an important clue towards clinical diagnosis. In this work, we present an approach to fill this gap. First, we introduce a new dataset composed of clinical images, collected using smartphones, and clinical data related to the patient. Next, we propose a straightforward method that includes an aggregation mechanism in well-known deep learning models to combine features from images and clinical data. Last, we carry out experiments to compare the models’ performance with and without using this mechanism. The results present an improvement of approximately 7\% in balanced accuracy when the aggregation method is applied. Overall, the impact of clinical data on models’ performance is significant and shows the importance of including these features on automated skin cancer detection.}
      \field{issn}{00104825}
      \field{journaltitle}{Computers in Biology and Medicine}
      \field{langid}{english}
      \field{month}{1}
      \field{shortjournal}{Computers in Biology and Medicine}
      \field{title}{The Impact of Patient Clinical Information on Automated Skin Cancer Detection}
      \field{urlday}{28}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{116}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{103545}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1016/j.compbiomed.2019.103545
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/8GRBMVLI/Pacheco und Krohling - 2020 - The impact of patient clinical information on auto.pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0010482519304019
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0010482519304019
      \endverb
    \endentry
    \entry{TID2013}{article}{}
      \name{author}{11}{}{%
        {{un=0,uniquepart=base,hash=6b0ff13763f4a453b1d67bcef505c432}{%
           family={Ponomarenko},
           familyi={P\bibinitperiod},
           given={Nikolay},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=907fb6d00ff75c72b6d853ef1774f7f3}{%
           family={Jin},
           familyi={J\bibinitperiod},
           given={Lina},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1fe31832eb20800c7cd39d1cad85d7c9}{%
           family={Ieremeiev},
           familyi={I\bibinitperiod},
           given={Oleg},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fb49a7d26e4975bcb180af4a1fb7c99c}{%
           family={Lukin},
           familyi={L\bibinitperiod},
           given={Vladimir},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=72943da991b92fae8d3fcb28a3080793}{%
           family={Egiazarian},
           familyi={E\bibinitperiod},
           given={Karen},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4e0efd455d29950438dd83f5832f2921}{%
           family={Astola},
           familyi={A\bibinitperiod},
           given={Jaakko},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4a4f6b7f29f29613b2d443fbb6c58666}{%
           family={Vozel},
           familyi={V\bibinitperiod},
           given={Benoit},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=66695ef8124fdf52d033aff69af5bcae}{%
           family={Chehdi},
           familyi={C\bibinitperiod},
           given={Kacem},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f63fd57cf4abe0aec29baf824c417de2}{%
           family={Carli},
           familyi={C\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=98456d3cec333fcf3f72e5a9a98bebba}{%
           family={Battisti},
           familyi={B\bibinitperiod},
           given={Federica},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c0aab84e5274fd7546e004e63d60f04e}{%
           family={Jay\bibnamedelima Kuo},
           familyi={J\bibinitperiod\bibinitdelim K\bibinitperiod},
           given={C.-C.},
           giveni={C\bibinithyphendelim C\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{eaa11fffd3aeed1bc200d020c1b222b5}
      \strng{fullhash}{4e34179dbf744081b7a35d5b2fa6931a}
      \strng{bibnamehash}{4e34179dbf744081b7a35d5b2fa6931a}
      \strng{authorbibnamehash}{4e34179dbf744081b7a35d5b2fa6931a}
      \strng{authornamehash}{eaa11fffd3aeed1bc200d020c1b222b5}
      \strng{authorfullhash}{4e34179dbf744081b7a35d5b2fa6931a}
      \field{extraname}{1}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper describes a recently created image database, TID2013, intended for evaluation of full-reference visual quality assessment metrics. With respect to TID2008, the new database contains a larger number (3000) of test images obtained from 25 reference images, 24 types of distortions for each reference image, and 5 levels for each type of distortion. Motivations for introducing 7 new types of distortions and one additional level of distortions are given; examples of distorted images are presented. Mean opinion scores (MOS) for the new database have been collected by performing 985 subjective experiments with volunteers (observers) from five countries (Finland, France, Italy, Ukraine, and USA). The availability of MOS allows the use of the designed database as a fundamental tool for assessing the effectiveness of visual quality. Furthermore, existing visual quality metrics have been tested with the proposed database and the collected results have been analyzed using rank order correlation coefficients between MOS and considered metrics. These correlation indices have been obtained both considering the full set of distorted images and specific image subsets, for highlighting advantages and drawbacks of existing, state of the art, quality metrics. Approaches to thorough performance analysis for a given metric are presented to detect practical situations or distortion types for which this metric is not adequate enough to human perception. The created image database and the collected MOS values are freely available for downloading and utilization for scientific purposes.}
      \field{issn}{09235965}
      \field{journaltitle}{Signal Processing: Image Communication}
      \field{langid}{english}
      \field{month}{1}
      \field{shortjournal}{Signal Processing: Image Communication}
      \field{shorttitle}{Image Database {{TID2013}}}
      \field{title}{Image Database {{TID2013}}: {{Peculiarities}}, Results and Perspectives}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{30}
      \field{year}{2015}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{57\bibrangedash 77}
      \range{pages}{21}
      \verb{doi}
      \verb 10.1016/j.image.2014.10.009
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/NSWLLPSB/Ponomarenko et al. - 2015 - Image database TID2013 Peculiarities, results and.pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0923596514001490
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0923596514001490
      \endverb
    \endentry
    \entry{TID2008}{article}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=6b0ff13763f4a453b1d67bcef505c432}{%
           family={Ponomarenko},
           familyi={P\bibinitperiod},
           given={Nikolay},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fb49a7d26e4975bcb180af4a1fb7c99c}{%
           family={Lukin},
           familyi={L\bibinitperiod},
           given={Vladimir},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=666e9bd7b942482665d8772f7b7971bb}{%
           family={Zelensky},
           familyi={Z\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=72943da991b92fae8d3fcb28a3080793}{%
           family={Egiazarian},
           familyi={E\bibinitperiod},
           given={Karen},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4e0efd455d29950438dd83f5832f2921}{%
           family={Astola},
           familyi={A\bibinitperiod},
           given={Jaakko},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f63fd57cf4abe0aec29baf824c417de2}{%
           family={Carli},
           familyi={C\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=98456d3cec333fcf3f72e5a9a98bebba}{%
           family={Battisti},
           familyi={B\bibinitperiod},
           given={Federica},
           giveni={F\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{eaa11fffd3aeed1bc200d020c1b222b5}
      \strng{fullhash}{83f7028eeea63dc208b91cb2fa48a4c0}
      \strng{bibnamehash}{83f7028eeea63dc208b91cb2fa48a4c0}
      \strng{authorbibnamehash}{83f7028eeea63dc208b91cb2fa48a4c0}
      \strng{authornamehash}{eaa11fffd3aeed1bc200d020c1b222b5}
      \strng{authorfullhash}{83f7028eeea63dc208b91cb2fa48a4c0}
      \field{extraname}{2}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, a new image database, TID2008, for evaluation of full-reference visual quality assessment metrics is described. It contains 1700 test images (25 reference images, 17 types of distortions for each reference image, 4 different levels of each type of distortion). Mean Opinion Scores (MOS) for this database have been obtained as a result of more than 800 experiments. During these tests, observers from three countries (Finland, Italy, and Ukraine) have carried out about 256000 individual human quality judgments. The obtained MOS can be used for effective testing of different visual quality metrics as well as for the design of new metrics. Using the designed image database, we have tested several known quality metrics. The designed test image database is freely available for downloading and utilization in scientific investigations.}
      \field{langid}{english}
      \field{month}{1}
      \field{title}{{{TID2008}} – {{A Database}} for {{Evaluation}} of {{Full- Reference Visual Quality Assessment Metrics}}}
      \field{year}{2009}
      \field{dateera}{ce}
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/M93CPMPI/Ponomarenko et al. - TID2008 – A Database for Evaluation of Full- Refer.pdf
      \endverb
    \endentry
    \entry{LIVE}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=84051ed6c4d99d3ccc763a9bfdfd28a8}{%
           family={Sheikh},
           familyi={S\bibinitperiod},
           given={H.R.},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2334097f18452e6d91139d8b12e6223c}{%
           family={Sabir},
           familyi={S\bibinitperiod},
           given={M.F.},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6192fbf30c45211fdfc67652236bec72}{%
           family={Bovik},
           familyi={B\bibinitperiod},
           given={A.C.},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{60b8bf6e07bbc3f0a1175b5fdca492f2}
      \strng{fullhash}{183b9ff62727cc10f604641f986c09bb}
      \strng{bibnamehash}{183b9ff62727cc10f604641f986c09bb}
      \strng{authorbibnamehash}{183b9ff62727cc10f604641f986c09bb}
      \strng{authornamehash}{60b8bf6e07bbc3f0a1175b5fdca492f2}
      \strng{authorfullhash}{183b9ff62727cc10f604641f986c09bb}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Measurement of visual quality is of fundamental importance for numerous image and video processing applications, where the goal of quality assessment (QA) algorithms is to automatically assess the quality of images or videos in agreement with human quality judgments. Over the years, many researchers have taken different approaches to the problem and have contributed significant research in this area and claim to have made progress in their respective domains. It is important to evaluate the performance of these algorithms in a comparative setting and analyze the strengths and weaknesses of these methods. In this paper, we present results of an extensive subjective quality assessment study in which a total of 779 distorted images were evaluated by about two dozen human subjects. The “ground truth” image quality data obtained from about 25 000 individual human quality judgments is used to evaluate the performance of several prominent full-reference image quality assessment algorithms. To the best of our knowledge, apart from video quality studies conducted by the Video Quality Experts Group, the study presented in this paper is the largest subjective image quality study in the literature in terms of number of images, distortion types, and number of human judgments per image. Moreover, we have made the data from the study freely available to the research community [1]. This would allow other researchers to easily report comparative results in the future.}
      \field{issn}{1057-7149}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{11}
      \field{number}{11}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{title}{A {{Statistical Evaluation}} of {{Recent Full Reference Image Quality Assessment Algorithms}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{15}
      \field{year}{2006}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{3440\bibrangedash 3451}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/TIP.2006.881959
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/8F2JWIAS/Sheikh et al. - 2006 - A Statistical Evaluation of Recent Full Reference .pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/1709988/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/1709988/
      \endverb
    \endentry
    \entry{MDID2016}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=4a71f03f723a983aabae2662ac156d9f}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Wen},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7c8ea78b26e5365d21c23659d9b4f074}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Fei},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=736e79ce2ca1a08fe56752b8e0af07e3}{%
           family={Liao},
           familyi={L\bibinitperiod},
           given={Qingmin},
           giveni={Q\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{f53481d5258202a126a9be4c28902e7f}
      \strng{fullhash}{e720cb32b22801f81c74f57f1eab3b26}
      \strng{bibnamehash}{e720cb32b22801f81c74f57f1eab3b26}
      \strng{authorbibnamehash}{e720cb32b22801f81c74f57f1eab3b26}
      \strng{authornamehash}{f53481d5258202a126a9be4c28902e7f}
      \strng{authorfullhash}{e720cb32b22801f81c74f57f1eab3b26}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In this paper, we present a new database, the multiply distorted image database (MDID), to evaluate image quality assessment (IQA) metrics on multiply distorted images. The database contains 20 reference images and 1600 distorted images. The latter images are obtained by contamination of the former with multiple distortions of random types and levels, so multiple types of distortions appear in each distorted image. Pair comparison sorting (PCS) is used as a new subjective rating method to evaluate image quality. This method allows subjects to make equal decisions on images whose difference in quality cannot be easily evaluated visually. A total of 192 subjects participated in the subjective rating, in which mean opinion scores and standard deviations were obtained. In IQA research, subjective scores and algorithm predictions are generally related by a nonlinear regression. We further propose a method to initialize the parameters of the nonlinear regression. The experiments of IQA metrics conducted on MDID validate that this database is advisable and challenging.}
      \field{issn}{00313203}
      \field{journaltitle}{Pattern Recognition}
      \field{langid}{english}
      \field{month}{1}
      \field{shortjournal}{Pattern Recognition}
      \field{shorttitle}{{{MDID}}}
      \field{title}{{{MDID}}: {{A}} Multiply Distorted Image Database for Image Quality Assessment}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{61}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{153\bibrangedash 168}
      \range{pages}{16}
      \verb{doi}
      \verb 10.1016/j.patcog.2016.07.033
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/JY7KJWKT/Sun et al. - 2017 - MDID A multiply distorted image database for imag.pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0031320316301911
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0031320316301911
      \endverb
    \endentry
    \entry{CID2013}{article}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=615c6826672471ff60b2d75da0020ced}{%
           family={Virtanen},
           familyi={V\bibinitperiod},
           given={Toni},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2c8e334e3ec64237c89b96f6f6dcee30}{%
           family={Nuutinen},
           familyi={N\bibinitperiod},
           given={Mikko},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c68ab1345a264730e85774b5e5fd34a9}{%
           family={Vaahteranoksa},
           familyi={V\bibinitperiod},
           given={Mikko},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=29ea3694c2bb063a2a643f72e5714d79}{%
           family={Oittinen},
           familyi={O\bibinitperiod},
           given={Pirkko},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=80a1211c5bf6d287819b70deed6eb327}{%
           family={Hakkinen},
           familyi={H\bibinitperiod},
           given={Jukka},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{e24786bd08b9de7985bad8323d0b8513}
      \strng{fullhash}{cc14904a43c60badb56949cfec98d6b1}
      \strng{bibnamehash}{cc14904a43c60badb56949cfec98d6b1}
      \strng{authorbibnamehash}{cc14904a43c60badb56949cfec98d6b1}
      \strng{authornamehash}{e24786bd08b9de7985bad8323d0b8513}
      \strng{authorfullhash}{cc14904a43c60badb56949cfec98d6b1}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper presents a new database, CID2013, to address the issue of using no-reference (NR) image quality assessment algorithms on images with multiple distortions. Current NR algorithms struggle to handle images with many concurrent distortion types, such as real photographic images captured by different digital cameras. The database consists of six image sets; on average, 30 subjects have evaluated 12–14 devices depicting eight different scenes for a total of 79 different cameras, 480 images, and 188 subjects (67\% female). The subjective evaluation method was a hybrid absolute category rating-pair comparison developed for the study and presented in this paper. This method utilizes a slideshow of all images within a scene to allow the test images to work as references to each other. In addition to mean opinion score value, the images are also rated using sharpness, graininess, lightness, and color saturation scales. The CID2013 database contains images used in the experiments with the full subjective data plus extensive background information from the subjects. The database is made freely available for the research community.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{shorttitle}{{{CID2013}}}
      \field{title}{{{CID2013}}: {{A Database}} for {{Evaluating No-Reference Image Quality Assessment Algorithms}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{24}
      \field{year}{2015}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{390\bibrangedash 402}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TIP.2014.2378061
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/KHXSACRZ/Virtanen et al. - 2015 - CID2013 A Database for Evaluating No-Reference Im.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6975172/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6975172/
      \endverb
    \endentry
    \entry{TrueImage}{online}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=727a8a479e533213d5df986b6f2d695e}{%
           family={Vodrahalli},
           familyi={V\bibinitperiod},
           given={Kailas},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0df7931cf6d169c0892a3a00ce803ffa}{%
           family={Daneshjou},
           familyi={D\bibinitperiod},
           given={Roxana},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7dcf7c517335b316301b5a23b218557b}{%
           family={Novoa},
           familyi={N\bibinitperiod},
           given={Roberto\bibnamedelima A.},
           giveni={R\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f8bf81fdd5ba316aafc4d84f3492fdc6}{%
           family={Chiou},
           familyi={C\bibinitperiod},
           given={Albert},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fafb26071e10025682d74122178dcdc3}{%
           family={Ko},
           familyi={K\bibinitperiod},
           given={Justin\bibnamedelima M.},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1b868d50048a635fa27ffa744323fa41}{%
           family={Zou},
           familyi={Z\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{5d4a1468e52078d03ee41bac58856ba8}
      \strng{fullhash}{1ff7a5aba214426ed147e083823e40b6}
      \strng{bibnamehash}{1ff7a5aba214426ed147e083823e40b6}
      \strng{authorbibnamehash}{1ff7a5aba214426ed147e083823e40b6}
      \strng{authornamehash}{5d4a1468e52078d03ee41bac58856ba8}
      \strng{authorfullhash}{1ff7a5aba214426ed147e083823e40b6}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Telehealth is an increasingly critical component of the health care ecosystem, especially due to the COVID-19 pandemic. Rapid adoption of telehealth has exposed limitations in the existing infrastructure. In this paper, we study and highlight photo quality as a major challenge in the telehealth workflow. We focus on teledermatology, where photo quality is particularly important; the framework proposed here can be generalized to other health domains. For telemedicine, dermatologists request that patients submit images of their lesions for assessment. However, these images are often of insufficient quality to make a clinical diagnosis since patients do not have experience taking clinical photos. A clinician has to manually triage poor quality images and request new images to be submitted, leading to wasted time for both the clinician and the patient. We propose an automated image assessment machine learning pipeline, TrueImage, to detect poor quality dermatology photos and to guide patients in taking better photos. Our experiments indicate that TrueImage can reject 50\% of the sub-par quality images, while retaining 80\% of good quality images patients send in, despite heterogeneity and limitations in the training data. These promising results suggest that our solution is feasible and can improve the quality of teledermatology care.}
      \field{day}{1}
      \field{eprintclass}{cs, eess}
      \field{eprinttype}{arxiv}
      \field{month}{10}
      \field{shorttitle}{{{TrueImage}}}
      \field{title}{{{TrueImage}}: {{A Machine Learning Algorithm}} to {{Improve}} the {{Quality}} of {{Telehealth Photos}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2010.02086
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/ZHAJZ8H3/Vodrahalli et al. - 2020 - TrueImage A Machine Learning Algorithm to Improve.pdf;/Users/choekyelnyungmartsang/Zotero/storage/J95RUXP7/2010.html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2010.02086
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2010.02086
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition,Computer Science - Computers and Society,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Signal Processing}
    \endentry
    \entry{SCIN}{online}{}
      \name{author}{20}{}{%
        {{un=0,uniquepart=base,hash=157eeb7ce96413ee755bd0cfc3fd3171}{%
           family={Ward},
           familyi={W\bibinitperiod},
           given={Abbi},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=968d50258df8e602bdff89292ed04f7e}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Jimmy},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=74ed6c812a6076b83c7d60b4ed25c56b}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Julie},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3594b4311617d31637c712574c23a86a}{%
           family={Lakshminarasimhan},
           familyi={L\bibinitperiod},
           given={Sriram},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6b651bbe7b5a39a7d2c8f18e8c23ffa3}{%
           family={Carrick},
           familyi={C\bibinitperiod},
           given={Ashley},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b8b84659f2ef971f9084812de41a996d}{%
           family={Campana},
           familyi={C\bibinitperiod},
           given={Bilson},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=63a749c918287d0d110056a35fefab13}{%
           family={Hartford},
           familyi={H\bibinitperiod},
           given={Jay},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9378442568d686a831bd5825320c1ef1}{%
           family={S},
           familyi={S\bibinitperiod},
           given={Pradeep\bibnamedelima Kumar},
           giveni={P\bibinitperiod\bibinitdelim K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3e3132e6f6ad493ee0ea0ddc316159b7}{%
           family={Tiyasirichokchai},
           familyi={T\bibinitperiod},
           given={Tiya},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=191bc273a5f531232c05b746f242e5ef}{%
           family={Virmani},
           familyi={V\bibinitperiod},
           given={Sunny},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0ef6f4906fe6a3689db39f9ba23e0753}{%
           family={Wong},
           familyi={W\bibinitperiod},
           given={Renee},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=46fb71a11e070da3ec8e9ff62a75ddef}{%
           family={Matias},
           familyi={M\bibinitperiod},
           given={Yossi},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=84d9f354fa0b45dae996f27dad2c6607}{%
           family={Corrado},
           familyi={C\bibinitperiod},
           given={Greg\bibnamedelima S.},
           giveni={G\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d38a80bf82831fe5c4d0f850a77ddff9}{%
           family={Webster},
           familyi={W\bibinitperiod},
           given={Dale\bibnamedelima R.},
           giveni={D\bibinitperiod\bibinitdelim R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a6468eba3b866893d49ff041b27ebc90}{%
           family={Siegel},
           familyi={S\bibinitperiod},
           given={Dawn},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d1a8967b0a24afdb7417d43b5c02a5fe}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Steven},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d5274c1d02c20ebd471b200127fcee09}{%
           family={Ko},
           familyi={K\bibinitperiod},
           given={Justin},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=45aacfb5c7248e226c7bc1188c1e4e00}{%
           family={Karthikesalingam},
           familyi={K\bibinitperiod},
           given={Alan},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9ee01be967ae8313a09a6ac2ac566cfa}{%
           family={Semturs},
           familyi={S\bibinitperiod},
           given={Christopher},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=237ccb6307c5f44294cf3c1a86f20f37}{%
           family={Rao},
           familyi={R\bibinitperiod},
           given={Pooja},
           giveni={P\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{3c84a7ffa1295ec35976dd43530332b3}
      \strng{fullhash}{edfdba1ab1637c9e2621d6b53c909a62}
      \strng{bibnamehash}{edfdba1ab1637c9e2621d6b53c909a62}
      \strng{authorbibnamehash}{edfdba1ab1637c9e2621d6b53c909a62}
      \strng{authornamehash}{3c84a7ffa1295ec35976dd43530332b3}
      \strng{authorfullhash}{edfdba1ab1637c9e2621d6b53c909a62}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Background: Health datasets from clinical sources do not reflect the breadth and diversity of disease in the real world, impacting research, medical education, and artificial intelligence (AI) tool development. Dermatology is a suitable area to develop and test a new and scalable method to create representative health datasets. Methods: We used Google Search advertisements to invite contributions to an open access dataset of images of dermatology conditions, demographic, and symptom information. With informed contributor consent, we describe and release this dataset containing 10,408 images from 5,033 contributions from internet users in the United States over 8 months starting March 2023. The dataset includes dermatologist condition labels as well as estimated Fitzpatrick Skin Type (eFST) and Monk Skin Tone (eMST) labels for the images. Results: We received a median of 22 submissions/day (IQR 14–30). Female (66.72\%) and younger (52\% {$<$} age 40) contributors had a higher representation in the dataset compared to the US population, and 32.6\% of contributors reported a non-White racial or ethnic identity. Over 97.5\% of contributions were genuine images of skin conditions. Dermatologist confidence in assigning a differential diagnosis increased with the number of available variables, and showed a weak correlation with image sharpness (Spearman’s P values {$<$} 0.001 and 0.01 respectively). Most contributions were short-duration (54\% with onset {$<$} 7 days ago ) and 89\% were allergic, infectious, or inflammatory conditions. eFST and eMST distributions reflected the geographical origin of the dataset. The dataset is available at github.com/google-researchdatasets/scin. Conclusion: Search ads are effective at crowdsourcing images of health conditions. The SCIN dataset bridges important gaps in the availability of representative images of common skin conditions.}
      \field{day}{28}
      \field{eprintclass}{cs}
      \field{eprinttype}{arxiv}
      \field{langid}{english}
      \field{month}{2}
      \field{shorttitle}{Crowdsourcing {{Dermatology Images}} with {{Google Search Ads}}}
      \field{title}{Crowdsourcing {{Dermatology Images}} with {{Google Search Ads}}: {{Creating}} a {{Real-World Skin Condition Dataset}}}
      \field{urlday}{28}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2024}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2402.18545
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/UQGXAEAY/Ward et al. - 2024 - Crowdsourcing Dermatology Images with Google Searc.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2402.18545
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2402.18545
      \endverb
      \keyw{Computer Science - Computers and Society}
    \endentry
    \entry{ACNE04}{article}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=1e9a188f2fe0d90e12f60cc057f247e9}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Xiaoping},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e75d9f8e33d3b19f37af6bfbb75ee3d8}{%
           family={Wen},
           familyi={W\bibinitperiod},
           given={Ni},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2fdd02cf869cd5db2eb76ef827bb449d}{%
           family={Liang},
           familyi={L\bibinitperiod},
           given={Jie},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4bb63a56d1c146994bcd32b61ecddbf9}{%
           family={Lai},
           familyi={L\bibinitperiod},
           given={Yu-Kun},
           giveni={Y\bibinithyphendelim K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=24aa2bf674e02bf6de471f2763a3ee86}{%
           family={She},
           familyi={S\bibinitperiod},
           given={Dongyu},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bfbe355b6a8257baeffd5b8814bc5c57}{%
           family={Cheng},
           familyi={C\bibinitperiod},
           given={Ming-Ming},
           giveni={M\bibinithyphendelim M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=658c76617bcffe77e2bd3f068cf03c67}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Jufeng},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Seoul, Korea (South)}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{c452610eaf09b5680fcfd3167d1cd188}
      \strng{fullhash}{308851af87d512d2a5468470587a057c}
      \strng{bibnamehash}{308851af87d512d2a5468470587a057c}
      \strng{authorbibnamehash}{308851af87d512d2a5468470587a057c}
      \strng{authornamehash}{c452610eaf09b5680fcfd3167d1cd188}
      \strng{authorfullhash}{308851af87d512d2a5468470587a057c}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Accurate grading of skin disease severity plays a crucial role in precise treatment for patients. Acne vulgaris, the most common skin disease in adolescence, can be graded by evidence-based lesion counting as well as experiencebased global estimation in the medical field. However, due to the appearance similarity of acne with close severity, it is challenging to count and grade acne accurately. In this paper, we address the problem of acne image analysis via Label Distribution Learning (LDL) considering the ambiguous information among acne severity. Based on the professional grading criterion, we generate two acne label distributions considering the relationship between the similar number of lesions and severity of acne, respectively. We also propose a unified framework for joint acne image grading and counting, which is optimized by the multi-task learning loss. In addition, we further build the ACNE04 dataset with annotations of acne severity and lesion number of each image for evaluation. Experiments demonstrate that our proposed framework performs favorably against stateof-the-art methods. We make the code and dataset publicly available at https://github.com/xpwu95/ldl.}
      \field{eventtitle}{2019 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})}
      \field{isbn}{978-1-72814-803-8}
      \field{journaltitle}{2019 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})}
      \field{langid}{english}
      \field{month}{10}
      \field{title}{Joint {{Acne Image Grading}} and {{Counting}} via {{Label Distribution Learning}}}
      \field{urlday}{28}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{10641\bibrangedash 10650}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/ICCV.2019.01074
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/43KJG5LJ/Wu et al. - 2019 - Joint Acne Image Grading and Counting via Label Di.pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/9010021/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/9010021/
      \endverb
    \endentry
    \entry{SIQAD}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=20c90b2c7ed4d1d31d2f648c075f6c90}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Huan},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d3a448d23a1b82215bcec1d99bd62be9}{%
           family={{Yuming Fang}},
           familyi={Y\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=ef82e2e99c11391b0d3372d3bf096101}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Weisi},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f244e8ae5eff7776cf2b4b5b84ad8c4a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhou},
           giveni={Z\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Singapore, Singapore}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{8969d129e834b307511063481c2617d5}
      \strng{fullhash}{e66dc206f4d5df2b4d3f10a64a29b763}
      \strng{bibnamehash}{e66dc206f4d5df2b4d3f10a64a29b763}
      \strng{authorbibnamehash}{e66dc206f4d5df2b4d3f10a64a29b763}
      \strng{authornamehash}{8969d129e834b307511063481c2617d5}
      \strng{authorfullhash}{e66dc206f4d5df2b4d3f10a64a29b763}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Research on Screen Content Images (SCIs) becomes important as they are increasingly used in multi-device communication applications. In this paper, we present a study of subjective quality assessment for distorted SCIs, and investigate which part (text or picture) contributes more to the overall visual quality. We construct a large-scale Screen Image Quality Assessment Database (SIQAD) consisting of 20 source and 980 distorted SCIs. The 11-category Absolute Category Rating (ACR) is employed to obtain three subjective quality scores corresponding to the entire image, textual and pictorial regions respectively. Based on the subjective data, we investigate the applicability of 12 state-of-the-art Image Quality Assessment (IQA) methods for objectively assessing the quality of SCIs. The results indicate that existing IQA methods are limited in predicting human quality judgement of SCIs. Moreover, we propose a prediction model to account for the correlation between the subjective scores of textual and pictorial regions and the entire image. The current results make an initial move towards objective quality assessment of SCIs.}
      \field{eventtitle}{2014 {{Sixth International Workshop}} on {{Quality}} of {{Multimedia Experience}} ({{QoMEX}})}
      \field{isbn}{978-1-4799-6536-6}
      \field{journaltitle}{2014 {{Sixth International Workshop}} on {{Quality}} of {{Multimedia Experience}} ({{QoMEX}})}
      \field{langid}{english}
      \field{month}{9}
      \field{title}{Subjective Quality Assessment of {{Screen Content Images}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{257\bibrangedash 262}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/QoMEX.2014.6982328
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/46AJMFUP/Yang et al. - 2014 - Subjective quality assessment of Screen Content Im.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6982328/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6982328/
      \endverb
    \endentry
  \enddatalist
\endrefsection
\endinput

