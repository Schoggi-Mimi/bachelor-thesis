% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{apa/apasortcite//global/global}
    \entry{ARNIQA}{online}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=aa83122097905bf500be2f88e74d627f}{%
           family={Agnolucci},
           familyi={A\bibinitperiod},
           given={Lorenzo},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=653187c5fa949d389d18b815f0493cc6}{%
           family={Galteri},
           familyi={G\bibinitperiod},
           given={Leonardo},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=71c3126324af7ecd81c3870d46cd25b7}{%
           family={Bertini},
           familyi={B\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=20db68b33ce9530f55f14524fbfb14a2}{%
           family={Del\bibnamedelima Bimbo},
           familyi={D\bibinitperiod\bibinitdelim B\bibinitperiod},
           given={Alberto},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{2a62fec986d80f4d681fb14a8ad424a9}
      \strng{fullhash}{8aebff667f68a289b6c628110e185b00}
      \strng{bibnamehash}{8aebff667f68a289b6c628110e185b00}
      \strng{authorbibnamehash}{8aebff667f68a289b6c628110e185b00}
      \strng{authornamehash}{2a62fec986d80f4d681fb14a8ad424a9}
      \strng{authorfullhash}{8aebff667f68a289b6c628110e185b00}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{No-Reference Image Quality Assessment (NR-IQA) aims to develop methods to measure image quality in alignment with human perception without the need for a high-quality reference image. In this work, we propose a self-supervised approach named ARNIQA (leArning distoRtion maNifold for Image Quality Assessment) for modeling the image distortion manifold to obtain quality representations in an intrinsic manner. First, we introduce an image degradation model that randomly composes ordered sequences of consecutively applied distortions. In this way, we can synthetically degrade images with a large variety of degradation patterns. Second, we propose to train our model by maximizing the similarity between the representations of patches of different images distorted equally, despite varying content. Therefore, images degraded in the same manner correspond to neighboring positions within the distortion manifold. Finally, we map the image representations to the quality scores with a simple linear regressor, thus without fine-tuning the encoder weights. The experiments show that our approach achieves state-of-the-art performance on several datasets. In addition, ARNIQA demonstrates improved data efficiency, generalization capabilities, and robustness compared to competing methods. The code and the model are publicly available at https://github.com/ miccunifi/ARNIQA.}
      \field{day}{4}
      \field{eprintclass}{cs}
      \field{eprinttype}{arxiv}
      \field{langid}{english}
      \field{month}{11}
      \field{shorttitle}{{{ARNIQA}}}
      \field{title}{{{ARNIQA}}: {{Learning Distortion Manifold}} for {{Image Quality Assessment}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2310.14918
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/FT9WTHT5/Agnolucci et al. - 2023 - ARNIQA Learning Distortion Manifold for Image Qua.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2310.14918
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2310.14918
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{CSIQ}{article}{}
      \name{author}{1}{}{%
        {{un=1,uniquepart=given,hash=c5addfdd7f1dd742dac1643e46f25ee6}{%
           family={Chandler},
           familyi={C\bibinitperiod},
           given={Damon\bibnamedelima M.},
           giveni={D\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=1}}%
      }
      \strng{namehash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{fullhash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{bibnamehash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{authorbibnamehash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{authornamehash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{authorfullhash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{day}{1}
      \field{issn}{1017-9909}
      \field{journaltitle}{Journal of Electronic Imaging}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{J. Electron. Imaging}
      \field{shorttitle}{Most Apparent Distortion}
      \field{title}{Most Apparent Distortion: Full-Reference Image Quality Assessment and the Role of Strategy}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{19}
      \field{year}{2010}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{011006}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1117/1.3267105
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/ND7PFFNY/Chandler - 2010 - Most apparent distortion full-reference image qua.pdf
      \endverb
      \verb{urlraw}
      \verb https://s2.smu.edu/~eclarson/pubs/2010JEI_MAD.pdf
      \endverb
      \verb{url}
      \verb https://s2.smu.edu/~eclarson/pubs/2010JEI_MAD.pdf
      \endverb
    \endentry
    \entry{A57}{article}{}
      \name{author}{2}{}{%
        {{un=1,uniquepart=given,hash=52a422f501ab24ced4fed94ce0226e40}{%
           family={Chandler},
           familyi={C\bibinitperiod},
           given={D.M.},
           giveni={D\bibinitperiod},
           givenun=1}}%
        {{un=0,uniquepart=base,hash=e4622e95fefb83373d9614ae9c8ce220}{%
           family={Hemami},
           familyi={H\bibinitperiod},
           given={S.S.},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{fullhash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{bibnamehash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{authorbibnamehash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{authornamehash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{authorfullhash}{1ea3294ab1b80857b24a400ac4e1c519}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper presents an efficient metric for quantifying the visual fidelity of natural images based on near-threshold and suprathreshold properties of human vision. The proposed metric, the visual signal-to-noise ratio (VSNR), operates via a two-stage approach. In the first stage, contrast thresholds for detection of distortions in the presence of natural images are computed via wavelet-based models of visual masking and visual summation in order to determine whether the distortions in the distorted image are visible. If the distortions are below the threshold of detection, the distorted image is deemed to be of perfect visual fidelity (VSNR = ) and no further analysis is required. If the distortions are suprathreshold, a second stage is applied which operates based on the low-level visual property of perceived contrast, and the mid-level visual property of global precedence. These two properties are modeled as Euclidean distances in distortion-contrast space of a multiscale wavelet decomposition, and VSNR is computed based on a simple linear sum of these distances. The proposed VSNR metric is generally competitive with current metrics of visual fidelity; it is efficient both in terms of its low computational complexity and in terms of its low memory requirements; and it operates based on physical luminances and visual angle (rather than on digital pixel values and pixel-based dimensions) to accommodate different viewing conditions.}
      \field{issn}{1057-7149}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{9}
      \field{number}{9}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{shorttitle}{{{VSNR}}}
      \field{title}{{{VSNR}}: {{A Wavelet-Based Visual Signal-to-Noise Ratio}} for {{Natural Images}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{16}
      \field{year}{2007}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2284\bibrangedash 2298}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1109/TIP.2007.901820
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/EW9CANZ4/Chandler und Hemami - 2007 - VSNR A Wavelet-Based Visual Signal-to-Noise Ratio.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/4286985/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/4286985/
      \endverb
    \endentry
    \entry{LIVE_Wild}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=3e0108af1e78568ae823af503315860a}{%
           family={Ghadiyaram},
           familyi={G\bibinitperiod},
           given={Deepti},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d9c2ab9a8cbcab08292923a454c88ce7}{%
           family={Bovik},
           familyi={B\bibinitperiod},
           given={Alan\bibnamedelima C.},
           giveni={A\bibinitperiod\bibinitdelim C\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{fullhash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{bibnamehash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{authorbibnamehash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{authornamehash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{authorfullhash}{3cdb959f35d9532ad6b5f9539dc38537}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Most publicly available image quality databases have been created under highly controlled conditions by introducing graded simulated distortions onto high-quality photographs. However, images captured using typical real-world mobile camera devices are usually afflicted by complex mixtures of multiple distortions, which are not necessarily well-modeled by the synthetic distortions found in existing databases. The originators of existing legacy databases usually conducted human psychometric studies to obtain statistically meaningful sets of human opinion scores on images in a stringently controlled visual environment, resulting in small data collections relative to other kinds of image analysis databases. Toward overcoming these limitations, we designed and created a new database that we call the LIVE In the Wild Image Quality Challenge Database, which contains widely diverse authentic image distortions on a large number of images captured using a representative variety of modern mobile devices. We also designed and implemented a new online crowdsourcing system, which we have used to conduct a very large-scale, multi-month image quality assessment (IQA) subjective study. Our database consists of over 350 000 opinion scores on 1162 images evaluated by over 8100 unique human observers. Despite the lack of control over the experimental environments of the numerous study participants, we demonstrate excellent internal consistency of the subjective data set. We also evaluate several top-performing blind IQA algorithms on it and present insights on how the mixtures of distortions challenge both end users as well as automatic perceptual quality prediction models. The new database is available for public use at http://live.ece.utexas.edu/research/ChallengeDB/index.html.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{title}{Massive {{Online Crowdsourced Study}} of {{Subjective}} and {{Objective Picture Quality}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{25}
      \field{year}{2016}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{372\bibrangedash 387}
      \range{pages}{16}
      \verb{doi}
      \verb 10.1109/TIP.2015.2500021
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/NQWGF6QQ/Ghadiyaram und Bovik - 2016 - Massive Online Crowdsourced Study of Subjective an.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/7327186/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/7327186/
      \endverb
    \endentry
    \entry{MDID2013}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=a64df0db3d659a7cb92ab2266cdd6339}{%
           family={Gu},
           familyi={G\bibinitperiod},
           given={Ke},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=de70ef50dd45ba84349c3a3d3d5a9141}{%
           family={Zhai},
           familyi={Z\bibinitperiod},
           given={Guangtao},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=31f1758fe4ad1edbef9504ac0116d1ad}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Xiaokang},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0d9c450eb8905fc9a195a67a39e601af}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Wenjun},
           giveni={W\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{4e5d9e5d83d0e26c4d17cce126315705}
      \strng{fullhash}{4f4df664f870c36e53e9c30c581f479c}
      \strng{bibnamehash}{4f4df664f870c36e53e9c30c581f479c}
      \strng{authorbibnamehash}{4f4df664f870c36e53e9c30c581f479c}
      \strng{authornamehash}{4e5d9e5d83d0e26c4d17cce126315705}
      \strng{authorfullhash}{4f4df664f870c36e53e9c30c581f479c}
      \field{extraname}{1}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In a typical image communication system, the visual signal presented to the end users may undergo the steps of acquisition, compression and transmission which cause the artifacts of blurring, quantization and noise. However, the researches of image quality assessment (IQA) with multiple distortion types are very limited. In this paper, we first introduce a new multiply distorted image database (MDID2013), which is composed of 324 images that are simultaneously corrupted by blurring, JPEG compression and noise injection. We then propose a new six-step blind metric (SISBLIM) for quality assessment of both singly and multiply distorted images. Inspired by the early human visual model and recently revealed free energy based brain theory, our method works to systematically combine the single quality prediction of each emerging distortion type and joint effects of different distortion sources. Comparative studies of the proposed SISBLIM with popular full-reference IQA approaches and start-of-the-art no-reference IQA metrics are conducted on five singly distorted image databases (LIVE, TID2008, CSIQ, IVC, Toyama) and two newly released multiply distorted image databases (LIVEMD, MDID2013). Experimental results confirm the effectiveness of our blind technique. MATLAB codes of the proposed SISBLIM algorithm and MDID2013 database will be available online at http://gvsp.sjtu.edu.cn/.}
      \field{issn}{0018-9316, 1557-9611}
      \field{journaltitle}{IEEE Transactions on Broadcasting}
      \field{langid}{english}
      \field{month}{9}
      \field{number}{3}
      \field{shortjournal}{IEEE Trans. on Broadcast.}
      \field{title}{Hybrid {{No-Reference Quality Metric}} for {{Singly}} and {{Multiply Distorted Images}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{60}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{555\bibrangedash 567}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TBC.2014.2344471
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/B4SN597A/Gu et al. - 2014 - Hybrid No-Reference Quality Metric for Singly and .pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/6879255/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/6879255/
      \endverb
    \endentry
    \entry{HSNID}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=a64df0db3d659a7cb92ab2266cdd6339}{%
           family={Gu},
           familyi={G\bibinitperiod},
           given={Ke},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b6fc78834b479731029a5edb14fd5de0}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Xin},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=14f0dd7dfcfc375a1d3a6b42a2c58757}{%
           family={Qiao},
           familyi={Q\bibinitperiod},
           given={Junfei},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a63ef12742ef71a5a06fcf66d6d72ad7}{%
           family={Jiang},
           familyi={J\bibinitperiod},
           given={Qiuping},
           giveni={Q\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ef82e2e99c11391b0d3372d3bf096101}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Weisi},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=24f20de24938c18a3655f419579d0900}{%
           family={Thalmann},
           familyi={T\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{4e5d9e5d83d0e26c4d17cce126315705}
      \strng{fullhash}{3c429fdd3ef0a5700e5721efbe97dd62}
      \strng{bibnamehash}{3c429fdd3ef0a5700e5721efbe97dd62}
      \strng{authorbibnamehash}{3c429fdd3ef0a5700e5721efbe97dd62}
      \strng{authornamehash}{4e5d9e5d83d0e26c4d17cce126315705}
      \strng{authorfullhash}{3c429fdd3ef0a5700e5721efbe97dd62}
      \field{extraname}{2}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this work, we resolve a big challenge that most current image quality metrics (IQMs) are unavailable across different image contents, especially simultaneously coping with natural scene (NS) images or screen content (SC) images. By comparison with existing works, this paper deploys on-line and off-line data for proposing a unified no-reference (NR) IQM, not only applied to different distortion types and intensities but also to various image contents including classical NS images and prevailing SC images. Our proposed NR IQM is developed with two data-driven learning processes following feature extraction, which is based on scene statistic models, free-energy brain principle, and human visual system (HVS) characteristics. In the first process, the scene statistic models and an image retrieve technique are combined, based on on-line and off-line training instances, to derive a novel loose classifier for retrieving clean images and helping to infer the image content. In the second process, the features extracted by incorporating the inferred image content, free-energy and low-level perceptual characteristics of the HVS are learned by utilizing off-line training samples to analyze the distortion types and intensities and thereby to predict the image quality. The two processes mentioned above depend on a gigantic quantity of training data, much exceeding the number of images applied to performance validation, and thus make our model’s performance more reliable. Through extensive experiments, it has been validated that the proposed blind IQM is capable of simultaneously inferring the quality of NS and SC images, and it has attained superior performance as compared with popular and state-of-the-art IQMs on the subjective NS and SC image quality databases. The source code of our model will be released with the publication of the paper at https://kegu.netlify.com.}
      \field{day}{1}
      \field{issn}{2332-7790, 2372-2096}
      \field{journaltitle}{IEEE Transactions on Big Data}
      \field{langid}{english}
      \field{month}{12}
      \field{number}{4}
      \field{shortjournal}{IEEE Trans. Big Data}
      \field{title}{Learning a {{Unified Blind Image Quality Metric}} via {{On-Line}} and {{Off-Line Big Training Instances}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{6}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{780\bibrangedash 791}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/TBDATA.2019.2895605
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/8K778KAQ/Gu et al. - 2020 - Learning a Unified Blind Image Quality Metric via .pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8627983/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8627983/
      \endverb
    \endentry
    \entry{LIVEMD}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=cd27d3d228b115c84bc1d88310a81f02}{%
           family={Jayaraman},
           familyi={J\bibinitperiod},
           given={Dinesh},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5140f90dfa1ff2db127d5ad357e881ea}{%
           family={Mittal},
           familyi={M\bibinitperiod},
           given={Anish},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0637cd6093dcea240cdcb122b300761b}{%
           family={Moorthy},
           familyi={M\bibinitperiod},
           given={Anush\bibnamedelima K.},
           giveni={A\bibinitperiod\bibinitdelim K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d9c2ab9a8cbcab08292923a454c88ce7}{%
           family={Bovik},
           familyi={B\bibinitperiod},
           given={Alan\bibnamedelima C.},
           giveni={A\bibinitperiod\bibinitdelim C\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Pacific Grove, CA, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{b9473887aa8ef09533091798c76022ef}
      \strng{fullhash}{8fb566e1d8b66be5dca6b5531931decd}
      \strng{bibnamehash}{8fb566e1d8b66be5dca6b5531931decd}
      \strng{authorbibnamehash}{8fb566e1d8b66be5dca6b5531931decd}
      \strng{authornamehash}{b9473887aa8ef09533091798c76022ef}
      \strng{authorfullhash}{8fb566e1d8b66be5dca6b5531931decd}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Subjective studies have been conducted in the past to obtain human judgments of visual quality on distorted images in order, among other things, to benchmark objective image qual. ity assessment (lQA) algorithms. Existing subjective studies primarily have records of human ratings on images that were corrupted by only one of many possible distortions. However, the majority of images that are available for consumption are corrupted by multiple distortions. Towards broadening the corpora of records of human responses to visual distortions, we recently conducted a study on two types of multiply distorted images to obtain human judgments of the visual quality of such images. Further, we compared the performance of several existing objective image quality measures on the new database and analyze the effects of multiple distortions on commonly used quality-determinant features and on human ratings.}
      \field{eventtitle}{2012 46th {{Asilomar Conference}} on {{Signals}}, {{Systems}} and {{Computers}}}
      \field{journaltitle}{2012 {{Conference Record}} of the {{Forty Sixth Asilomar Conference}} on {{Signals}}, {{Systems}} and {{Computers}} ({{ASILOMAR}})}
      \field{langid}{english}
      \field{month}{11}
      \field{title}{Objective Quality Assessment of Multiply Distorted Images}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2012}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1693\bibrangedash 1697}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/ACSSC.2012.6489321
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/XIL22H3U/Jayaraman et al. - 2012 - Objective quality assessment of multiply distorted.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6489321/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6489321/
      \endverb
    \endentry
    \entry{WED}{article}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=79f9b1044b245e49f7e431dfc1b96bbd}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Kede},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9aec47e12e3d6fbc7bdca7a5da683262}{%
           family={Duanmu},
           familyi={D\bibinitperiod},
           given={Zhengfang},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c39472ae48abeae16b94f055c782c3fe}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Qingbo},
           giveni={Q\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f244e8ae5eff7776cf2b4b5b84ad8c4a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhou},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a145467fa9fec4f93e60603bdd640271}{%
           family={Yong},
           familyi={Y\bibinitperiod},
           given={Hongwei},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a549968ccfc4003d90c1ffd4a9ff5a05}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Hongliang},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f4a4cbf770add19c206827116c68732e}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Lei},
           giveni={L\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{629b9403529af15b56742c449f643c2d}
      \strng{fullhash}{19823db61e86416d5dafd1eee1bf3ab2}
      \strng{bibnamehash}{19823db61e86416d5dafd1eee1bf3ab2}
      \strng{authorbibnamehash}{19823db61e86416d5dafd1eee1bf3ab2}
      \strng{authornamehash}{629b9403529af15b56742c449f643c2d}
      \strng{authorfullhash}{19823db61e86416d5dafd1eee1bf3ab2}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The great content diversity of real-world digital images poses a grand challenge to image quality assessment (IQA) models, which are traditionally designed and validated on a handful of commonly used IQA databases with very limited content variation. To test the generalization capability and to facilitate the wide usage of IQA techniques in real-world applications, we establish a large-scale database named the Waterloo Exploration Database, which in its current state contains 4744 pristine natural images and 94 880 distorted images created from them. Instead of collecting the mean opinion score for each image via subjective testing, which is extremely difficult if not impossible, we present three alternative test criteria to evaluate the performance of IQA models, namely, the pristine/distorted image discriminability test, the listwise ranking consistency test, and the pairwise preference consistency test (P-test). We compare 20 well-known IQA models using the proposed criteria, which not only provide a stronger test in a more challenging testing environment for existing models, but also demonstrate the additional benefits of using the proposed database. For example, in the P-test, even for the best performing no-reference IQA model, more than 6 million failure cases against the model are “discovered” automatically out of over 1 billion test pairs. Furthermore, we discuss how the new database may be exploited using innovative approaches in the future, to reveal the weaknesses of existing IQA models, to provide insights on how to improve the models, and to shed light on how the next-generation IQA models may be developed. The database and codes are made publicly available at: https://ece.uwaterloo.ca/\textasciitilde k29ma/exploration/.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{2}
      \field{number}{2}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{shorttitle}{Waterloo {{Exploration Database}}}
      \field{title}{Waterloo {{Exploration Database}}: {{New Challenges}} for {{Image Quality Assessment Models}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{26}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1004\bibrangedash 1016}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TIP.2016.2631888
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/CZGVWNWD/Ma et al. - 2017 - Waterloo Exploration Database New Challenges for .pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/7752930/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/7752930/
      \endverb
    \endentry
    \entry{CCT}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=2f8448dbface32ad773f9ade4399a3f6}{%
           family={Min},
           familyi={M\bibinitperiod},
           given={Xiongkuo},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=79f9b1044b245e49f7e431dfc1b96bbd}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Kede},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a64df0db3d659a7cb92ab2266cdd6339}{%
           family={Gu},
           familyi={G\bibinitperiod},
           given={Ke},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=de70ef50dd45ba84349c3a3d3d5a9141}{%
           family={Zhai},
           familyi={Z\bibinitperiod},
           given={Guangtao},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f244e8ae5eff7776cf2b4b5b84ad8c4a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhou},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ef82e2e99c11391b0d3372d3bf096101}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Weisi},
           giveni={W\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b5956eea704a1bf19d70dfa9e1835ec0}
      \strng{fullhash}{62389347e63997afa9f42a66fd9abb81}
      \strng{bibnamehash}{62389347e63997afa9f42a66fd9abb81}
      \strng{authorbibnamehash}{62389347e63997afa9f42a66fd9abb81}
      \strng{authornamehash}{b5956eea704a1bf19d70dfa9e1835ec0}
      \strng{authorfullhash}{62389347e63997afa9f42a66fd9abb81}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Digital images in the real world are created by a variety of means and have diverse properties. A photographical natural scene image (NSI) may exhibit substantially different characteristics from a computer graphic image (CGI) or a screen content image (SCI). This casts major challenges to objective image quality assessment, for which existing approaches lack effective mechanisms to capture such content type variations, and thus are difficult to generalize from one type to another. To tackle this problem, we first construct a cross-content-type (CCT) database, which contains 1,320 distorted NSIs, CGIs, and SCIs, compressed using the high efficiency video coding (HEVC) intra coding method and the screen content compression (SCC) extension of HEVC. We then carry out a subjective experiment on the database in a well-controlled laboratory environment. Moreover, we propose a unified content-type adaptive (UCA) blind image quality assessment model that is applicable across content types. A key step in UCA is to incorporate the variations of human perceptual characteristics in viewing different content types through a multi-scale weighting framework. This leads to superior performance on the constructed CCT database. UCA is training-free, implying strong generalizability. To verify this, we test UCA on other databases containing JPEG, MPEG-2, H.264, and HEVC compressed images/videos, and observe that it consistently achieves competitive performance.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{11}
      \field{number}{11}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{title}{Unified {{Blind Quality Assessment}} of {{Compressed Natural}}, {{Graphic}}, and {{Screen Content Images}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{26}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{5462\bibrangedash 5474}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TIP.2017.2735192
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/FCJP6NPM/Min et al. - 2017 - Unified Blind Quality Assessment of Compressed Nat.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/8000398/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/8000398/
      \endverb
    \endentry
    \entry{SCIQ}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=9c42300b0b3bbf9827ee4a6c487490c7}{%
           family={Ni},
           familyi={N\bibinitperiod},
           given={Zhangkai},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8601659a37cae9b8932645c653921e5b}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Lin},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6b78353626b7ef8b21555f733da16b90}{%
           family={Zeng},
           familyi={Z\bibinitperiod},
           given={Huanqiang},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=11c05b885f1bc92570da26e49722e81d}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Jing},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=303437312f7cdcac2a16a360f776ae19}{%
           family={Cai},
           familyi={C\bibinitperiod},
           given={Canhui},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cd16103d76b32c3a006e7b7ad54f13c5}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Kai-Kuang},
           giveni={K\bibinithyphendelim K\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{6c4a826b8d6c30eb9890ddf80eedeb09}
      \strng{fullhash}{25988e9cf43c1bdbd64c9a3e1fd02cfc}
      \strng{bibnamehash}{25988e9cf43c1bdbd64c9a3e1fd02cfc}
      \strng{authorbibnamehash}{25988e9cf43c1bdbd64c9a3e1fd02cfc}
      \strng{authornamehash}{6c4a826b8d6c30eb9890ddf80eedeb09}
      \strng{authorfullhash}{25988e9cf43c1bdbd64c9a3e1fd02cfc}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In this paper, an accurate full-reference image quality assessment (IQA) model developed for assessing screen content images (SCIs), called the edge similarity (ESIM), is proposed. It is inspired by the fact that the human visual system (HVS) is highly sensitive to edges that are often encountered in SCIs; therefore, essential edge features are extracted and exploited for conducting IQA for the SCIs. The key novelty of the proposed ESIM lies in the extraction and use of three salient edge features—i.e., edge contrast, edge width, and edge direction. The first two attributes are simultaneously generated from the input SCI based on a parametric edge model, while the last one is derived directly from the input SCI. The extraction of these three features will be performed for the reference SCI and the distorted SCI, individually. The degree of similarity measured for each above-mentioned edge attribute is then computed independently, followed by combining them together using our proposed edge-width pooling strategy to generate the final ESIM score. To conduct the performance evaluation of our proposed ESIM model, a new and the largest SCI database (denoted as SCID) is established in our work and made to the public for download. Our database contains 1800 distorted SCIs that are generated from 40 reference SCIs. For each SCI, nine distortion types are investigated, and five degradation levels are produced for each distortion type. Extensive simulation results have clearly shown that the proposed ESIM model is more consistent with the perception of the HVS on the evaluation of distorted SCIs than the multiple state-of-the-art IQA methods.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{10}
      \field{number}{10}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{shorttitle}{{{ESIM}}}
      \field{title}{{{ESIM}}: {{Edge Similarity}} for {{Screen Content Image Quality Assessment}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{26}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{4818\bibrangedash 4831}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1109/TIP.2017.2718185
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/KUNRFCHU/Ni et al. - 2017 - ESIM Edge Similarity for Screen Content Image Qua.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/7954714/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/7954714/
      \endverb
    \endentry
    \entry{TID2008}{article}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=6b0ff13763f4a453b1d67bcef505c432}{%
           family={Ponomarenko},
           familyi={P\bibinitperiod},
           given={Nikolay},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fb49a7d26e4975bcb180af4a1fb7c99c}{%
           family={Lukin},
           familyi={L\bibinitperiod},
           given={Vladimir},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=666e9bd7b942482665d8772f7b7971bb}{%
           family={Zelensky},
           familyi={Z\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=72943da991b92fae8d3fcb28a3080793}{%
           family={Egiazarian},
           familyi={E\bibinitperiod},
           given={Karen},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4e0efd455d29950438dd83f5832f2921}{%
           family={Astola},
           familyi={A\bibinitperiod},
           given={Jaakko},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f63fd57cf4abe0aec29baf824c417de2}{%
           family={Carli},
           familyi={C\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=98456d3cec333fcf3f72e5a9a98bebba}{%
           family={Battisti},
           familyi={B\bibinitperiod},
           given={Federica},
           giveni={F\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{eaa11fffd3aeed1bc200d020c1b222b5}
      \strng{fullhash}{83f7028eeea63dc208b91cb2fa48a4c0}
      \strng{bibnamehash}{83f7028eeea63dc208b91cb2fa48a4c0}
      \strng{authorbibnamehash}{83f7028eeea63dc208b91cb2fa48a4c0}
      \strng{authornamehash}{eaa11fffd3aeed1bc200d020c1b222b5}
      \strng{authorfullhash}{83f7028eeea63dc208b91cb2fa48a4c0}
      \field{extraname}{1}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, a new image database, TID2008, for evaluation of full-reference visual quality assessment metrics is described. It contains 1700 test images (25 reference images, 17 types of distortions for each reference image, 4 different levels of each type of distortion). Mean Opinion Scores (MOS) for this database have been obtained as a result of more than 800 experiments. During these tests, observers from three countries (Finland, Italy, and Ukraine) have carried out about 256000 individual human quality judgments. The obtained MOS can be used for effective testing of different visual quality metrics as well as for the design of new metrics. Using the designed image database, we have tested several known quality metrics. The designed test image database is freely available for downloading and utilization in scientific investigations.}
      \field{langid}{english}
      \field{month}{1}
      \field{title}{{{TID2008}} – {{A Database}} for {{Evaluation}} of {{Full- Reference Visual Quality Assessment Metrics}}}
      \field{year}{2009}
      \field{dateera}{ce}
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/M93CPMPI/Ponomarenko et al. - TID2008 – A Database for Evaluation of Full- Refer.pdf
      \endverb
    \endentry
    \entry{TID2013}{article}{}
      \name{author}{11}{}{%
        {{un=0,uniquepart=base,hash=6b0ff13763f4a453b1d67bcef505c432}{%
           family={Ponomarenko},
           familyi={P\bibinitperiod},
           given={Nikolay},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=907fb6d00ff75c72b6d853ef1774f7f3}{%
           family={Jin},
           familyi={J\bibinitperiod},
           given={Lina},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1fe31832eb20800c7cd39d1cad85d7c9}{%
           family={Ieremeiev},
           familyi={I\bibinitperiod},
           given={Oleg},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fb49a7d26e4975bcb180af4a1fb7c99c}{%
           family={Lukin},
           familyi={L\bibinitperiod},
           given={Vladimir},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=72943da991b92fae8d3fcb28a3080793}{%
           family={Egiazarian},
           familyi={E\bibinitperiod},
           given={Karen},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4e0efd455d29950438dd83f5832f2921}{%
           family={Astola},
           familyi={A\bibinitperiod},
           given={Jaakko},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4a4f6b7f29f29613b2d443fbb6c58666}{%
           family={Vozel},
           familyi={V\bibinitperiod},
           given={Benoit},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=66695ef8124fdf52d033aff69af5bcae}{%
           family={Chehdi},
           familyi={C\bibinitperiod},
           given={Kacem},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f63fd57cf4abe0aec29baf824c417de2}{%
           family={Carli},
           familyi={C\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=98456d3cec333fcf3f72e5a9a98bebba}{%
           family={Battisti},
           familyi={B\bibinitperiod},
           given={Federica},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c0aab84e5274fd7546e004e63d60f04e}{%
           family={Jay\bibnamedelima Kuo},
           familyi={J\bibinitperiod\bibinitdelim K\bibinitperiod},
           given={C.-C.},
           giveni={C\bibinithyphendelim C\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{eaa11fffd3aeed1bc200d020c1b222b5}
      \strng{fullhash}{4e34179dbf744081b7a35d5b2fa6931a}
      \strng{bibnamehash}{4e34179dbf744081b7a35d5b2fa6931a}
      \strng{authorbibnamehash}{4e34179dbf744081b7a35d5b2fa6931a}
      \strng{authornamehash}{eaa11fffd3aeed1bc200d020c1b222b5}
      \strng{authorfullhash}{4e34179dbf744081b7a35d5b2fa6931a}
      \field{extraname}{2}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper describes a recently created image database, TID2013, intended for evaluation of full-reference visual quality assessment metrics. With respect to TID2008, the new database contains a larger number (3000) of test images obtained from 25 reference images, 24 types of distortions for each reference image, and 5 levels for each type of distortion. Motivations for introducing 7 new types of distortions and one additional level of distortions are given; examples of distorted images are presented. Mean opinion scores (MOS) for the new database have been collected by performing 985 subjective experiments with volunteers (observers) from five countries (Finland, France, Italy, Ukraine, and USA). The availability of MOS allows the use of the designed database as a fundamental tool for assessing the effectiveness of visual quality. Furthermore, existing visual quality metrics have been tested with the proposed database and the collected results have been analyzed using rank order correlation coefficients between MOS and considered metrics. These correlation indices have been obtained both considering the full set of distorted images and specific image subsets, for highlighting advantages and drawbacks of existing, state of the art, quality metrics. Approaches to thorough performance analysis for a given metric are presented to detect practical situations or distortion types for which this metric is not adequate enough to human perception. The created image database and the collected MOS values are freely available for downloading and utilization for scientific purposes.}
      \field{issn}{09235965}
      \field{journaltitle}{Signal Processing: Image Communication}
      \field{langid}{english}
      \field{month}{1}
      \field{shortjournal}{Signal Processing: Image Communication}
      \field{shorttitle}{Image Database {{TID2013}}}
      \field{title}{Image Database {{TID2013}}: {{Peculiarities}}, Results and Perspectives}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{30}
      \field{year}{2015}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{57\bibrangedash 77}
      \range{pages}{21}
      \verb{doi}
      \verb 10.1016/j.image.2014.10.009
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/NSWLLPSB/Ponomarenko et al. - 2015 - Image database TID2013 Peculiarities, results and.pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0923596514001490
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0923596514001490
      \endverb
    \endentry
    \entry{LIVE}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=84051ed6c4d99d3ccc763a9bfdfd28a8}{%
           family={Sheikh},
           familyi={S\bibinitperiod},
           given={H.R.},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2334097f18452e6d91139d8b12e6223c}{%
           family={Sabir},
           familyi={S\bibinitperiod},
           given={M.F.},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6192fbf30c45211fdfc67652236bec72}{%
           family={Bovik},
           familyi={B\bibinitperiod},
           given={A.C.},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{60b8bf6e07bbc3f0a1175b5fdca492f2}
      \strng{fullhash}{183b9ff62727cc10f604641f986c09bb}
      \strng{bibnamehash}{183b9ff62727cc10f604641f986c09bb}
      \strng{authorbibnamehash}{183b9ff62727cc10f604641f986c09bb}
      \strng{authornamehash}{60b8bf6e07bbc3f0a1175b5fdca492f2}
      \strng{authorfullhash}{183b9ff62727cc10f604641f986c09bb}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Measurement of visual quality is of fundamental importance for numerous image and video processing applications, where the goal of quality assessment (QA) algorithms is to automatically assess the quality of images or videos in agreement with human quality judgments. Over the years, many researchers have taken different approaches to the problem and have contributed significant research in this area and claim to have made progress in their respective domains. It is important to evaluate the performance of these algorithms in a comparative setting and analyze the strengths and weaknesses of these methods. In this paper, we present results of an extensive subjective quality assessment study in which a total of 779 distorted images were evaluated by about two dozen human subjects. The “ground truth” image quality data obtained from about 25 000 individual human quality judgments is used to evaluate the performance of several prominent full-reference image quality assessment algorithms. To the best of our knowledge, apart from video quality studies conducted by the Video Quality Experts Group, the study presented in this paper is the largest subjective image quality study in the literature in terms of number of images, distortion types, and number of human judgments per image. Moreover, we have made the data from the study freely available to the research community [1]. This would allow other researchers to easily report comparative results in the future.}
      \field{issn}{1057-7149}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{11}
      \field{number}{11}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{title}{A {{Statistical Evaluation}} of {{Recent Full Reference Image Quality Assessment Algorithms}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{15}
      \field{year}{2006}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{3440\bibrangedash 3451}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/TIP.2006.881959
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/8F2JWIAS/Sheikh et al. - 2006 - A Statistical Evaluation of Recent Full Reference .pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/1709988/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/1709988/
      \endverb
    \endentry
    \entry{MDID2016}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=4a71f03f723a983aabae2662ac156d9f}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Wen},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7c8ea78b26e5365d21c23659d9b4f074}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Fei},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=736e79ce2ca1a08fe56752b8e0af07e3}{%
           family={Liao},
           familyi={L\bibinitperiod},
           given={Qingmin},
           giveni={Q\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{f53481d5258202a126a9be4c28902e7f}
      \strng{fullhash}{e720cb32b22801f81c74f57f1eab3b26}
      \strng{bibnamehash}{e720cb32b22801f81c74f57f1eab3b26}
      \strng{authorbibnamehash}{e720cb32b22801f81c74f57f1eab3b26}
      \strng{authornamehash}{f53481d5258202a126a9be4c28902e7f}
      \strng{authorfullhash}{e720cb32b22801f81c74f57f1eab3b26}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In this paper, we present a new database, the multiply distorted image database (MDID), to evaluate image quality assessment (IQA) metrics on multiply distorted images. The database contains 20 reference images and 1600 distorted images. The latter images are obtained by contamination of the former with multiple distortions of random types and levels, so multiple types of distortions appear in each distorted image. Pair comparison sorting (PCS) is used as a new subjective rating method to evaluate image quality. This method allows subjects to make equal decisions on images whose difference in quality cannot be easily evaluated visually. A total of 192 subjects participated in the subjective rating, in which mean opinion scores and standard deviations were obtained. In IQA research, subjective scores and algorithm predictions are generally related by a nonlinear regression. We further propose a method to initialize the parameters of the nonlinear regression. The experiments of IQA metrics conducted on MDID validate that this database is advisable and challenging.}
      \field{issn}{00313203}
      \field{journaltitle}{Pattern Recognition}
      \field{langid}{english}
      \field{month}{1}
      \field{shortjournal}{Pattern Recognition}
      \field{shorttitle}{{{MDID}}}
      \field{title}{{{MDID}}: {{A}} Multiply Distorted Image Database for Image Quality Assessment}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{61}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{153\bibrangedash 168}
      \range{pages}{16}
      \verb{doi}
      \verb 10.1016/j.patcog.2016.07.033
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/JY7KJWKT/Sun et al. - 2017 - MDID A multiply distorted image database for imag.pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0031320316301911
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0031320316301911
      \endverb
    \endentry
    \entry{CID2013}{article}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=615c6826672471ff60b2d75da0020ced}{%
           family={Virtanen},
           familyi={V\bibinitperiod},
           given={Toni},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2c8e334e3ec64237c89b96f6f6dcee30}{%
           family={Nuutinen},
           familyi={N\bibinitperiod},
           given={Mikko},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c68ab1345a264730e85774b5e5fd34a9}{%
           family={Vaahteranoksa},
           familyi={V\bibinitperiod},
           given={Mikko},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=29ea3694c2bb063a2a643f72e5714d79}{%
           family={Oittinen},
           familyi={O\bibinitperiod},
           given={Pirkko},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=80a1211c5bf6d287819b70deed6eb327}{%
           family={Hakkinen},
           familyi={H\bibinitperiod},
           given={Jukka},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{e24786bd08b9de7985bad8323d0b8513}
      \strng{fullhash}{cc14904a43c60badb56949cfec98d6b1}
      \strng{bibnamehash}{cc14904a43c60badb56949cfec98d6b1}
      \strng{authorbibnamehash}{cc14904a43c60badb56949cfec98d6b1}
      \strng{authornamehash}{e24786bd08b9de7985bad8323d0b8513}
      \strng{authorfullhash}{cc14904a43c60badb56949cfec98d6b1}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper presents a new database, CID2013, to address the issue of using no-reference (NR) image quality assessment algorithms on images with multiple distortions. Current NR algorithms struggle to handle images with many concurrent distortion types, such as real photographic images captured by different digital cameras. The database consists of six image sets; on average, 30 subjects have evaluated 12–14 devices depicting eight different scenes for a total of 79 different cameras, 480 images, and 188 subjects (67\% female). The subjective evaluation method was a hybrid absolute category rating-pair comparison developed for the study and presented in this paper. This method utilizes a slideshow of all images within a scene to allow the test images to work as references to each other. In addition to mean opinion score value, the images are also rated using sharpness, graininess, lightness, and color saturation scales. The CID2013 database contains images used in the experiments with the full subjective data plus extensive background information from the subjects. The database is made freely available for the research community.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{shorttitle}{{{CID2013}}}
      \field{title}{{{CID2013}}: {{A Database}} for {{Evaluating No-Reference Image Quality Assessment Algorithms}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{24}
      \field{year}{2015}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{390\bibrangedash 402}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TIP.2014.2378061
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/KHXSACRZ/Virtanen et al. - 2015 - CID2013 A Database for Evaluating No-Reference Im.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6975172/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6975172/
      \endverb
    \endentry
    \entry{SIQAD}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=20c90b2c7ed4d1d31d2f648c075f6c90}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Huan},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d3a448d23a1b82215bcec1d99bd62be9}{%
           family={{Yuming Fang}},
           familyi={Y\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=ef82e2e99c11391b0d3372d3bf096101}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Weisi},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f244e8ae5eff7776cf2b4b5b84ad8c4a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhou},
           giveni={Z\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Singapore, Singapore}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{8969d129e834b307511063481c2617d5}
      \strng{fullhash}{e66dc206f4d5df2b4d3f10a64a29b763}
      \strng{bibnamehash}{e66dc206f4d5df2b4d3f10a64a29b763}
      \strng{authorbibnamehash}{e66dc206f4d5df2b4d3f10a64a29b763}
      \strng{authornamehash}{8969d129e834b307511063481c2617d5}
      \strng{authorfullhash}{e66dc206f4d5df2b4d3f10a64a29b763}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Research on Screen Content Images (SCIs) becomes important as they are increasingly used in multi-device communication applications. In this paper, we present a study of subjective quality assessment for distorted SCIs, and investigate which part (text or picture) contributes more to the overall visual quality. We construct a large-scale Screen Image Quality Assessment Database (SIQAD) consisting of 20 source and 980 distorted SCIs. The 11-category Absolute Category Rating (ACR) is employed to obtain three subjective quality scores corresponding to the entire image, textual and pictorial regions respectively. Based on the subjective data, we investigate the applicability of 12 state-of-the-art Image Quality Assessment (IQA) methods for objectively assessing the quality of SCIs. The results indicate that existing IQA methods are limited in predicting human quality judgement of SCIs. Moreover, we propose a prediction model to account for the correlation between the subjective scores of textual and pictorial regions and the entire image. The current results make an initial move towards objective quality assessment of SCIs.}
      \field{eventtitle}{2014 {{Sixth International Workshop}} on {{Quality}} of {{Multimedia Experience}} ({{QoMEX}})}
      \field{isbn}{978-1-4799-6536-6}
      \field{journaltitle}{2014 {{Sixth International Workshop}} on {{Quality}} of {{Multimedia Experience}} ({{QoMEX}})}
      \field{langid}{english}
      \field{month}{9}
      \field{title}{Subjective Quality Assessment of {{Screen Content Images}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{257\bibrangedash 262}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/QoMEX.2014.6982328
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/46AJMFUP/Yang et al. - 2014 - Subjective quality assessment of Screen Content Im.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6982328/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6982328/
      \endverb
    \endentry
  \enddatalist
  \datalist[entry]{apa/global//global/global}
    \entry{ARNIQA}{online}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=aa83122097905bf500be2f88e74d627f}{%
           family={Agnolucci},
           familyi={A\bibinitperiod},
           given={Lorenzo},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=653187c5fa949d389d18b815f0493cc6}{%
           family={Galteri},
           familyi={G\bibinitperiod},
           given={Leonardo},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=71c3126324af7ecd81c3870d46cd25b7}{%
           family={Bertini},
           familyi={B\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=20db68b33ce9530f55f14524fbfb14a2}{%
           family={Del\bibnamedelima Bimbo},
           familyi={D\bibinitperiod\bibinitdelim B\bibinitperiod},
           given={Alberto},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{2a62fec986d80f4d681fb14a8ad424a9}
      \strng{fullhash}{8aebff667f68a289b6c628110e185b00}
      \strng{bibnamehash}{8aebff667f68a289b6c628110e185b00}
      \strng{authorbibnamehash}{8aebff667f68a289b6c628110e185b00}
      \strng{authornamehash}{2a62fec986d80f4d681fb14a8ad424a9}
      \strng{authorfullhash}{8aebff667f68a289b6c628110e185b00}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{No-Reference Image Quality Assessment (NR-IQA) aims to develop methods to measure image quality in alignment with human perception without the need for a high-quality reference image. In this work, we propose a self-supervised approach named ARNIQA (leArning distoRtion maNifold for Image Quality Assessment) for modeling the image distortion manifold to obtain quality representations in an intrinsic manner. First, we introduce an image degradation model that randomly composes ordered sequences of consecutively applied distortions. In this way, we can synthetically degrade images with a large variety of degradation patterns. Second, we propose to train our model by maximizing the similarity between the representations of patches of different images distorted equally, despite varying content. Therefore, images degraded in the same manner correspond to neighboring positions within the distortion manifold. Finally, we map the image representations to the quality scores with a simple linear regressor, thus without fine-tuning the encoder weights. The experiments show that our approach achieves state-of-the-art performance on several datasets. In addition, ARNIQA demonstrates improved data efficiency, generalization capabilities, and robustness compared to competing methods. The code and the model are publicly available at https://github.com/ miccunifi/ARNIQA.}
      \field{day}{4}
      \field{eprintclass}{cs}
      \field{eprinttype}{arxiv}
      \field{langid}{english}
      \field{month}{11}
      \field{shorttitle}{{{ARNIQA}}}
      \field{title}{{{ARNIQA}}: {{Learning Distortion Manifold}} for {{Image Quality Assessment}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{eprint}
      \verb 2310.14918
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/FT9WTHT5/Agnolucci et al. - 2023 - ARNIQA Learning Distortion Manifold for Image Qua.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2310.14918
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2310.14918
      \endverb
      \keyw{Computer Science - Computer Vision and Pattern Recognition}
    \endentry
    \entry{CSIQ}{article}{}
      \name{author}{1}{}{%
        {{un=1,uniquepart=given,hash=c5addfdd7f1dd742dac1643e46f25ee6}{%
           family={Chandler},
           familyi={C\bibinitperiod},
           given={Damon\bibnamedelima M.},
           giveni={D\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=1}}%
      }
      \strng{namehash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{fullhash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{bibnamehash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{authorbibnamehash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{authornamehash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \strng{authorfullhash}{c5addfdd7f1dd742dac1643e46f25ee6}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{day}{1}
      \field{issn}{1017-9909}
      \field{journaltitle}{Journal of Electronic Imaging}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{J. Electron. Imaging}
      \field{shorttitle}{Most Apparent Distortion}
      \field{title}{Most Apparent Distortion: Full-Reference Image Quality Assessment and the Role of Strategy}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{19}
      \field{year}{2010}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{011006}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1117/1.3267105
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/ND7PFFNY/Chandler - 2010 - Most apparent distortion full-reference image qua.pdf
      \endverb
      \verb{urlraw}
      \verb https://s2.smu.edu/~eclarson/pubs/2010JEI_MAD.pdf
      \endverb
      \verb{url}
      \verb https://s2.smu.edu/~eclarson/pubs/2010JEI_MAD.pdf
      \endverb
    \endentry
    \entry{A57}{article}{}
      \name{author}{2}{}{%
        {{un=1,uniquepart=given,hash=52a422f501ab24ced4fed94ce0226e40}{%
           family={Chandler},
           familyi={C\bibinitperiod},
           given={D.M.},
           giveni={D\bibinitperiod},
           givenun=1}}%
        {{un=0,uniquepart=base,hash=e4622e95fefb83373d9614ae9c8ce220}{%
           family={Hemami},
           familyi={H\bibinitperiod},
           given={S.S.},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{fullhash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{bibnamehash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{authorbibnamehash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{authornamehash}{1ea3294ab1b80857b24a400ac4e1c519}
      \strng{authorfullhash}{1ea3294ab1b80857b24a400ac4e1c519}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper presents an efficient metric for quantifying the visual fidelity of natural images based on near-threshold and suprathreshold properties of human vision. The proposed metric, the visual signal-to-noise ratio (VSNR), operates via a two-stage approach. In the first stage, contrast thresholds for detection of distortions in the presence of natural images are computed via wavelet-based models of visual masking and visual summation in order to determine whether the distortions in the distorted image are visible. If the distortions are below the threshold of detection, the distorted image is deemed to be of perfect visual fidelity (VSNR = ) and no further analysis is required. If the distortions are suprathreshold, a second stage is applied which operates based on the low-level visual property of perceived contrast, and the mid-level visual property of global precedence. These two properties are modeled as Euclidean distances in distortion-contrast space of a multiscale wavelet decomposition, and VSNR is computed based on a simple linear sum of these distances. The proposed VSNR metric is generally competitive with current metrics of visual fidelity; it is efficient both in terms of its low computational complexity and in terms of its low memory requirements; and it operates based on physical luminances and visual angle (rather than on digital pixel values and pixel-based dimensions) to accommodate different viewing conditions.}
      \field{issn}{1057-7149}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{9}
      \field{number}{9}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{shorttitle}{{{VSNR}}}
      \field{title}{{{VSNR}}: {{A Wavelet-Based Visual Signal-to-Noise Ratio}} for {{Natural Images}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{16}
      \field{year}{2007}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2284\bibrangedash 2298}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1109/TIP.2007.901820
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/EW9CANZ4/Chandler und Hemami - 2007 - VSNR A Wavelet-Based Visual Signal-to-Noise Ratio.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/4286985/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/4286985/
      \endverb
    \endentry
    \entry{LIVE_Wild}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=3e0108af1e78568ae823af503315860a}{%
           family={Ghadiyaram},
           familyi={G\bibinitperiod},
           given={Deepti},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d9c2ab9a8cbcab08292923a454c88ce7}{%
           family={Bovik},
           familyi={B\bibinitperiod},
           given={Alan\bibnamedelima C.},
           giveni={A\bibinitperiod\bibinitdelim C\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{fullhash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{bibnamehash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{authorbibnamehash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{authornamehash}{3cdb959f35d9532ad6b5f9539dc38537}
      \strng{authorfullhash}{3cdb959f35d9532ad6b5f9539dc38537}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Most publicly available image quality databases have been created under highly controlled conditions by introducing graded simulated distortions onto high-quality photographs. However, images captured using typical real-world mobile camera devices are usually afflicted by complex mixtures of multiple distortions, which are not necessarily well-modeled by the synthetic distortions found in existing databases. The originators of existing legacy databases usually conducted human psychometric studies to obtain statistically meaningful sets of human opinion scores on images in a stringently controlled visual environment, resulting in small data collections relative to other kinds of image analysis databases. Toward overcoming these limitations, we designed and created a new database that we call the LIVE In the Wild Image Quality Challenge Database, which contains widely diverse authentic image distortions on a large number of images captured using a representative variety of modern mobile devices. We also designed and implemented a new online crowdsourcing system, which we have used to conduct a very large-scale, multi-month image quality assessment (IQA) subjective study. Our database consists of over 350 000 opinion scores on 1162 images evaluated by over 8100 unique human observers. Despite the lack of control over the experimental environments of the numerous study participants, we demonstrate excellent internal consistency of the subjective data set. We also evaluate several top-performing blind IQA algorithms on it and present insights on how the mixtures of distortions challenge both end users as well as automatic perceptual quality prediction models. The new database is available for public use at http://live.ece.utexas.edu/research/ChallengeDB/index.html.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{title}{Massive {{Online Crowdsourced Study}} of {{Subjective}} and {{Objective Picture Quality}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{25}
      \field{year}{2016}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{372\bibrangedash 387}
      \range{pages}{16}
      \verb{doi}
      \verb 10.1109/TIP.2015.2500021
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/NQWGF6QQ/Ghadiyaram und Bovik - 2016 - Massive Online Crowdsourced Study of Subjective an.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/7327186/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/7327186/
      \endverb
    \endentry
    \entry{HSNID}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=a64df0db3d659a7cb92ab2266cdd6339}{%
           family={Gu},
           familyi={G\bibinitperiod},
           given={Ke},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b6fc78834b479731029a5edb14fd5de0}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Xin},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=14f0dd7dfcfc375a1d3a6b42a2c58757}{%
           family={Qiao},
           familyi={Q\bibinitperiod},
           given={Junfei},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a63ef12742ef71a5a06fcf66d6d72ad7}{%
           family={Jiang},
           familyi={J\bibinitperiod},
           given={Qiuping},
           giveni={Q\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ef82e2e99c11391b0d3372d3bf096101}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Weisi},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=24f20de24938c18a3655f419579d0900}{%
           family={Thalmann},
           familyi={T\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{4e5d9e5d83d0e26c4d17cce126315705}
      \strng{fullhash}{3c429fdd3ef0a5700e5721efbe97dd62}
      \strng{bibnamehash}{3c429fdd3ef0a5700e5721efbe97dd62}
      \strng{authorbibnamehash}{3c429fdd3ef0a5700e5721efbe97dd62}
      \strng{authornamehash}{4e5d9e5d83d0e26c4d17cce126315705}
      \strng{authorfullhash}{3c429fdd3ef0a5700e5721efbe97dd62}
      \field{extraname}{1}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this work, we resolve a big challenge that most current image quality metrics (IQMs) are unavailable across different image contents, especially simultaneously coping with natural scene (NS) images or screen content (SC) images. By comparison with existing works, this paper deploys on-line and off-line data for proposing a unified no-reference (NR) IQM, not only applied to different distortion types and intensities but also to various image contents including classical NS images and prevailing SC images. Our proposed NR IQM is developed with two data-driven learning processes following feature extraction, which is based on scene statistic models, free-energy brain principle, and human visual system (HVS) characteristics. In the first process, the scene statistic models and an image retrieve technique are combined, based on on-line and off-line training instances, to derive a novel loose classifier for retrieving clean images and helping to infer the image content. In the second process, the features extracted by incorporating the inferred image content, free-energy and low-level perceptual characteristics of the HVS are learned by utilizing off-line training samples to analyze the distortion types and intensities and thereby to predict the image quality. The two processes mentioned above depend on a gigantic quantity of training data, much exceeding the number of images applied to performance validation, and thus make our model’s performance more reliable. Through extensive experiments, it has been validated that the proposed blind IQM is capable of simultaneously inferring the quality of NS and SC images, and it has attained superior performance as compared with popular and state-of-the-art IQMs on the subjective NS and SC image quality databases. The source code of our model will be released with the publication of the paper at https://kegu.netlify.com.}
      \field{day}{1}
      \field{issn}{2332-7790, 2372-2096}
      \field{journaltitle}{IEEE Transactions on Big Data}
      \field{langid}{english}
      \field{month}{12}
      \field{number}{4}
      \field{shortjournal}{IEEE Trans. Big Data}
      \field{title}{Learning a {{Unified Blind Image Quality Metric}} via {{On-Line}} and {{Off-Line Big Training Instances}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{6}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{780\bibrangedash 791}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/TBDATA.2019.2895605
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/8K778KAQ/Gu et al. - 2020 - Learning a Unified Blind Image Quality Metric via .pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8627983/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8627983/
      \endverb
    \endentry
    \entry{MDID2013}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=a64df0db3d659a7cb92ab2266cdd6339}{%
           family={Gu},
           familyi={G\bibinitperiod},
           given={Ke},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=de70ef50dd45ba84349c3a3d3d5a9141}{%
           family={Zhai},
           familyi={Z\bibinitperiod},
           given={Guangtao},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=31f1758fe4ad1edbef9504ac0116d1ad}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Xiaokang},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0d9c450eb8905fc9a195a67a39e601af}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Wenjun},
           giveni={W\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{4e5d9e5d83d0e26c4d17cce126315705}
      \strng{fullhash}{4f4df664f870c36e53e9c30c581f479c}
      \strng{bibnamehash}{4f4df664f870c36e53e9c30c581f479c}
      \strng{authorbibnamehash}{4f4df664f870c36e53e9c30c581f479c}
      \strng{authornamehash}{4e5d9e5d83d0e26c4d17cce126315705}
      \strng{authorfullhash}{4f4df664f870c36e53e9c30c581f479c}
      \field{extraname}{2}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In a typical image communication system, the visual signal presented to the end users may undergo the steps of acquisition, compression and transmission which cause the artifacts of blurring, quantization and noise. However, the researches of image quality assessment (IQA) with multiple distortion types are very limited. In this paper, we first introduce a new multiply distorted image database (MDID2013), which is composed of 324 images that are simultaneously corrupted by blurring, JPEG compression and noise injection. We then propose a new six-step blind metric (SISBLIM) for quality assessment of both singly and multiply distorted images. Inspired by the early human visual model and recently revealed free energy based brain theory, our method works to systematically combine the single quality prediction of each emerging distortion type and joint effects of different distortion sources. Comparative studies of the proposed SISBLIM with popular full-reference IQA approaches and start-of-the-art no-reference IQA metrics are conducted on five singly distorted image databases (LIVE, TID2008, CSIQ, IVC, Toyama) and two newly released multiply distorted image databases (LIVEMD, MDID2013). Experimental results confirm the effectiveness of our blind technique. MATLAB codes of the proposed SISBLIM algorithm and MDID2013 database will be available online at http://gvsp.sjtu.edu.cn/.}
      \field{issn}{0018-9316, 1557-9611}
      \field{journaltitle}{IEEE Transactions on Broadcasting}
      \field{langid}{english}
      \field{month}{9}
      \field{number}{3}
      \field{shortjournal}{IEEE Trans. on Broadcast.}
      \field{title}{Hybrid {{No-Reference Quality Metric}} for {{Singly}} and {{Multiply Distorted Images}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{60}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{555\bibrangedash 567}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TBC.2014.2344471
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/B4SN597A/Gu et al. - 2014 - Hybrid No-Reference Quality Metric for Singly and .pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/6879255/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/6879255/
      \endverb
    \endentry
    \entry{LIVEMD}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=cd27d3d228b115c84bc1d88310a81f02}{%
           family={Jayaraman},
           familyi={J\bibinitperiod},
           given={Dinesh},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5140f90dfa1ff2db127d5ad357e881ea}{%
           family={Mittal},
           familyi={M\bibinitperiod},
           given={Anish},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0637cd6093dcea240cdcb122b300761b}{%
           family={Moorthy},
           familyi={M\bibinitperiod},
           given={Anush\bibnamedelima K.},
           giveni={A\bibinitperiod\bibinitdelim K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d9c2ab9a8cbcab08292923a454c88ce7}{%
           family={Bovik},
           familyi={B\bibinitperiod},
           given={Alan\bibnamedelima C.},
           giveni={A\bibinitperiod\bibinitdelim C\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Pacific Grove, CA, USA}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{b9473887aa8ef09533091798c76022ef}
      \strng{fullhash}{8fb566e1d8b66be5dca6b5531931decd}
      \strng{bibnamehash}{8fb566e1d8b66be5dca6b5531931decd}
      \strng{authorbibnamehash}{8fb566e1d8b66be5dca6b5531931decd}
      \strng{authornamehash}{b9473887aa8ef09533091798c76022ef}
      \strng{authorfullhash}{8fb566e1d8b66be5dca6b5531931decd}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Subjective studies have been conducted in the past to obtain human judgments of visual quality on distorted images in order, among other things, to benchmark objective image qual. ity assessment (lQA) algorithms. Existing subjective studies primarily have records of human ratings on images that were corrupted by only one of many possible distortions. However, the majority of images that are available for consumption are corrupted by multiple distortions. Towards broadening the corpora of records of human responses to visual distortions, we recently conducted a study on two types of multiply distorted images to obtain human judgments of the visual quality of such images. Further, we compared the performance of several existing objective image quality measures on the new database and analyze the effects of multiple distortions on commonly used quality-determinant features and on human ratings.}
      \field{eventtitle}{2012 46th {{Asilomar Conference}} on {{Signals}}, {{Systems}} and {{Computers}}}
      \field{journaltitle}{2012 {{Conference Record}} of the {{Forty Sixth Asilomar Conference}} on {{Signals}}, {{Systems}} and {{Computers}} ({{ASILOMAR}})}
      \field{langid}{english}
      \field{month}{11}
      \field{title}{Objective Quality Assessment of Multiply Distorted Images}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2012}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1693\bibrangedash 1697}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/ACSSC.2012.6489321
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/XIL22H3U/Jayaraman et al. - 2012 - Objective quality assessment of multiply distorted.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6489321/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6489321/
      \endverb
    \endentry
    \entry{WED}{article}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=79f9b1044b245e49f7e431dfc1b96bbd}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Kede},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9aec47e12e3d6fbc7bdca7a5da683262}{%
           family={Duanmu},
           familyi={D\bibinitperiod},
           given={Zhengfang},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c39472ae48abeae16b94f055c782c3fe}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Qingbo},
           giveni={Q\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f244e8ae5eff7776cf2b4b5b84ad8c4a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhou},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a145467fa9fec4f93e60603bdd640271}{%
           family={Yong},
           familyi={Y\bibinitperiod},
           given={Hongwei},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a549968ccfc4003d90c1ffd4a9ff5a05}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Hongliang},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f4a4cbf770add19c206827116c68732e}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Lei},
           giveni={L\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{629b9403529af15b56742c449f643c2d}
      \strng{fullhash}{19823db61e86416d5dafd1eee1bf3ab2}
      \strng{bibnamehash}{19823db61e86416d5dafd1eee1bf3ab2}
      \strng{authorbibnamehash}{19823db61e86416d5dafd1eee1bf3ab2}
      \strng{authornamehash}{629b9403529af15b56742c449f643c2d}
      \strng{authorfullhash}{19823db61e86416d5dafd1eee1bf3ab2}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The great content diversity of real-world digital images poses a grand challenge to image quality assessment (IQA) models, which are traditionally designed and validated on a handful of commonly used IQA databases with very limited content variation. To test the generalization capability and to facilitate the wide usage of IQA techniques in real-world applications, we establish a large-scale database named the Waterloo Exploration Database, which in its current state contains 4744 pristine natural images and 94 880 distorted images created from them. Instead of collecting the mean opinion score for each image via subjective testing, which is extremely difficult if not impossible, we present three alternative test criteria to evaluate the performance of IQA models, namely, the pristine/distorted image discriminability test, the listwise ranking consistency test, and the pairwise preference consistency test (P-test). We compare 20 well-known IQA models using the proposed criteria, which not only provide a stronger test in a more challenging testing environment for existing models, but also demonstrate the additional benefits of using the proposed database. For example, in the P-test, even for the best performing no-reference IQA model, more than 6 million failure cases against the model are “discovered” automatically out of over 1 billion test pairs. Furthermore, we discuss how the new database may be exploited using innovative approaches in the future, to reveal the weaknesses of existing IQA models, to provide insights on how to improve the models, and to shed light on how the next-generation IQA models may be developed. The database and codes are made publicly available at: https://ece.uwaterloo.ca/\textasciitilde k29ma/exploration/.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{2}
      \field{number}{2}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{shorttitle}{Waterloo {{Exploration Database}}}
      \field{title}{Waterloo {{Exploration Database}}: {{New Challenges}} for {{Image Quality Assessment Models}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{26}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1004\bibrangedash 1016}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TIP.2016.2631888
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/CZGVWNWD/Ma et al. - 2017 - Waterloo Exploration Database New Challenges for .pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/7752930/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/7752930/
      \endverb
    \endentry
    \entry{CCT}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=2f8448dbface32ad773f9ade4399a3f6}{%
           family={Min},
           familyi={M\bibinitperiod},
           given={Xiongkuo},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=79f9b1044b245e49f7e431dfc1b96bbd}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Kede},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a64df0db3d659a7cb92ab2266cdd6339}{%
           family={Gu},
           familyi={G\bibinitperiod},
           given={Ke},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=de70ef50dd45ba84349c3a3d3d5a9141}{%
           family={Zhai},
           familyi={Z\bibinitperiod},
           given={Guangtao},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f244e8ae5eff7776cf2b4b5b84ad8c4a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhou},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ef82e2e99c11391b0d3372d3bf096101}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Weisi},
           giveni={W\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b5956eea704a1bf19d70dfa9e1835ec0}
      \strng{fullhash}{62389347e63997afa9f42a66fd9abb81}
      \strng{bibnamehash}{62389347e63997afa9f42a66fd9abb81}
      \strng{authorbibnamehash}{62389347e63997afa9f42a66fd9abb81}
      \strng{authornamehash}{b5956eea704a1bf19d70dfa9e1835ec0}
      \strng{authorfullhash}{62389347e63997afa9f42a66fd9abb81}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Digital images in the real world are created by a variety of means and have diverse properties. A photographical natural scene image (NSI) may exhibit substantially different characteristics from a computer graphic image (CGI) or a screen content image (SCI). This casts major challenges to objective image quality assessment, for which existing approaches lack effective mechanisms to capture such content type variations, and thus are difficult to generalize from one type to another. To tackle this problem, we first construct a cross-content-type (CCT) database, which contains 1,320 distorted NSIs, CGIs, and SCIs, compressed using the high efficiency video coding (HEVC) intra coding method and the screen content compression (SCC) extension of HEVC. We then carry out a subjective experiment on the database in a well-controlled laboratory environment. Moreover, we propose a unified content-type adaptive (UCA) blind image quality assessment model that is applicable across content types. A key step in UCA is to incorporate the variations of human perceptual characteristics in viewing different content types through a multi-scale weighting framework. This leads to superior performance on the constructed CCT database. UCA is training-free, implying strong generalizability. To verify this, we test UCA on other databases containing JPEG, MPEG-2, H.264, and HEVC compressed images/videos, and observe that it consistently achieves competitive performance.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{11}
      \field{number}{11}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{title}{Unified {{Blind Quality Assessment}} of {{Compressed Natural}}, {{Graphic}}, and {{Screen Content Images}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{26}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{5462\bibrangedash 5474}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TIP.2017.2735192
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/FCJP6NPM/Min et al. - 2017 - Unified Blind Quality Assessment of Compressed Nat.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/8000398/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/8000398/
      \endverb
    \endentry
    \entry{SCIQ}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=9c42300b0b3bbf9827ee4a6c487490c7}{%
           family={Ni},
           familyi={N\bibinitperiod},
           given={Zhangkai},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8601659a37cae9b8932645c653921e5b}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Lin},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6b78353626b7ef8b21555f733da16b90}{%
           family={Zeng},
           familyi={Z\bibinitperiod},
           given={Huanqiang},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=11c05b885f1bc92570da26e49722e81d}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Jing},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=303437312f7cdcac2a16a360f776ae19}{%
           family={Cai},
           familyi={C\bibinitperiod},
           given={Canhui},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cd16103d76b32c3a006e7b7ad54f13c5}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Kai-Kuang},
           giveni={K\bibinithyphendelim K\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{6c4a826b8d6c30eb9890ddf80eedeb09}
      \strng{fullhash}{25988e9cf43c1bdbd64c9a3e1fd02cfc}
      \strng{bibnamehash}{25988e9cf43c1bdbd64c9a3e1fd02cfc}
      \strng{authorbibnamehash}{25988e9cf43c1bdbd64c9a3e1fd02cfc}
      \strng{authornamehash}{6c4a826b8d6c30eb9890ddf80eedeb09}
      \strng{authorfullhash}{25988e9cf43c1bdbd64c9a3e1fd02cfc}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In this paper, an accurate full-reference image quality assessment (IQA) model developed for assessing screen content images (SCIs), called the edge similarity (ESIM), is proposed. It is inspired by the fact that the human visual system (HVS) is highly sensitive to edges that are often encountered in SCIs; therefore, essential edge features are extracted and exploited for conducting IQA for the SCIs. The key novelty of the proposed ESIM lies in the extraction and use of three salient edge features—i.e., edge contrast, edge width, and edge direction. The first two attributes are simultaneously generated from the input SCI based on a parametric edge model, while the last one is derived directly from the input SCI. The extraction of these three features will be performed for the reference SCI and the distorted SCI, individually. The degree of similarity measured for each above-mentioned edge attribute is then computed independently, followed by combining them together using our proposed edge-width pooling strategy to generate the final ESIM score. To conduct the performance evaluation of our proposed ESIM model, a new and the largest SCI database (denoted as SCID) is established in our work and made to the public for download. Our database contains 1800 distorted SCIs that are generated from 40 reference SCIs. For each SCI, nine distortion types are investigated, and five degradation levels are produced for each distortion type. Extensive simulation results have clearly shown that the proposed ESIM model is more consistent with the perception of the HVS on the evaluation of distorted SCIs than the multiple state-of-the-art IQA methods.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{10}
      \field{number}{10}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{shorttitle}{{{ESIM}}}
      \field{title}{{{ESIM}}: {{Edge Similarity}} for {{Screen Content Image Quality Assessment}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{26}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{4818\bibrangedash 4831}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1109/TIP.2017.2718185
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/KUNRFCHU/Ni et al. - 2017 - ESIM Edge Similarity for Screen Content Image Qua.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/7954714/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/7954714/
      \endverb
    \endentry
    \entry{TID2013}{article}{}
      \name{author}{11}{}{%
        {{un=0,uniquepart=base,hash=6b0ff13763f4a453b1d67bcef505c432}{%
           family={Ponomarenko},
           familyi={P\bibinitperiod},
           given={Nikolay},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=907fb6d00ff75c72b6d853ef1774f7f3}{%
           family={Jin},
           familyi={J\bibinitperiod},
           given={Lina},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1fe31832eb20800c7cd39d1cad85d7c9}{%
           family={Ieremeiev},
           familyi={I\bibinitperiod},
           given={Oleg},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fb49a7d26e4975bcb180af4a1fb7c99c}{%
           family={Lukin},
           familyi={L\bibinitperiod},
           given={Vladimir},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=72943da991b92fae8d3fcb28a3080793}{%
           family={Egiazarian},
           familyi={E\bibinitperiod},
           given={Karen},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4e0efd455d29950438dd83f5832f2921}{%
           family={Astola},
           familyi={A\bibinitperiod},
           given={Jaakko},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4a4f6b7f29f29613b2d443fbb6c58666}{%
           family={Vozel},
           familyi={V\bibinitperiod},
           given={Benoit},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=66695ef8124fdf52d033aff69af5bcae}{%
           family={Chehdi},
           familyi={C\bibinitperiod},
           given={Kacem},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f63fd57cf4abe0aec29baf824c417de2}{%
           family={Carli},
           familyi={C\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=98456d3cec333fcf3f72e5a9a98bebba}{%
           family={Battisti},
           familyi={B\bibinitperiod},
           given={Federica},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c0aab84e5274fd7546e004e63d60f04e}{%
           family={Jay\bibnamedelima Kuo},
           familyi={J\bibinitperiod\bibinitdelim K\bibinitperiod},
           given={C.-C.},
           giveni={C\bibinithyphendelim C\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{eaa11fffd3aeed1bc200d020c1b222b5}
      \strng{fullhash}{4e34179dbf744081b7a35d5b2fa6931a}
      \strng{bibnamehash}{4e34179dbf744081b7a35d5b2fa6931a}
      \strng{authorbibnamehash}{4e34179dbf744081b7a35d5b2fa6931a}
      \strng{authornamehash}{eaa11fffd3aeed1bc200d020c1b222b5}
      \strng{authorfullhash}{4e34179dbf744081b7a35d5b2fa6931a}
      \field{extraname}{1}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper describes a recently created image database, TID2013, intended for evaluation of full-reference visual quality assessment metrics. With respect to TID2008, the new database contains a larger number (3000) of test images obtained from 25 reference images, 24 types of distortions for each reference image, and 5 levels for each type of distortion. Motivations for introducing 7 new types of distortions and one additional level of distortions are given; examples of distorted images are presented. Mean opinion scores (MOS) for the new database have been collected by performing 985 subjective experiments with volunteers (observers) from five countries (Finland, France, Italy, Ukraine, and USA). The availability of MOS allows the use of the designed database as a fundamental tool for assessing the effectiveness of visual quality. Furthermore, existing visual quality metrics have been tested with the proposed database and the collected results have been analyzed using rank order correlation coefficients between MOS and considered metrics. These correlation indices have been obtained both considering the full set of distorted images and specific image subsets, for highlighting advantages and drawbacks of existing, state of the art, quality metrics. Approaches to thorough performance analysis for a given metric are presented to detect practical situations or distortion types for which this metric is not adequate enough to human perception. The created image database and the collected MOS values are freely available for downloading and utilization for scientific purposes.}
      \field{issn}{09235965}
      \field{journaltitle}{Signal Processing: Image Communication}
      \field{langid}{english}
      \field{month}{1}
      \field{shortjournal}{Signal Processing: Image Communication}
      \field{shorttitle}{Image Database {{TID2013}}}
      \field{title}{Image Database {{TID2013}}: {{Peculiarities}}, Results and Perspectives}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{30}
      \field{year}{2015}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{57\bibrangedash 77}
      \range{pages}{21}
      \verb{doi}
      \verb 10.1016/j.image.2014.10.009
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/NSWLLPSB/Ponomarenko et al. - 2015 - Image database TID2013 Peculiarities, results and.pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0923596514001490
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0923596514001490
      \endverb
    \endentry
    \entry{TID2008}{article}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=6b0ff13763f4a453b1d67bcef505c432}{%
           family={Ponomarenko},
           familyi={P\bibinitperiod},
           given={Nikolay},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fb49a7d26e4975bcb180af4a1fb7c99c}{%
           family={Lukin},
           familyi={L\bibinitperiod},
           given={Vladimir},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=666e9bd7b942482665d8772f7b7971bb}{%
           family={Zelensky},
           familyi={Z\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=72943da991b92fae8d3fcb28a3080793}{%
           family={Egiazarian},
           familyi={E\bibinitperiod},
           given={Karen},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4e0efd455d29950438dd83f5832f2921}{%
           family={Astola},
           familyi={A\bibinitperiod},
           given={Jaakko},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f63fd57cf4abe0aec29baf824c417de2}{%
           family={Carli},
           familyi={C\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=98456d3cec333fcf3f72e5a9a98bebba}{%
           family={Battisti},
           familyi={B\bibinitperiod},
           given={Federica},
           giveni={F\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{eaa11fffd3aeed1bc200d020c1b222b5}
      \strng{fullhash}{83f7028eeea63dc208b91cb2fa48a4c0}
      \strng{bibnamehash}{83f7028eeea63dc208b91cb2fa48a4c0}
      \strng{authorbibnamehash}{83f7028eeea63dc208b91cb2fa48a4c0}
      \strng{authornamehash}{eaa11fffd3aeed1bc200d020c1b222b5}
      \strng{authorfullhash}{83f7028eeea63dc208b91cb2fa48a4c0}
      \field{extraname}{2}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, a new image database, TID2008, for evaluation of full-reference visual quality assessment metrics is described. It contains 1700 test images (25 reference images, 17 types of distortions for each reference image, 4 different levels of each type of distortion). Mean Opinion Scores (MOS) for this database have been obtained as a result of more than 800 experiments. During these tests, observers from three countries (Finland, Italy, and Ukraine) have carried out about 256000 individual human quality judgments. The obtained MOS can be used for effective testing of different visual quality metrics as well as for the design of new metrics. Using the designed image database, we have tested several known quality metrics. The designed test image database is freely available for downloading and utilization in scientific investigations.}
      \field{langid}{english}
      \field{month}{1}
      \field{title}{{{TID2008}} – {{A Database}} for {{Evaluation}} of {{Full- Reference Visual Quality Assessment Metrics}}}
      \field{year}{2009}
      \field{dateera}{ce}
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/M93CPMPI/Ponomarenko et al. - TID2008 – A Database for Evaluation of Full- Refer.pdf
      \endverb
    \endentry
    \entry{LIVE}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=84051ed6c4d99d3ccc763a9bfdfd28a8}{%
           family={Sheikh},
           familyi={S\bibinitperiod},
           given={H.R.},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2334097f18452e6d91139d8b12e6223c}{%
           family={Sabir},
           familyi={S\bibinitperiod},
           given={M.F.},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6192fbf30c45211fdfc67652236bec72}{%
           family={Bovik},
           familyi={B\bibinitperiod},
           given={A.C.},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{60b8bf6e07bbc3f0a1175b5fdca492f2}
      \strng{fullhash}{183b9ff62727cc10f604641f986c09bb}
      \strng{bibnamehash}{183b9ff62727cc10f604641f986c09bb}
      \strng{authorbibnamehash}{183b9ff62727cc10f604641f986c09bb}
      \strng{authornamehash}{60b8bf6e07bbc3f0a1175b5fdca492f2}
      \strng{authorfullhash}{183b9ff62727cc10f604641f986c09bb}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Measurement of visual quality is of fundamental importance for numerous image and video processing applications, where the goal of quality assessment (QA) algorithms is to automatically assess the quality of images or videos in agreement with human quality judgments. Over the years, many researchers have taken different approaches to the problem and have contributed significant research in this area and claim to have made progress in their respective domains. It is important to evaluate the performance of these algorithms in a comparative setting and analyze the strengths and weaknesses of these methods. In this paper, we present results of an extensive subjective quality assessment study in which a total of 779 distorted images were evaluated by about two dozen human subjects. The “ground truth” image quality data obtained from about 25 000 individual human quality judgments is used to evaluate the performance of several prominent full-reference image quality assessment algorithms. To the best of our knowledge, apart from video quality studies conducted by the Video Quality Experts Group, the study presented in this paper is the largest subjective image quality study in the literature in terms of number of images, distortion types, and number of human judgments per image. Moreover, we have made the data from the study freely available to the research community [1]. This would allow other researchers to easily report comparative results in the future.}
      \field{issn}{1057-7149}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{11}
      \field{number}{11}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{title}{A {{Statistical Evaluation}} of {{Recent Full Reference Image Quality Assessment Algorithms}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{15}
      \field{year}{2006}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{3440\bibrangedash 3451}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/TIP.2006.881959
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/8F2JWIAS/Sheikh et al. - 2006 - A Statistical Evaluation of Recent Full Reference .pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/1709988/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/1709988/
      \endverb
    \endentry
    \entry{MDID2016}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=4a71f03f723a983aabae2662ac156d9f}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Wen},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7c8ea78b26e5365d21c23659d9b4f074}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Fei},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=736e79ce2ca1a08fe56752b8e0af07e3}{%
           family={Liao},
           familyi={L\bibinitperiod},
           given={Qingmin},
           giveni={Q\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{f53481d5258202a126a9be4c28902e7f}
      \strng{fullhash}{e720cb32b22801f81c74f57f1eab3b26}
      \strng{bibnamehash}{e720cb32b22801f81c74f57f1eab3b26}
      \strng{authorbibnamehash}{e720cb32b22801f81c74f57f1eab3b26}
      \strng{authornamehash}{f53481d5258202a126a9be4c28902e7f}
      \strng{authorfullhash}{e720cb32b22801f81c74f57f1eab3b26}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In this paper, we present a new database, the multiply distorted image database (MDID), to evaluate image quality assessment (IQA) metrics on multiply distorted images. The database contains 20 reference images and 1600 distorted images. The latter images are obtained by contamination of the former with multiple distortions of random types and levels, so multiple types of distortions appear in each distorted image. Pair comparison sorting (PCS) is used as a new subjective rating method to evaluate image quality. This method allows subjects to make equal decisions on images whose difference in quality cannot be easily evaluated visually. A total of 192 subjects participated in the subjective rating, in which mean opinion scores and standard deviations were obtained. In IQA research, subjective scores and algorithm predictions are generally related by a nonlinear regression. We further propose a method to initialize the parameters of the nonlinear regression. The experiments of IQA metrics conducted on MDID validate that this database is advisable and challenging.}
      \field{issn}{00313203}
      \field{journaltitle}{Pattern Recognition}
      \field{langid}{english}
      \field{month}{1}
      \field{shortjournal}{Pattern Recognition}
      \field{shorttitle}{{{MDID}}}
      \field{title}{{{MDID}}: {{A}} Multiply Distorted Image Database for Image Quality Assessment}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{61}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{153\bibrangedash 168}
      \range{pages}{16}
      \verb{doi}
      \verb 10.1016/j.patcog.2016.07.033
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/JY7KJWKT/Sun et al. - 2017 - MDID A multiply distorted image database for imag.pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0031320316301911
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0031320316301911
      \endverb
    \endentry
    \entry{CID2013}{article}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=615c6826672471ff60b2d75da0020ced}{%
           family={Virtanen},
           familyi={V\bibinitperiod},
           given={Toni},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2c8e334e3ec64237c89b96f6f6dcee30}{%
           family={Nuutinen},
           familyi={N\bibinitperiod},
           given={Mikko},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c68ab1345a264730e85774b5e5fd34a9}{%
           family={Vaahteranoksa},
           familyi={V\bibinitperiod},
           given={Mikko},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=29ea3694c2bb063a2a643f72e5714d79}{%
           family={Oittinen},
           familyi={O\bibinitperiod},
           given={Pirkko},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=80a1211c5bf6d287819b70deed6eb327}{%
           family={Hakkinen},
           familyi={H\bibinitperiod},
           given={Jukka},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{e24786bd08b9de7985bad8323d0b8513}
      \strng{fullhash}{cc14904a43c60badb56949cfec98d6b1}
      \strng{bibnamehash}{cc14904a43c60badb56949cfec98d6b1}
      \strng{authorbibnamehash}{cc14904a43c60badb56949cfec98d6b1}
      \strng{authornamehash}{e24786bd08b9de7985bad8323d0b8513}
      \strng{authorfullhash}{cc14904a43c60badb56949cfec98d6b1}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper presents a new database, CID2013, to address the issue of using no-reference (NR) image quality assessment algorithms on images with multiple distortions. Current NR algorithms struggle to handle images with many concurrent distortion types, such as real photographic images captured by different digital cameras. The database consists of six image sets; on average, 30 subjects have evaluated 12–14 devices depicting eight different scenes for a total of 79 different cameras, 480 images, and 188 subjects (67\% female). The subjective evaluation method was a hybrid absolute category rating-pair comparison developed for the study and presented in this paper. This method utilizes a slideshow of all images within a scene to allow the test images to work as references to each other. In addition to mean opinion score value, the images are also rated using sharpness, graininess, lightness, and color saturation scales. The CID2013 database contains images used in the experiments with the full subjective data plus extensive background information from the subjects. The database is made freely available for the research community.}
      \field{issn}{1057-7149, 1941-0042}
      \field{journaltitle}{IEEE Transactions on Image Processing}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{IEEE Trans. on Image Process.}
      \field{shorttitle}{{{CID2013}}}
      \field{title}{{{CID2013}}: {{A Database}} for {{Evaluating No-Reference Image Quality Assessment Algorithms}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{volume}{24}
      \field{year}{2015}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{390\bibrangedash 402}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TIP.2014.2378061
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/KHXSACRZ/Virtanen et al. - 2015 - CID2013 A Database for Evaluating No-Reference Im.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6975172/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6975172/
      \endverb
    \endentry
    \entry{SIQAD}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=20c90b2c7ed4d1d31d2f648c075f6c90}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Huan},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d3a448d23a1b82215bcec1d99bd62be9}{%
           family={{Yuming Fang}},
           familyi={Y\bibinitperiod}}}%
        {{un=0,uniquepart=base,hash=ef82e2e99c11391b0d3372d3bf096101}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Weisi},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f244e8ae5eff7776cf2b4b5b84ad8c4a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Zhou},
           giveni={Z\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Singapore, Singapore}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{8969d129e834b307511063481c2617d5}
      \strng{fullhash}{e66dc206f4d5df2b4d3f10a64a29b763}
      \strng{bibnamehash}{e66dc206f4d5df2b4d3f10a64a29b763}
      \strng{authorbibnamehash}{e66dc206f4d5df2b4d3f10a64a29b763}
      \strng{authornamehash}{8969d129e834b307511063481c2617d5}
      \strng{authorfullhash}{e66dc206f4d5df2b4d3f10a64a29b763}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Research on Screen Content Images (SCIs) becomes important as they are increasingly used in multi-device communication applications. In this paper, we present a study of subjective quality assessment for distorted SCIs, and investigate which part (text or picture) contributes more to the overall visual quality. We construct a large-scale Screen Image Quality Assessment Database (SIQAD) consisting of 20 source and 980 distorted SCIs. The 11-category Absolute Category Rating (ACR) is employed to obtain three subjective quality scores corresponding to the entire image, textual and pictorial regions respectively. Based on the subjective data, we investigate the applicability of 12 state-of-the-art Image Quality Assessment (IQA) methods for objectively assessing the quality of SCIs. The results indicate that existing IQA methods are limited in predicting human quality judgement of SCIs. Moreover, we propose a prediction model to account for the correlation between the subjective scores of textual and pictorial regions and the entire image. The current results make an initial move towards objective quality assessment of SCIs.}
      \field{eventtitle}{2014 {{Sixth International Workshop}} on {{Quality}} of {{Multimedia Experience}} ({{QoMEX}})}
      \field{isbn}{978-1-4799-6536-6}
      \field{journaltitle}{2014 {{Sixth International Workshop}} on {{Quality}} of {{Multimedia Experience}} ({{QoMEX}})}
      \field{langid}{english}
      \field{month}{9}
      \field{title}{Subjective Quality Assessment of {{Screen Content Images}}}
      \field{urlday}{23}
      \field{urlmonth}{4}
      \field{urlyear}{2024}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{257\bibrangedash 262}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/QoMEX.2014.6982328
      \endverb
      \verb{file}
      \verb /Users/choekyelnyungmartsang/Zotero/storage/46AJMFUP/Yang et al. - 2014 - Subjective quality assessment of Screen Content Im.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6982328/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6982328/
      \endverb
    \endentry
  \enddatalist
\endrefsection
\endinput

